{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fd201cb",
   "metadata": {},
   "source": [
    "# Step 1 - Installation of the model required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41e9588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com, https://pypi.ngc.nvidia.com\n",
      "Collecting torch\n",
      "  Downloading torch-1.11.0-cp38-cp38-manylinux1_x86_64.whl (750.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m201.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from torch) (4.0.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.11.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.0.1 requires botocore<1.22.9,>=1.22.8, but you have botocore 1.27.13 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com, https://pypi.ngc.nvidia.com\n",
      "Collecting nvidia-pyindex\n",
      "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nvidia-pyindex\n",
      "  Building wheel for nvidia-pyindex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-pyindex: filename=nvidia_pyindex-1.0.9-py3-none-any.whl size=8413 sha256=06277d6a386eb14f3a064b3e226269bb483110a0dcb29b13fbfb92fd6cde2103\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-z5rq5row/wheels/e0/c2/fb/5cf4e1cfaf28007238362cb746fb38fc2dd76348331a748d54\n",
      "Successfully built nvidia-pyindex\n",
      "Installing collected packages: nvidia-pyindex\n",
      "Successfully installed nvidia-pyindex-1.0.9\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com, https://pypi.ngc.nvidia.com\n",
      "Collecting tritonclient[http]\n",
      "  Downloading tritonclient-2.22.4-py3-none-manylinux1_x86_64.whl (8.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m194.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-rapidjson>=0.9.1\n",
      "  Downloading python_rapidjson-1.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m227.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from tritonclient[http]) (1.20.3)\n",
      "Collecting geventhttpclient>=1.4.4\n",
      "  Downloading geventhttpclient-1.5.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m175.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from geventhttpclient>=1.4.4->tritonclient[http]) (1.16.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from geventhttpclient>=1.4.4->tritonclient[http]) (2021.10.8)\n",
      "Requirement already satisfied: gevent>=0.13 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from geventhttpclient>=1.4.4->tritonclient[http]) (21.8.0)\n",
      "Collecting brotli\n",
      "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 kB\u001b[0m \u001b[31m210.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: greenlet<2.0,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (1.1.2)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (59.4.0)\n",
      "Requirement already satisfied: zope.event in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (4.5.0)\n",
      "Requirement already satisfied: zope.interface in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (5.4.0)\n",
      "Installing collected packages: brotli, python-rapidjson, tritonclient, geventhttpclient\n",
      "Successfully installed brotli-1.0.9 geventhttpclient-1.5.4 python-rapidjson-1.6 tritonclient-2.22.4\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com, https://pypi.ngc.nvidia.com\n",
      "Collecting pickle5\n",
      "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pickle5\n",
      "  Building wheel for pickle5 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pickle5: filename=pickle5-0.0.11-cp38-cp38-linux_x86_64.whl size=264755 sha256=e481e95f25df8b0c051c4191f21c94f556e729264c64d7ea3ffb928bfaf7ccc9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-iv0dlpm3/wheels/25/d4/61/dbd8edd1a0d656be7b4267c85db3b61951eb60016a0154a122\n",
      "Successfully built pickle5\n",
      "Installing collected packages: pickle5\n",
      "Successfully installed pickle5-0.0.11\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com, https://pypi.ngc.nvidia.com\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.3.2-py3-none-any.whl (362 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.3/362.3 kB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (7.0.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (2021.11.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (0.8.1)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (1.20.3)\n",
      "Requirement already satisfied: dill<0.3.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (4.62.3)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.1/212.1 kB\u001b[0m \u001b[31m204.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from packaging->datasets) (3.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp->datasets) (20.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, responses, datasets\n",
      "Successfully installed datasets-2.3.2 responses-0.18.0 xxhash-3.0.0\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (3.7)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from nltk) (2021.11.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch -U\n",
    "!pip install -qU pip awscli boto3 sagemaker transformers\n",
    "!pip install nvidia-pyindex\n",
    "!pip install tritonclient[http]\n",
    "!pip install pickle5\n",
    "!pip install datasets\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a8b53e",
   "metadata": {},
   "source": [
    "# Step 2 - Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8012c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-21 17:53:54,585 [INFO] Loading the Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-21 17:54:12,809 [INFO] Loading the Metric\n",
      "2022-06-21 17:54:12,889 [INFO] Loading the pretrained tokenizer and model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-21 17:54:13,917 [INFO] Preparing the training and evaluation dataset\n",
      "2022-06-21 17:56:48,785 [INFO] Training Started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 32580\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16292\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16292' max='16292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16292/16292 14:13, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.279900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.233000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.221300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.184800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.177000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.180500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.173200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.116800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.103800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.098200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.091100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.122000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.100700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.111200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.068200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.051700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.057800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.051600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.054900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.037400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.038200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.021400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.021800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.014200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-500\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-500/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-500/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-1000\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-1000/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-1000/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-1500\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-1500/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-1500/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-2000\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-2000/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-2000/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-2500\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-2500/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-2500/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-3000\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-3000/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-3000/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-3500\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-3500/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-3500/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-4000\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-4000/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-4000/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-4500\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-4500/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-4500/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-5000\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-5000/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-5000/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-5500\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-5500/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-5500/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-6000\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-6000/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-6000/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-6500\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-6500/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-6500/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-7000\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-7000/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-7000/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-7500\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-7500/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-7500/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-8000\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-8000/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-8000/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-8500\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-8500/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-8500/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-9000\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-9000/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-9000/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-9500\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-9500/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-9500/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-10000\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-10000/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-10000/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-10500\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-10500/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-10500/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-11000\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-11000/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-11000/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-11500\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-11500/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-11500/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-12000\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-12000/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-12000/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-12500\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-12500/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-12500/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-13000\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-13000/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-13000/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-13500\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-13500/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-13500/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-14000\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-14000/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-14000/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-14500\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-14500/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-14500/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-15000\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-15000/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-15000/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-15500\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-15500/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-15500/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./distilbert_train_intermediate/checkpoint-16000\n",
      "Configuration saved in ./distilbert_train_intermediate/checkpoint-16000/config.json\n",
      "Model weights saved in ./distilbert_train_intermediate/checkpoint-16000/pytorch_model.bin\n",
      "/tmp/ipykernel_26901/3408400625.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Configuration saved in ./workspace-trt/config.json\n",
      "Model weights saved in ./workspace-trt/pytorch_model.bin\n",
      "tokenizer config file saved in ./workspace-trt/tokenizer_config.json\n",
      "Special tokens file saved in ./workspace-trt/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-21 18:11:06,809 [INFO] Training Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 10860\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************** Evaluation ************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1358' max='1358' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1358/1358 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        4.0\n",
      "  eval_accuracy           =     0.9611\n",
      "  eval_loss               =      0.262\n",
      "  eval_runtime            = 0:00:15.25\n",
      "  eval_samples            =      10860\n",
      "  eval_samples_per_second =    712.027\n",
      "  eval_steps_per_second   =     89.036\n"
     ]
    }
   ],
   "source": [
    "import pickle5 as pickle\n",
    "import logging\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import sys\n",
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "\n",
    "TRAIN_DIR = \"./distilbert_train_intermediate\"\n",
    "FINAL_DIR = \"./workspace-trt\"\n",
    "DEFAULT_FILENAME = \"./spam_training_dataset_43k.pkl\"\n",
    "BATCH_SIZE = 128\n",
    "COL_DATA = \"text\"  # Name of the column with the spam text\n",
    "LABEL = \"is_spam\"  # Name of the column with the label 0 (ham) or 1 (spam)\n",
    "NUM_EPOCHS = 4\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "\n",
    "def clean_text(text):\n",
    "    import re\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    text = str(text).lower()  # Convert to lower case\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove everything except words\n",
    "    words = [word for word in text.split() if word not in stopwords]  # Remove stopwords\n",
    "    text = \" \".join(words)\n",
    "    return text\n",
    "\n",
    "def download_dataset():  \n",
    "    nltk.download(\"stopwords\")\n",
    "\n",
    "    with open(DEFAULT_FILENAME, \"rb\") as fh:\n",
    "        data = pickle.load(fh)\n",
    "        data = data[[COL_DATA, LABEL]]  \n",
    "        data[COL_DATA] = data[COL_DATA].apply(clean_text)\n",
    "        data.reset_index()\n",
    "        return data\n",
    "\n",
    "class ClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)    \n",
    "    \n",
    "logging.info('Loading the Dataset')\n",
    "dataset = download_dataset()\n",
    "\n",
    "logging.info('Loading the Metric')\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "logging.info('Loading the pretrained tokenizer and model')\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "logging.info('Preparing the training and evaluation dataset')\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(dataset[COL_DATA].values, dataset[LABEL].values)\n",
    "train_tokens = tokenizer(list(train_data), return_tensors=\"pt\", padding=True, truncation=True, max_length=BATCH_SIZE)\n",
    "val_tokens = tokenizer(list(val_data), return_tensors=\"pt\", padding=True, truncation=True, max_length=BATCH_SIZE)\n",
    "\n",
    "train_dataset = ClassificationDataset(train_tokens, train_labels)\n",
    "val_dataset = ClassificationDataset(val_tokens, val_labels)\n",
    "\n",
    "logging.info('Training Started')\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(output_dir=TRAIN_DIR, num_train_epochs=NUM_EPOCHS),\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(FINAL_DIR)\n",
    "tokenizer.save_pretrained(FINAL_DIR)\n",
    "logging.info('Training Completed')\n",
    "\n",
    "print(\"**************** Evaluation ************\")\n",
    "metrics = trainer.evaluate()\n",
    "metrics[\"eval_samples\"] = len(val_dataset)\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa915cb",
   "metadata": {},
   "source": [
    "# Step 3 - Generate the ONNX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4edd98ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 21.08 (build 26011915)\n",
      "PyTorch Version 1.10.0a0+3fd9dcf\n",
      "\n",
      "Container image Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.\n",
      "\n",
      "Copyright (c) 2014-2021 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "NVIDIA Deep Learning Profiler (dlprof) Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "NOTE: MOFED driver for multi-node communication was not detected.\n",
      "      Multi-node communication performance may be reduced.\n",
      "\n",
      "NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be\n",
      "   insufficient for PyTorch.  NVIDIA recommends the use of the following flags:\n",
      "   nvidia-docker run --ipc=host ...\n",
      "\n",
      "&&&& RUNNING TensorRT.trtexec [TensorRT v8001] # trtexec --onnx=model.onnx --saveEngine=model_bs16.plan --minShapes=input_ids:1x128,attention_mask:1x128 --optShapes=input_ids:1x128,attention_mask:1x128 --maxShapes=input_ids:1x128,attention_mask:1x128 --fp16 --verbose --workspace=14000\n",
      "[06/21/2022-18:22:00] [I] === Model Options ===\n",
      "[06/21/2022-18:22:00] [I] Format: ONNX\n",
      "[06/21/2022-18:22:00] [I] Model: model.onnx\n",
      "[06/21/2022-18:22:00] [I] Output:\n",
      "[06/21/2022-18:22:00] [I] === Build Options ===\n",
      "[06/21/2022-18:22:00] [I] Max batch: explicit\n",
      "[06/21/2022-18:22:00] [I] Workspace: 14000 MiB\n",
      "[06/21/2022-18:22:00] [I] minTiming: 1\n",
      "[06/21/2022-18:22:00] [I] avgTiming: 8\n",
      "[06/21/2022-18:22:00] [I] Precision: FP32+FP16\n",
      "[06/21/2022-18:22:00] [I] Calibration: \n",
      "[06/21/2022-18:22:00] [I] Refit: Disabled\n",
      "[06/21/2022-18:22:00] [I] Sparsity: Disabled\n",
      "[06/21/2022-18:22:00] [I] Safe mode: Disabled\n",
      "[06/21/2022-18:22:00] [I] Restricted mode: Disabled\n",
      "[06/21/2022-18:22:00] [I] Save engine: model_bs16.plan\n",
      "[06/21/2022-18:22:00] [I] Load engine: \n",
      "[06/21/2022-18:22:00] [I] NVTX verbosity: 0\n",
      "[06/21/2022-18:22:00] [I] Tactic sources: Using default tactic sources\n",
      "[06/21/2022-18:22:00] [I] timingCacheMode: local\n",
      "[06/21/2022-18:22:00] [I] timingCacheFile: \n",
      "[06/21/2022-18:22:00] [I] Input(s)s format: fp32:CHW\n",
      "[06/21/2022-18:22:00] [I] Output(s)s format: fp32:CHW\n",
      "[06/21/2022-18:22:00] [I] Input build shape: attention_mask=1x128+1x128+1x128\n",
      "[06/21/2022-18:22:00] [I] Input build shape: input_ids=1x128+1x128+1x128\n",
      "[06/21/2022-18:22:00] [I] Input calibration shapes: model\n",
      "[06/21/2022-18:22:00] [I] === System Options ===\n",
      "[06/21/2022-18:22:00] [I] Device: 0\n",
      "[06/21/2022-18:22:00] [I] DLACore: \n",
      "[06/21/2022-18:22:00] [I] Plugins:\n",
      "[06/21/2022-18:22:00] [I] === Inference Options ===\n",
      "[06/21/2022-18:22:00] [I] Batch: Explicit\n",
      "[06/21/2022-18:22:00] [I] Input inference shape: input_ids=1x128\n",
      "[06/21/2022-18:22:00] [I] Input inference shape: attention_mask=1x128\n",
      "[06/21/2022-18:22:00] [I] Iterations: 10\n",
      "[06/21/2022-18:22:00] [I] Duration: 3s (+ 200ms warm up)\n",
      "[06/21/2022-18:22:00] [I] Sleep time: 0ms\n",
      "[06/21/2022-18:22:00] [I] Streams: 1\n",
      "[06/21/2022-18:22:00] [I] ExposeDMA: Disabled\n",
      "[06/21/2022-18:22:00] [I] Data transfers: Enabled\n",
      "[06/21/2022-18:22:00] [I] Spin-wait: Disabled\n",
      "[06/21/2022-18:22:00] [I] Multithreading: Disabled\n",
      "[06/21/2022-18:22:00] [I] CUDA Graph: Disabled\n",
      "[06/21/2022-18:22:00] [I] Separate profiling: Disabled\n",
      "[06/21/2022-18:22:00] [I] Time Deserialize: Disabled\n",
      "[06/21/2022-18:22:00] [I] Time Refit: Disabled\n",
      "[06/21/2022-18:22:00] [I] Skip inference: Disabled\n",
      "[06/21/2022-18:22:00] [I] Inputs:\n",
      "[06/21/2022-18:22:00] [I] === Reporting Options ===\n",
      "[06/21/2022-18:22:00] [I] Verbose: Enabled\n",
      "[06/21/2022-18:22:00] [I] Averages: 10 inferences\n",
      "[06/21/2022-18:22:00] [I] Percentile: 99\n",
      "[06/21/2022-18:22:00] [I] Dump refittable layers:Disabled\n",
      "[06/21/2022-18:22:00] [I] Dump output: Disabled\n",
      "[06/21/2022-18:22:00] [I] Profile: Disabled\n",
      "[06/21/2022-18:22:00] [I] Export timing to JSON file: \n",
      "[06/21/2022-18:22:00] [I] Export output to JSON file: \n",
      "[06/21/2022-18:22:00] [I] Export profile to JSON file: \n",
      "[06/21/2022-18:22:00] [I] \n",
      "[06/21/2022-18:22:00] [I] === Device Information ===\n",
      "[06/21/2022-18:22:00] [I] Selected Device: Tesla V100-SXM2-16GB\n",
      "[06/21/2022-18:22:00] [I] Compute Capability: 7.0\n",
      "[06/21/2022-18:22:00] [I] SMs: 80\n",
      "[06/21/2022-18:22:00] [I] Compute Clock Rate: 1.53 GHz\n",
      "[06/21/2022-18:22:00] [I] Device Global Memory: 16160 MiB\n",
      "[06/21/2022-18:22:00] [I] Shared Memory per SM: 96 KiB\n",
      "[06/21/2022-18:22:00] [I] Memory Bus Width: 4096 bits (ECC enabled)\n",
      "[06/21/2022-18:22:00] [I] Memory Clock Rate: 0.877 GHz\n",
      "[06/21/2022-18:22:00] [I] \n",
      "[06/21/2022-18:22:00] [I] TensorRT version: 8001\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::Region_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::ScatterND version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::CropAndResize version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::Proposal version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::Split version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1\n",
      "[06/21/2022-18:22:00] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1\n",
      "[06/21/2022-18:22:01] [I] [TRT] [MemUsageChange] Init CUDA: CPU +249, GPU +0, now: CPU 256, GPU 3356 (MiB)\n",
      "[06/21/2022-18:22:01] [I] Start parsing network model\n",
      "[06/21/2022-18:22:01] [I] [TRT] ----------------------------------------------------------------\n",
      "[06/21/2022-18:22:01] [I] [TRT] Input filename:   model.onnx\n",
      "[06/21/2022-18:22:01] [I] [TRT] ONNX IR version:  0.0.6\n",
      "[06/21/2022-18:22:01] [I] [TRT] Opset version:    11\n",
      "[06/21/2022-18:22:01] [I] [TRT] Producer name:    pytorch\n",
      "[06/21/2022-18:22:01] [I] [TRT] Producer version: 1.10\n",
      "[06/21/2022-18:22:01] [I] [TRT] Domain:           \n",
      "[06/21/2022-18:22:01] [I] [TRT] Model version:    0\n",
      "[06/21/2022-18:22:01] [I] [TRT] Doc string:       \n",
      "[06/21/2022-18:22:01] [I] [TRT] ----------------------------------------------------------------\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::ScatterND version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::Proposal version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::Split version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1\n",
      "[06/21/2022-18:22:01] [V] [TRT] Adding network input: input_ids with dtype: int32, dimensions: (-1, -1)\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: input_ids for ONNX tensor: input_ids\n",
      "[06/21/2022-18:22:01] [V] [TRT] Adding network input: attention_mask with dtype: int32, dimensions: (-1, -1)\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: attention_mask for ONNX tensor: attention_mask\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.embeddings.word_embeddings.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.embeddings.position_embeddings.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.embeddings.LayerNorm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.embeddings.LayerNorm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.0.attention.q_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.0.attention.k_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.0.attention.v_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.0.attention.out_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.0.sa_layer_norm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.0.sa_layer_norm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.0.ffn.lin1.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.0.ffn.lin2.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.0.output_layer_norm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.0.output_layer_norm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.1.attention.q_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.1.attention.k_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.1.attention.v_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.1.attention.out_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.1.sa_layer_norm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.1.sa_layer_norm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.1.ffn.lin1.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.1.ffn.lin2.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.1.output_layer_norm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.1.output_layer_norm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.2.attention.q_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.2.attention.k_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.2.attention.v_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.2.attention.out_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.2.sa_layer_norm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.2.sa_layer_norm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.2.ffn.lin1.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.2.ffn.lin2.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.2.output_layer_norm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.2.output_layer_norm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.3.attention.q_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.3.attention.k_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.3.attention.v_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.3.attention.out_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.3.sa_layer_norm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.3.sa_layer_norm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.3.ffn.lin1.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.3.ffn.lin2.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.3.output_layer_norm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.3.output_layer_norm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.4.attention.q_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.4.attention.k_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.4.attention.v_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.4.attention.out_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.4.sa_layer_norm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.4.sa_layer_norm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.4.ffn.lin1.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.4.ffn.lin2.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.4.output_layer_norm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.4.output_layer_norm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.5.attention.q_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.5.attention.k_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.5.attention.v_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.5.attention.out_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.5.sa_layer_norm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.5.sa_layer_norm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.5.ffn.lin1.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.5.ffn.lin2.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.5.output_layer_norm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: distilbert.transformer.layer.5.output_layer_norm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: pre_classifier.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: pre_classifier.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: classifier.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: classifier.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 820\n",
      "[W] [06/21/2022-18:22:01] [TRT] onnx2trt_utils.cpp:362: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 821\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 822\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 823\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 824\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 825\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 826\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 827\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 828\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 829\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 830\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 831\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 832\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 833\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 834\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 835\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 836\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 837\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 838\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 839\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 840\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 841\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 842\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 843\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 844\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 845\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 846\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 847\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 848\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 849\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 850\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 851\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 852\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 853\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 854\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 855\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 856\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 857\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 858\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 859\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 860\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 861\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 862\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 863\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 864\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 865\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 866\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 867\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 868\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 869\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 870\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 871\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 872\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 873\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 874\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 875\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 876\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 877\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 878\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 879\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 880\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 881\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 882\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 883\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 884\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 885\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 886\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 887\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 888\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 889\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 890\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 891\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 892\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 893\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 894\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 895\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 896\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 897\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 898\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 899\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 900\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 901\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 902\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 903\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 904\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 905\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 906\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 907\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 908\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 909\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 910\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 911\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 912\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 913\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 914\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 915\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 916\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 917\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 918\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 919\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 920\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 921\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 922\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 923\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 924\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 925\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 926\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 927\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 928\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 929\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 930\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 931\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 932\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 933\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 934\n",
      "[06/21/2022-18:22:01] [V] [TRT] Importing initializer: 935\n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Shape_0 [Shape]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: input_ids\n",
      "[06/21/2022-18:22:01] [V] [TRT] Shape_0 [Shape] inputs: [input_ids -> (-1, -1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Shape_0 for ONNX node: Shape_0\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 106 for ONNX tensor: 106\n",
      "[06/21/2022-18:22:01] [V] [TRT] Shape_0 [Shape] outputs: [106 -> (2)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_1 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_1 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_1 [Constant] outputs: [107 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Gather_2 [Gather]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 106\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 107\n",
      "[06/21/2022-18:22:01] [V] [TRT] Gather_2 [Gather] inputs: [106 -> (2)[INT32]], [107 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 107 for ONNX node: 107\n",
      "[06/21/2022-18:22:01] [V] [TRT] Using Gather axis: 0\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Gather_2 for ONNX node: Gather_2\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 108 for ONNX tensor: 108\n",
      "[06/21/2022-18:22:01] [V] [TRT] Gather_2 [Gather] outputs: [108 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_3 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_3 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_3 [Constant] outputs: [109 -> (1, 512)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Unsqueeze_4 [Unsqueeze]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 108\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_4 [Unsqueeze] inputs: [108 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Unsqueeze_4 for ONNX node: Unsqueeze_4\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 113 for ONNX tensor: 113\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_4 [Unsqueeze] outputs: [113 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_5 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_5 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_5 [Constant] outputs: [115 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Slice_6 [Slice]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 109\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 820\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 113\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 821\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 115\n",
      "[06/21/2022-18:22:01] [V] [TRT] Slice_6 [Slice] inputs: [109 -> (1, 512)[INT32]], [820 -> (1)[INT32]], [113 -> (1)[INT32]], [821 -> (1)[INT32]], [115 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 109 for ONNX node: 109\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Slice_6 for ONNX node: Slice_6\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 116 for ONNX tensor: 116\n",
      "[06/21/2022-18:22:01] [V] [TRT] Slice_6 [Slice] outputs: [116 -> (1, -1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Gather_7 [Gather]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.embeddings.word_embeddings.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: input_ids\n",
      "[06/21/2022-18:22:01] [V] [TRT] Gather_7 [Gather] inputs: [distilbert.embeddings.word_embeddings.weight -> (30522, 768)[FLOAT]], [input_ids -> (-1, -1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.embeddings.word_embeddings.weight for ONNX node: distilbert.embeddings.word_embeddings.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Using Gather axis: 0\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Gather_7 for ONNX node: Gather_7\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 117 for ONNX tensor: 117\n",
      "[06/21/2022-18:22:01] [V] [TRT] Gather_7 [Gather] outputs: [117 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Gather_8 [Gather]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.embeddings.position_embeddings.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 116\n",
      "[06/21/2022-18:22:01] [V] [TRT] Gather_8 [Gather] inputs: [distilbert.embeddings.position_embeddings.weight -> (512, 768)[FLOAT]], [116 -> (1, -1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.embeddings.position_embeddings.weight for ONNX node: distilbert.embeddings.position_embeddings.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Using Gather axis: 0\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Gather_8 for ONNX node: Gather_8\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 118 for ONNX tensor: 118\n",
      "[06/21/2022-18:22:01] [V] [TRT] Gather_8 [Gather] outputs: [118 -> (1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_9 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 117\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 118\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_9 [Add] inputs: [117 -> (-1, -1, 768)[FLOAT]], [118 -> (1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_9 for ONNX node: Add_9\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 119 for ONNX tensor: 119\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_9 [Add] outputs: [119 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: ReduceMean_10 [ReduceMean]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 119\n",
      "[06/21/2022-18:22:01] [V] [TRT] ReduceMean_10 [ReduceMean] inputs: [119 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: ReduceMean_10 for ONNX node: ReduceMean_10\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 120 for ONNX tensor: 120\n",
      "[06/21/2022-18:22:01] [V] [TRT] ReduceMean_10 [ReduceMean] outputs: [120 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Sub_11 [Sub]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 119\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 120\n",
      "[06/21/2022-18:22:01] [V] [TRT] Sub_11 [Sub] inputs: [119 -> (-1, -1, 768)[FLOAT]], [120 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Sub_11 for ONNX node: Sub_11\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 121 for ONNX tensor: 121\n",
      "[06/21/2022-18:22:01] [V] [TRT] Sub_11 [Sub] outputs: [121 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_12 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_12 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_12 [Constant] outputs: [122 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Pow_13 [Pow]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 121\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 122\n",
      "[06/21/2022-18:22:01] [V] [TRT] Pow_13 [Pow] inputs: [121 -> (-1, -1, 768)[FLOAT]], [122 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 122 for ONNX node: 122\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Pow_13 for ONNX node: Pow_13\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 123 for ONNX tensor: 123\n",
      "[06/21/2022-18:22:01] [V] [TRT] Pow_13 [Pow] outputs: [123 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: ReduceMean_14 [ReduceMean]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 123\n",
      "[06/21/2022-18:22:01] [V] [TRT] ReduceMean_14 [ReduceMean] inputs: [123 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: ReduceMean_14 for ONNX node: ReduceMean_14\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 124 for ONNX tensor: 124\n",
      "[06/21/2022-18:22:01] [V] [TRT] ReduceMean_14 [ReduceMean] outputs: [124 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_15 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_15 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_15 [Constant] outputs: [125 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_16 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 124\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 125\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_16 [Add] inputs: [124 -> (-1, -1, 1)[FLOAT]], [125 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 125 for ONNX node: 125\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_16 for ONNX node: Add_16\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 126 for ONNX tensor: 126\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_16 [Add] outputs: [126 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Sqrt_17 [Sqrt]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 126\n",
      "[06/21/2022-18:22:01] [V] [TRT] Sqrt_17 [Sqrt] inputs: [126 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Sqrt_17 for ONNX node: Sqrt_17\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 127 for ONNX tensor: 127\n",
      "[06/21/2022-18:22:01] [V] [TRT] Sqrt_17 [Sqrt] outputs: [127 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Div_18 [Div]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 121\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 127\n",
      "[06/21/2022-18:22:01] [V] [TRT] Div_18 [Div] inputs: [121 -> (-1, -1, 768)[FLOAT]], [127 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Div_18 for ONNX node: Div_18\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 128 for ONNX tensor: 128\n",
      "[06/21/2022-18:22:01] [V] [TRT] Div_18 [Div] outputs: [128 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Mul_19 [Mul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 128\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.embeddings.LayerNorm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Mul_19 [Mul] inputs: [128 -> (-1, -1, 768)[FLOAT]], [distilbert.embeddings.LayerNorm.weight -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.embeddings.LayerNorm.weight for ONNX node: distilbert.embeddings.LayerNorm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Mul_19 for ONNX node: Mul_19\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 129 for ONNX tensor: 129\n",
      "[06/21/2022-18:22:01] [V] [TRT] Mul_19 [Mul] outputs: [129 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_20 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 129\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.embeddings.LayerNorm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_20 [Add] inputs: [129 -> (-1, -1, 768)[FLOAT]], [distilbert.embeddings.LayerNorm.bias -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.embeddings.LayerNorm.bias for ONNX node: distilbert.embeddings.LayerNorm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_20 for ONNX node: Add_20\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 130 for ONNX tensor: 130\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_20 [Add] outputs: [130 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Shape_21 [Shape]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 130\n",
      "[06/21/2022-18:22:01] [V] [TRT] Shape_21 [Shape] inputs: [130 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Shape_21 for ONNX node: Shape_21\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 131 for ONNX tensor: 131\n",
      "[06/21/2022-18:22:01] [V] [TRT] Shape_21 [Shape] outputs: [131 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_22 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_22 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_22 [Constant] outputs: [132 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Gather_23 [Gather]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 131\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 132\n",
      "[06/21/2022-18:22:01] [V] [TRT] Gather_23 [Gather] inputs: [131 -> (3)[INT32]], [132 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 132 for ONNX node: 132\n",
      "[06/21/2022-18:22:01] [V] [TRT] Using Gather axis: 0\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Gather_23 for ONNX node: Gather_23\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 133 for ONNX tensor: 133\n",
      "[06/21/2022-18:22:01] [V] [TRT] Gather_23 [Gather] outputs: [133 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Shape_24 [Shape]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 130\n",
      "[06/21/2022-18:22:01] [V] [TRT] Shape_24 [Shape] inputs: [130 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Shape_24 for ONNX node: Shape_24\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 134 for ONNX tensor: 134\n",
      "[06/21/2022-18:22:01] [V] [TRT] Shape_24 [Shape] outputs: [134 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_25 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_25 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_25 [Constant] outputs: [135 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Gather_26 [Gather]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 134\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 135\n",
      "[06/21/2022-18:22:01] [V] [TRT] Gather_26 [Gather] inputs: [134 -> (3)[INT32]], [135 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 135 for ONNX node: 135\n",
      "[06/21/2022-18:22:01] [V] [TRT] Using Gather axis: 0\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Gather_26 for ONNX node: Gather_26\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 136 for ONNX tensor: 136\n",
      "[06/21/2022-18:22:01] [V] [TRT] Gather_26 [Gather] outputs: [136 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: MatMul_27 [MatMul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 130\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 822\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_27 [MatMul] inputs: [130 -> (-1, -1, 768)[FLOAT]], [822 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 822 for ONNX node: 822\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: MatMul_27 for ONNX node: MatMul_27\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 138 for ONNX tensor: 138\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_27 [MatMul] outputs: [138 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_28 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.transformer.layer.0.attention.q_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 138\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_28 [Add] inputs: [distilbert.transformer.layer.0.attention.q_lin.bias -> (768)[FLOAT]], [138 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.transformer.layer.0.attention.q_lin.bias for ONNX node: distilbert.transformer.layer.0.attention.q_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_28 for ONNX node: Add_28\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 139 for ONNX tensor: 139\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_28 [Add] outputs: [139 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Unsqueeze_29 [Unsqueeze]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 133\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_29 [Unsqueeze] inputs: [133 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Unsqueeze_29 for ONNX node: Unsqueeze_29\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 143 for ONNX tensor: 143\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_29 [Unsqueeze] outputs: [143 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Concat_30 [Concat]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 143\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 823\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 824\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 825\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_30 [Concat] inputs: [143 -> (1)[INT32]], [823 -> (1)[INT32]], [824 -> (1)[INT32]], [825 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 823 for ONNX node: 823\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 824 for ONNX node: 824\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 825 for ONNX node: 825\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Concat_30 for ONNX node: Concat_30\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 147 for ONNX tensor: 147\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_30 [Concat] outputs: [147 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Reshape_31 [Reshape]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 139\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 147\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_31 [Reshape] inputs: [139 -> (-1, -1, 768)[FLOAT]], [147 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Reshape_31 for ONNX node: Reshape_31\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 148 for ONNX tensor: 148\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_31 [Reshape] outputs: [148 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Transpose_32 [Transpose]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 148\n",
      "[06/21/2022-18:22:01] [V] [TRT] Transpose_32 [Transpose] inputs: [148 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Transpose_32 for ONNX node: Transpose_32\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 149 for ONNX tensor: 149\n",
      "[06/21/2022-18:22:01] [V] [TRT] Transpose_32 [Transpose] outputs: [149 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: MatMul_33 [MatMul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 130\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 826\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_33 [MatMul] inputs: [130 -> (-1, -1, 768)[FLOAT]], [826 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 826 for ONNX node: 826\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: MatMul_33 for ONNX node: MatMul_33\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 151 for ONNX tensor: 151\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_33 [MatMul] outputs: [151 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_34 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.transformer.layer.0.attention.k_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 151\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_34 [Add] inputs: [distilbert.transformer.layer.0.attention.k_lin.bias -> (768)[FLOAT]], [151 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.transformer.layer.0.attention.k_lin.bias for ONNX node: distilbert.transformer.layer.0.attention.k_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_34 for ONNX node: Add_34\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 152 for ONNX tensor: 152\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_34 [Add] outputs: [152 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Unsqueeze_35 [Unsqueeze]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 133\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_35 [Unsqueeze] inputs: [133 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Unsqueeze_35 for ONNX node: Unsqueeze_35\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 156 for ONNX tensor: 156\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_35 [Unsqueeze] outputs: [156 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Concat_36 [Concat]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 156\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 827\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 828\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 829\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_36 [Concat] inputs: [156 -> (1)[INT32]], [827 -> (1)[INT32]], [828 -> (1)[INT32]], [829 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 827 for ONNX node: 827\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 828 for ONNX node: 828\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 829 for ONNX node: 829\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Concat_36 for ONNX node: Concat_36\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 160 for ONNX tensor: 160\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_36 [Concat] outputs: [160 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Reshape_37 [Reshape]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 152\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 160\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_37 [Reshape] inputs: [152 -> (-1, -1, 768)[FLOAT]], [160 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Reshape_37 for ONNX node: Reshape_37\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 161 for ONNX tensor: 161\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_37 [Reshape] outputs: [161 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: MatMul_38 [MatMul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 130\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 830\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_38 [MatMul] inputs: [130 -> (-1, -1, 768)[FLOAT]], [830 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 830 for ONNX node: 830\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: MatMul_38 for ONNX node: MatMul_38\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 163 for ONNX tensor: 163\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_38 [MatMul] outputs: [163 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_39 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.transformer.layer.0.attention.v_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 163\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_39 [Add] inputs: [distilbert.transformer.layer.0.attention.v_lin.bias -> (768)[FLOAT]], [163 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.transformer.layer.0.attention.v_lin.bias for ONNX node: distilbert.transformer.layer.0.attention.v_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_39 for ONNX node: Add_39\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 164 for ONNX tensor: 164\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_39 [Add] outputs: [164 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Unsqueeze_40 [Unsqueeze]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 133\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_40 [Unsqueeze] inputs: [133 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Unsqueeze_40 for ONNX node: Unsqueeze_40\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 168 for ONNX tensor: 168\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_40 [Unsqueeze] outputs: [168 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Concat_41 [Concat]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 168\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 831\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 832\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 833\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_41 [Concat] inputs: [168 -> (1)[INT32]], [831 -> (1)[INT32]], [832 -> (1)[INT32]], [833 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 831 for ONNX node: 831\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 832 for ONNX node: 832\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 833 for ONNX node: 833\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Concat_41 for ONNX node: Concat_41\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 172 for ONNX tensor: 172\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_41 [Concat] outputs: [172 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Reshape_42 [Reshape]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 164\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 172\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_42 [Reshape] inputs: [164 -> (-1, -1, 768)[FLOAT]], [172 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Reshape_42 for ONNX node: Reshape_42\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 173 for ONNX tensor: 173\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_42 [Reshape] outputs: [173 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Transpose_43 [Transpose]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 173\n",
      "[06/21/2022-18:22:01] [V] [TRT] Transpose_43 [Transpose] inputs: [173 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Transpose_43 for ONNX node: Transpose_43\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 174 for ONNX tensor: 174\n",
      "[06/21/2022-18:22:01] [V] [TRT] Transpose_43 [Transpose] outputs: [174 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_44 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_44 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_44 [Constant] outputs: [175 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Div_45 [Div]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 149\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 175\n",
      "[06/21/2022-18:22:01] [V] [TRT] Div_45 [Div] inputs: [149 -> (-1, 12, -1, 64)[FLOAT]], [175 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 175 for ONNX node: 175\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Div_45 for ONNX node: Div_45\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 176 for ONNX tensor: 176\n",
      "[06/21/2022-18:22:01] [V] [TRT] Div_45 [Div] outputs: [176 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Transpose_46 [Transpose]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 161\n",
      "[06/21/2022-18:22:01] [V] [TRT] Transpose_46 [Transpose] inputs: [161 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Transpose_46 for ONNX node: Transpose_46\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 177 for ONNX tensor: 177\n",
      "[06/21/2022-18:22:01] [V] [TRT] Transpose_46 [Transpose] outputs: [177 -> (-1, 12, 64, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: MatMul_47 [MatMul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 176\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 177\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_47 [MatMul] inputs: [176 -> (-1, 12, -1, 64)[FLOAT]], [177 -> (-1, 12, 64, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: MatMul_47 for ONNX node: MatMul_47\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 178 for ONNX tensor: 178\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_47 [MatMul] outputs: [178 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_48 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_48 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_48 [Constant] outputs: [179 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Equal_49 [Equal]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: attention_mask\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 179\n",
      "[06/21/2022-18:22:01] [V] [TRT] Equal_49 [Equal] inputs: [attention_mask -> (-1, -1)[INT32]], [179 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 179 for ONNX node: 179\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Equal_49 for ONNX node: Equal_49\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 180 for ONNX tensor: 180\n",
      "[06/21/2022-18:22:01] [V] [TRT] Equal_49 [Equal] outputs: [180 -> (-1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Unsqueeze_50 [Unsqueeze]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 133\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_50 [Unsqueeze] inputs: [133 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Unsqueeze_50 for ONNX node: Unsqueeze_50\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 183 for ONNX tensor: 183\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_50 [Unsqueeze] outputs: [183 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Unsqueeze_51 [Unsqueeze]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 136\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_51 [Unsqueeze] inputs: [136 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Unsqueeze_51 for ONNX node: Unsqueeze_51\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 186 for ONNX tensor: 186\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_51 [Unsqueeze] outputs: [186 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Concat_52 [Concat]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 183\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 834\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 835\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 186\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_52 [Concat] inputs: [183 -> (1)[INT32]], [834 -> (1)[INT32]], [835 -> (1)[INT32]], [186 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 834 for ONNX node: 834\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 835 for ONNX node: 835\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Concat_52 for ONNX node: Concat_52\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 187 for ONNX tensor: 187\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_52 [Concat] outputs: [187 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Reshape_53 [Reshape]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 180\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 187\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_53 [Reshape] inputs: [180 -> (-1, -1)[BOOL]], [187 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Reshape_53 for ONNX node: Reshape_53\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 188 for ONNX tensor: 188\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_53 [Reshape] outputs: [188 -> (-1, 1, 1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Shape_54 [Shape]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 178\n",
      "[06/21/2022-18:22:01] [V] [TRT] Shape_54 [Shape] inputs: [178 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Shape_54 for ONNX node: Shape_54\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 189 for ONNX tensor: 189\n",
      "[06/21/2022-18:22:01] [V] [TRT] Shape_54 [Shape] outputs: [189 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Expand_55 [Expand]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 188\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 189\n",
      "[06/21/2022-18:22:01] [V] [TRT] Expand_55 [Expand] inputs: [188 -> (-1, 1, 1, -1)[BOOL]], [189 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Expand_55 for ONNX node: Expand_55\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 190 for ONNX tensor: 190\n",
      "[06/21/2022-18:22:01] [V] [TRT] Expand_55 [Expand] outputs: [190 -> (-1, 12, -1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Cast_56 [Cast]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 190\n",
      "[06/21/2022-18:22:01] [V] [TRT] Cast_56 [Cast] inputs: [190 -> (-1, 12, -1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Casting to type: bool\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Cast_56 for ONNX node: Cast_56\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 191 for ONNX tensor: 191\n",
      "[06/21/2022-18:22:01] [V] [TRT] Cast_56 [Cast] outputs: [191 -> (-1, 12, -1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_57 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_57 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_57 [Constant] outputs: [192 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Where_58 [Where]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 191\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 192\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 178\n",
      "[06/21/2022-18:22:01] [V] [TRT] Where_58 [Where] inputs: [191 -> (-1, 12, -1, -1)[BOOL]], [192 -> ()[FLOAT]], [178 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 192 for ONNX node: 192\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Where_58 for ONNX node: Where_58\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 193 for ONNX tensor: 193\n",
      "[06/21/2022-18:22:01] [V] [TRT] Where_58 [Where] outputs: [193 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Softmax_59 [Softmax]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 193\n",
      "[06/21/2022-18:22:01] [V] [TRT] Softmax_59 [Softmax] inputs: [193 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Softmax_59 for ONNX node: Softmax_59\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 194 for ONNX tensor: 194\n",
      "[06/21/2022-18:22:01] [V] [TRT] Softmax_59 [Softmax] outputs: [194 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: MatMul_60 [MatMul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 194\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 174\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_60 [MatMul] inputs: [194 -> (-1, 12, -1, -1)[FLOAT]], [174 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: MatMul_60 for ONNX node: MatMul_60\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 195 for ONNX tensor: 195\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_60 [MatMul] outputs: [195 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Transpose_61 [Transpose]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 195\n",
      "[06/21/2022-18:22:01] [V] [TRT] Transpose_61 [Transpose] inputs: [195 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Transpose_61 for ONNX node: Transpose_61\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 196 for ONNX tensor: 196\n",
      "[06/21/2022-18:22:01] [V] [TRT] Transpose_61 [Transpose] outputs: [196 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Unsqueeze_62 [Unsqueeze]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 133\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_62 [Unsqueeze] inputs: [133 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Unsqueeze_62 for ONNX node: Unsqueeze_62\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 199 for ONNX tensor: 199\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_62 [Unsqueeze] outputs: [199 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Concat_63 [Concat]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 199\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 836\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 837\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_63 [Concat] inputs: [199 -> (1)[INT32]], [836 -> (1)[INT32]], [837 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 836 for ONNX node: 836\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 837 for ONNX node: 837\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Concat_63 for ONNX node: Concat_63\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 202 for ONNX tensor: 202\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_63 [Concat] outputs: [202 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Reshape_64 [Reshape]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 196\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 202\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_64 [Reshape] inputs: [196 -> (-1, -1, 12, 64)[FLOAT]], [202 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Reshape_64 for ONNX node: Reshape_64\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 203 for ONNX tensor: 203\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_64 [Reshape] outputs: [203 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: MatMul_65 [MatMul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 203\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 838\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_65 [MatMul] inputs: [203 -> (-1, -1, 768)[FLOAT]], [838 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 838 for ONNX node: 838\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: MatMul_65 for ONNX node: MatMul_65\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 205 for ONNX tensor: 205\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_65 [MatMul] outputs: [205 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_66 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.transformer.layer.0.attention.out_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 205\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_66 [Add] inputs: [distilbert.transformer.layer.0.attention.out_lin.bias -> (768)[FLOAT]], [205 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.transformer.layer.0.attention.out_lin.bias for ONNX node: distilbert.transformer.layer.0.attention.out_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_66 for ONNX node: Add_66\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 206 for ONNX tensor: 206\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_66 [Add] outputs: [206 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_67 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 206\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 130\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_67 [Add] inputs: [206 -> (-1, -1, 768)[FLOAT]], [130 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_67 for ONNX node: Add_67\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 207 for ONNX tensor: 207\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_67 [Add] outputs: [207 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: ReduceMean_68 [ReduceMean]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 207\n",
      "[06/21/2022-18:22:01] [V] [TRT] ReduceMean_68 [ReduceMean] inputs: [207 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: ReduceMean_68 for ONNX node: ReduceMean_68\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 208 for ONNX tensor: 208\n",
      "[06/21/2022-18:22:01] [V] [TRT] ReduceMean_68 [ReduceMean] outputs: [208 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Sub_69 [Sub]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 207\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 208\n",
      "[06/21/2022-18:22:01] [V] [TRT] Sub_69 [Sub] inputs: [207 -> (-1, -1, 768)[FLOAT]], [208 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Sub_69 for ONNX node: Sub_69\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 209 for ONNX tensor: 209\n",
      "[06/21/2022-18:22:01] [V] [TRT] Sub_69 [Sub] outputs: [209 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_70 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_70 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_70 [Constant] outputs: [210 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Pow_71 [Pow]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 209\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 210\n",
      "[06/21/2022-18:22:01] [V] [TRT] Pow_71 [Pow] inputs: [209 -> (-1, -1, 768)[FLOAT]], [210 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 210 for ONNX node: 210\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Pow_71 for ONNX node: Pow_71\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 211 for ONNX tensor: 211\n",
      "[06/21/2022-18:22:01] [V] [TRT] Pow_71 [Pow] outputs: [211 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: ReduceMean_72 [ReduceMean]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 211\n",
      "[06/21/2022-18:22:01] [V] [TRT] ReduceMean_72 [ReduceMean] inputs: [211 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: ReduceMean_72 for ONNX node: ReduceMean_72\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 212 for ONNX tensor: 212\n",
      "[06/21/2022-18:22:01] [V] [TRT] ReduceMean_72 [ReduceMean] outputs: [212 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_73 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_73 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_73 [Constant] outputs: [213 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_74 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 212\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 213\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_74 [Add] inputs: [212 -> (-1, -1, 1)[FLOAT]], [213 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 213 for ONNX node: 213\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_74 for ONNX node: Add_74\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 214 for ONNX tensor: 214\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_74 [Add] outputs: [214 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Sqrt_75 [Sqrt]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 214\n",
      "[06/21/2022-18:22:01] [V] [TRT] Sqrt_75 [Sqrt] inputs: [214 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Sqrt_75 for ONNX node: Sqrt_75\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 215 for ONNX tensor: 215\n",
      "[06/21/2022-18:22:01] [V] [TRT] Sqrt_75 [Sqrt] outputs: [215 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Div_76 [Div]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 209\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 215\n",
      "[06/21/2022-18:22:01] [V] [TRT] Div_76 [Div] inputs: [209 -> (-1, -1, 768)[FLOAT]], [215 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Div_76 for ONNX node: Div_76\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 216 for ONNX tensor: 216\n",
      "[06/21/2022-18:22:01] [V] [TRT] Div_76 [Div] outputs: [216 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Mul_77 [Mul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 216\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.transformer.layer.0.sa_layer_norm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Mul_77 [Mul] inputs: [216 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.0.sa_layer_norm.weight -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.transformer.layer.0.sa_layer_norm.weight for ONNX node: distilbert.transformer.layer.0.sa_layer_norm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Mul_77 for ONNX node: Mul_77\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 217 for ONNX tensor: 217\n",
      "[06/21/2022-18:22:01] [V] [TRT] Mul_77 [Mul] outputs: [217 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_78 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 217\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.transformer.layer.0.sa_layer_norm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_78 [Add] inputs: [217 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.0.sa_layer_norm.bias -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.transformer.layer.0.sa_layer_norm.bias for ONNX node: distilbert.transformer.layer.0.sa_layer_norm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_78 for ONNX node: Add_78\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 218 for ONNX tensor: 218\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_78 [Add] outputs: [218 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: MatMul_79 [MatMul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 218\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 839\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_79 [MatMul] inputs: [218 -> (-1, -1, 768)[FLOAT]], [839 -> (768, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 839 for ONNX node: 839\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: MatMul_79 for ONNX node: MatMul_79\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 220 for ONNX tensor: 220\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_79 [MatMul] outputs: [220 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_80 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.transformer.layer.0.ffn.lin1.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 220\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_80 [Add] inputs: [distilbert.transformer.layer.0.ffn.lin1.bias -> (3072)[FLOAT]], [220 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.transformer.layer.0.ffn.lin1.bias for ONNX node: distilbert.transformer.layer.0.ffn.lin1.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_80 for ONNX node: Add_80\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 221 for ONNX tensor: 221\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_80 [Add] outputs: [221 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_81 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_81 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_81 [Constant] outputs: [222 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Div_82 [Div]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 221\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 222\n",
      "[06/21/2022-18:22:01] [V] [TRT] Div_82 [Div] inputs: [221 -> (-1, -1, 3072)[FLOAT]], [222 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 222 for ONNX node: 222\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Div_82 for ONNX node: Div_82\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 223 for ONNX tensor: 223\n",
      "[06/21/2022-18:22:01] [V] [TRT] Div_82 [Div] outputs: [223 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Erf_83 [Erf]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 223\n",
      "[06/21/2022-18:22:01] [V] [TRT] Erf_83 [Erf] inputs: [223 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Erf_83 for ONNX node: Erf_83\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 224 for ONNX tensor: 224\n",
      "[06/21/2022-18:22:01] [V] [TRT] Erf_83 [Erf] outputs: [224 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_84 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_84 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_84 [Constant] outputs: [225 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_85 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 224\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 225\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_85 [Add] inputs: [224 -> (-1, -1, 3072)[FLOAT]], [225 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 225 for ONNX node: 225\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_85 for ONNX node: Add_85\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 226 for ONNX tensor: 226\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_85 [Add] outputs: [226 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Mul_86 [Mul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 221\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 226\n",
      "[06/21/2022-18:22:01] [V] [TRT] Mul_86 [Mul] inputs: [221 -> (-1, -1, 3072)[FLOAT]], [226 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Mul_86 for ONNX node: Mul_86\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 227 for ONNX tensor: 227\n",
      "[06/21/2022-18:22:01] [V] [TRT] Mul_86 [Mul] outputs: [227 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_87 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_87 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_87 [Constant] outputs: [228 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Mul_88 [Mul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 227\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 228\n",
      "[06/21/2022-18:22:01] [V] [TRT] Mul_88 [Mul] inputs: [227 -> (-1, -1, 3072)[FLOAT]], [228 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 228 for ONNX node: 228\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Mul_88 for ONNX node: Mul_88\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 229 for ONNX tensor: 229\n",
      "[06/21/2022-18:22:01] [V] [TRT] Mul_88 [Mul] outputs: [229 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: MatMul_89 [MatMul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 229\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 840\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_89 [MatMul] inputs: [229 -> (-1, -1, 3072)[FLOAT]], [840 -> (3072, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 840 for ONNX node: 840\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: MatMul_89 for ONNX node: MatMul_89\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 231 for ONNX tensor: 231\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_89 [MatMul] outputs: [231 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_90 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.transformer.layer.0.ffn.lin2.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 231\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_90 [Add] inputs: [distilbert.transformer.layer.0.ffn.lin2.bias -> (768)[FLOAT]], [231 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.transformer.layer.0.ffn.lin2.bias for ONNX node: distilbert.transformer.layer.0.ffn.lin2.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_90 for ONNX node: Add_90\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 232 for ONNX tensor: 232\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_90 [Add] outputs: [232 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_91 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 232\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 218\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_91 [Add] inputs: [232 -> (-1, -1, 768)[FLOAT]], [218 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_91 for ONNX node: Add_91\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 233 for ONNX tensor: 233\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_91 [Add] outputs: [233 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: ReduceMean_92 [ReduceMean]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 233\n",
      "[06/21/2022-18:22:01] [V] [TRT] ReduceMean_92 [ReduceMean] inputs: [233 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: ReduceMean_92 for ONNX node: ReduceMean_92\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 234 for ONNX tensor: 234\n",
      "[06/21/2022-18:22:01] [V] [TRT] ReduceMean_92 [ReduceMean] outputs: [234 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Sub_93 [Sub]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 233\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 234\n",
      "[06/21/2022-18:22:01] [V] [TRT] Sub_93 [Sub] inputs: [233 -> (-1, -1, 768)[FLOAT]], [234 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Sub_93 for ONNX node: Sub_93\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 235 for ONNX tensor: 235\n",
      "[06/21/2022-18:22:01] [V] [TRT] Sub_93 [Sub] outputs: [235 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_94 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_94 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_94 [Constant] outputs: [236 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Pow_95 [Pow]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 235\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 236\n",
      "[06/21/2022-18:22:01] [V] [TRT] Pow_95 [Pow] inputs: [235 -> (-1, -1, 768)[FLOAT]], [236 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 236 for ONNX node: 236\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Pow_95 for ONNX node: Pow_95\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 237 for ONNX tensor: 237\n",
      "[06/21/2022-18:22:01] [V] [TRT] Pow_95 [Pow] outputs: [237 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: ReduceMean_96 [ReduceMean]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 237\n",
      "[06/21/2022-18:22:01] [V] [TRT] ReduceMean_96 [ReduceMean] inputs: [237 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: ReduceMean_96 for ONNX node: ReduceMean_96\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 238 for ONNX tensor: 238\n",
      "[06/21/2022-18:22:01] [V] [TRT] ReduceMean_96 [ReduceMean] outputs: [238 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_97 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_97 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_97 [Constant] outputs: [239 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_98 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 238\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 239\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_98 [Add] inputs: [238 -> (-1, -1, 1)[FLOAT]], [239 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 239 for ONNX node: 239\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_98 for ONNX node: Add_98\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 240 for ONNX tensor: 240\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_98 [Add] outputs: [240 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Sqrt_99 [Sqrt]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 240\n",
      "[06/21/2022-18:22:01] [V] [TRT] Sqrt_99 [Sqrt] inputs: [240 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Sqrt_99 for ONNX node: Sqrt_99\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 241 for ONNX tensor: 241\n",
      "[06/21/2022-18:22:01] [V] [TRT] Sqrt_99 [Sqrt] outputs: [241 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Div_100 [Div]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 235\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 241\n",
      "[06/21/2022-18:22:01] [V] [TRT] Div_100 [Div] inputs: [235 -> (-1, -1, 768)[FLOAT]], [241 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Div_100 for ONNX node: Div_100\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 242 for ONNX tensor: 242\n",
      "[06/21/2022-18:22:01] [V] [TRT] Div_100 [Div] outputs: [242 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Mul_101 [Mul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 242\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.transformer.layer.0.output_layer_norm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Mul_101 [Mul] inputs: [242 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.0.output_layer_norm.weight -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.transformer.layer.0.output_layer_norm.weight for ONNX node: distilbert.transformer.layer.0.output_layer_norm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Mul_101 for ONNX node: Mul_101\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 243 for ONNX tensor: 243\n",
      "[06/21/2022-18:22:01] [V] [TRT] Mul_101 [Mul] outputs: [243 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_102 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 243\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.transformer.layer.0.output_layer_norm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_102 [Add] inputs: [243 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.0.output_layer_norm.bias -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.transformer.layer.0.output_layer_norm.bias for ONNX node: distilbert.transformer.layer.0.output_layer_norm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_102 for ONNX node: Add_102\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 244 for ONNX tensor: 244\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_102 [Add] outputs: [244 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Shape_103 [Shape]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 244\n",
      "[06/21/2022-18:22:01] [V] [TRT] Shape_103 [Shape] inputs: [244 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Shape_103 for ONNX node: Shape_103\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 245 for ONNX tensor: 245\n",
      "[06/21/2022-18:22:01] [V] [TRT] Shape_103 [Shape] outputs: [245 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_104 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_104 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_104 [Constant] outputs: [246 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Gather_105 [Gather]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 245\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 246\n",
      "[06/21/2022-18:22:01] [V] [TRT] Gather_105 [Gather] inputs: [245 -> (3)[INT32]], [246 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 246 for ONNX node: 246\n",
      "[06/21/2022-18:22:01] [V] [TRT] Using Gather axis: 0\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Gather_105 for ONNX node: Gather_105\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 247 for ONNX tensor: 247\n",
      "[06/21/2022-18:22:01] [V] [TRT] Gather_105 [Gather] outputs: [247 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Shape_106 [Shape]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 244\n",
      "[06/21/2022-18:22:01] [V] [TRT] Shape_106 [Shape] inputs: [244 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Shape_106 for ONNX node: Shape_106\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 248 for ONNX tensor: 248\n",
      "[06/21/2022-18:22:01] [V] [TRT] Shape_106 [Shape] outputs: [248 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_107 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_107 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_107 [Constant] outputs: [249 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Gather_108 [Gather]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 248\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 249\n",
      "[06/21/2022-18:22:01] [V] [TRT] Gather_108 [Gather] inputs: [248 -> (3)[INT32]], [249 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 249 for ONNX node: 249\n",
      "[06/21/2022-18:22:01] [V] [TRT] Using Gather axis: 0\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Gather_108 for ONNX node: Gather_108\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 250 for ONNX tensor: 250\n",
      "[06/21/2022-18:22:01] [V] [TRT] Gather_108 [Gather] outputs: [250 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: MatMul_109 [MatMul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 244\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 841\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_109 [MatMul] inputs: [244 -> (-1, -1, 768)[FLOAT]], [841 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 841 for ONNX node: 841\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: MatMul_109 for ONNX node: MatMul_109\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 252 for ONNX tensor: 252\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_109 [MatMul] outputs: [252 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_110 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.transformer.layer.1.attention.q_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 252\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_110 [Add] inputs: [distilbert.transformer.layer.1.attention.q_lin.bias -> (768)[FLOAT]], [252 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.transformer.layer.1.attention.q_lin.bias for ONNX node: distilbert.transformer.layer.1.attention.q_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_110 for ONNX node: Add_110\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 253 for ONNX tensor: 253\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_110 [Add] outputs: [253 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Unsqueeze_111 [Unsqueeze]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 247\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_111 [Unsqueeze] inputs: [247 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Unsqueeze_111 for ONNX node: Unsqueeze_111\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 257 for ONNX tensor: 257\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_111 [Unsqueeze] outputs: [257 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Concat_112 [Concat]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 257\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 842\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 843\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 844\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_112 [Concat] inputs: [257 -> (1)[INT32]], [842 -> (1)[INT32]], [843 -> (1)[INT32]], [844 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 842 for ONNX node: 842\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 843 for ONNX node: 843\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 844 for ONNX node: 844\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Concat_112 for ONNX node: Concat_112\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 261 for ONNX tensor: 261\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_112 [Concat] outputs: [261 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Reshape_113 [Reshape]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 253\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 261\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_113 [Reshape] inputs: [253 -> (-1, -1, 768)[FLOAT]], [261 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Reshape_113 for ONNX node: Reshape_113\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 262 for ONNX tensor: 262\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_113 [Reshape] outputs: [262 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Transpose_114 [Transpose]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 262\n",
      "[06/21/2022-18:22:01] [V] [TRT] Transpose_114 [Transpose] inputs: [262 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Transpose_114 for ONNX node: Transpose_114\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 263 for ONNX tensor: 263\n",
      "[06/21/2022-18:22:01] [V] [TRT] Transpose_114 [Transpose] outputs: [263 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: MatMul_115 [MatMul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 244\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 845\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_115 [MatMul] inputs: [244 -> (-1, -1, 768)[FLOAT]], [845 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 845 for ONNX node: 845\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: MatMul_115 for ONNX node: MatMul_115\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 265 for ONNX tensor: 265\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_115 [MatMul] outputs: [265 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_116 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.transformer.layer.1.attention.k_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 265\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_116 [Add] inputs: [distilbert.transformer.layer.1.attention.k_lin.bias -> (768)[FLOAT]], [265 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.transformer.layer.1.attention.k_lin.bias for ONNX node: distilbert.transformer.layer.1.attention.k_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_116 for ONNX node: Add_116\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 266 for ONNX tensor: 266\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_116 [Add] outputs: [266 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Unsqueeze_117 [Unsqueeze]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 247\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_117 [Unsqueeze] inputs: [247 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Unsqueeze_117 for ONNX node: Unsqueeze_117\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 270 for ONNX tensor: 270\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_117 [Unsqueeze] outputs: [270 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Concat_118 [Concat]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 270\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 846\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 847\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 848\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_118 [Concat] inputs: [270 -> (1)[INT32]], [846 -> (1)[INT32]], [847 -> (1)[INT32]], [848 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 846 for ONNX node: 846\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 847 for ONNX node: 847\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 848 for ONNX node: 848\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Concat_118 for ONNX node: Concat_118\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 274 for ONNX tensor: 274\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_118 [Concat] outputs: [274 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Reshape_119 [Reshape]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 266\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 274\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_119 [Reshape] inputs: [266 -> (-1, -1, 768)[FLOAT]], [274 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Reshape_119 for ONNX node: Reshape_119\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 275 for ONNX tensor: 275\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_119 [Reshape] outputs: [275 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: MatMul_120 [MatMul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 244\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 849\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_120 [MatMul] inputs: [244 -> (-1, -1, 768)[FLOAT]], [849 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 849 for ONNX node: 849\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: MatMul_120 for ONNX node: MatMul_120\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 277 for ONNX tensor: 277\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_120 [MatMul] outputs: [277 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_121 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.transformer.layer.1.attention.v_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 277\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_121 [Add] inputs: [distilbert.transformer.layer.1.attention.v_lin.bias -> (768)[FLOAT]], [277 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.transformer.layer.1.attention.v_lin.bias for ONNX node: distilbert.transformer.layer.1.attention.v_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_121 for ONNX node: Add_121\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 278 for ONNX tensor: 278\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_121 [Add] outputs: [278 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Unsqueeze_122 [Unsqueeze]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 247\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_122 [Unsqueeze] inputs: [247 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Unsqueeze_122 for ONNX node: Unsqueeze_122\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 282 for ONNX tensor: 282\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_122 [Unsqueeze] outputs: [282 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Concat_123 [Concat]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 282\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 850\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 851\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 852\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_123 [Concat] inputs: [282 -> (1)[INT32]], [850 -> (1)[INT32]], [851 -> (1)[INT32]], [852 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 850 for ONNX node: 850\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 851 for ONNX node: 851\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 852 for ONNX node: 852\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Concat_123 for ONNX node: Concat_123\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 286 for ONNX tensor: 286\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_123 [Concat] outputs: [286 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Reshape_124 [Reshape]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 278\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 286\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_124 [Reshape] inputs: [278 -> (-1, -1, 768)[FLOAT]], [286 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Reshape_124 for ONNX node: Reshape_124\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 287 for ONNX tensor: 287\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_124 [Reshape] outputs: [287 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Transpose_125 [Transpose]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 287\n",
      "[06/21/2022-18:22:01] [V] [TRT] Transpose_125 [Transpose] inputs: [287 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Transpose_125 for ONNX node: Transpose_125\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 288 for ONNX tensor: 288\n",
      "[06/21/2022-18:22:01] [V] [TRT] Transpose_125 [Transpose] outputs: [288 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_126 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_126 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_126 [Constant] outputs: [289 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Div_127 [Div]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 263\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 289\n",
      "[06/21/2022-18:22:01] [V] [TRT] Div_127 [Div] inputs: [263 -> (-1, 12, -1, 64)[FLOAT]], [289 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 289 for ONNX node: 289\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Div_127 for ONNX node: Div_127\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 290 for ONNX tensor: 290\n",
      "[06/21/2022-18:22:01] [V] [TRT] Div_127 [Div] outputs: [290 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Transpose_128 [Transpose]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 275\n",
      "[06/21/2022-18:22:01] [V] [TRT] Transpose_128 [Transpose] inputs: [275 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Transpose_128 for ONNX node: Transpose_128\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 291 for ONNX tensor: 291\n",
      "[06/21/2022-18:22:01] [V] [TRT] Transpose_128 [Transpose] outputs: [291 -> (-1, 12, 64, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: MatMul_129 [MatMul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 290\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 291\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_129 [MatMul] inputs: [290 -> (-1, 12, -1, 64)[FLOAT]], [291 -> (-1, 12, 64, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: MatMul_129 for ONNX node: MatMul_129\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 292 for ONNX tensor: 292\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_129 [MatMul] outputs: [292 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_130 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_130 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_130 [Constant] outputs: [293 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Equal_131 [Equal]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: attention_mask\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 293\n",
      "[06/21/2022-18:22:01] [V] [TRT] Equal_131 [Equal] inputs: [attention_mask -> (-1, -1)[INT32]], [293 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 293 for ONNX node: 293\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Equal_131 for ONNX node: Equal_131\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 294 for ONNX tensor: 294\n",
      "[06/21/2022-18:22:01] [V] [TRT] Equal_131 [Equal] outputs: [294 -> (-1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Unsqueeze_132 [Unsqueeze]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 247\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_132 [Unsqueeze] inputs: [247 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Unsqueeze_132 for ONNX node: Unsqueeze_132\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 297 for ONNX tensor: 297\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_132 [Unsqueeze] outputs: [297 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Unsqueeze_133 [Unsqueeze]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 250\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_133 [Unsqueeze] inputs: [250 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Unsqueeze_133 for ONNX node: Unsqueeze_133\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 300 for ONNX tensor: 300\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_133 [Unsqueeze] outputs: [300 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Concat_134 [Concat]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 297\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 853\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 854\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 300\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_134 [Concat] inputs: [297 -> (1)[INT32]], [853 -> (1)[INT32]], [854 -> (1)[INT32]], [300 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 853 for ONNX node: 853\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 854 for ONNX node: 854\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Concat_134 for ONNX node: Concat_134\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 301 for ONNX tensor: 301\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_134 [Concat] outputs: [301 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Reshape_135 [Reshape]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 294\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 301\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_135 [Reshape] inputs: [294 -> (-1, -1)[BOOL]], [301 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Reshape_135 for ONNX node: Reshape_135\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 302 for ONNX tensor: 302\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_135 [Reshape] outputs: [302 -> (-1, 1, 1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Shape_136 [Shape]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 292\n",
      "[06/21/2022-18:22:01] [V] [TRT] Shape_136 [Shape] inputs: [292 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Shape_136 for ONNX node: Shape_136\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 303 for ONNX tensor: 303\n",
      "[06/21/2022-18:22:01] [V] [TRT] Shape_136 [Shape] outputs: [303 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Expand_137 [Expand]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 302\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 303\n",
      "[06/21/2022-18:22:01] [V] [TRT] Expand_137 [Expand] inputs: [302 -> (-1, 1, 1, -1)[BOOL]], [303 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Expand_137 for ONNX node: Expand_137\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 304 for ONNX tensor: 304\n",
      "[06/21/2022-18:22:01] [V] [TRT] Expand_137 [Expand] outputs: [304 -> (-1, 12, -1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Cast_138 [Cast]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 304\n",
      "[06/21/2022-18:22:01] [V] [TRT] Cast_138 [Cast] inputs: [304 -> (-1, 12, -1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Casting to type: bool\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Cast_138 for ONNX node: Cast_138\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 305 for ONNX tensor: 305\n",
      "[06/21/2022-18:22:01] [V] [TRT] Cast_138 [Cast] outputs: [305 -> (-1, 12, -1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_139 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_139 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_139 [Constant] outputs: [306 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Where_140 [Where]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 305\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 306\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 292\n",
      "[06/21/2022-18:22:01] [V] [TRT] Where_140 [Where] inputs: [305 -> (-1, 12, -1, -1)[BOOL]], [306 -> ()[FLOAT]], [292 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 306 for ONNX node: 306\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Where_140 for ONNX node: Where_140\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 307 for ONNX tensor: 307\n",
      "[06/21/2022-18:22:01] [V] [TRT] Where_140 [Where] outputs: [307 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Softmax_141 [Softmax]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 307\n",
      "[06/21/2022-18:22:01] [V] [TRT] Softmax_141 [Softmax] inputs: [307 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Softmax_141 for ONNX node: Softmax_141\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 308 for ONNX tensor: 308\n",
      "[06/21/2022-18:22:01] [V] [TRT] Softmax_141 [Softmax] outputs: [308 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: MatMul_142 [MatMul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 308\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 288\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_142 [MatMul] inputs: [308 -> (-1, 12, -1, -1)[FLOAT]], [288 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: MatMul_142 for ONNX node: MatMul_142\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 309 for ONNX tensor: 309\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_142 [MatMul] outputs: [309 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Transpose_143 [Transpose]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 309\n",
      "[06/21/2022-18:22:01] [V] [TRT] Transpose_143 [Transpose] inputs: [309 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Transpose_143 for ONNX node: Transpose_143\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 310 for ONNX tensor: 310\n",
      "[06/21/2022-18:22:01] [V] [TRT] Transpose_143 [Transpose] outputs: [310 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Unsqueeze_144 [Unsqueeze]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 247\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_144 [Unsqueeze] inputs: [247 -> ()[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Unsqueeze_144 for ONNX node: Unsqueeze_144\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 313 for ONNX tensor: 313\n",
      "[06/21/2022-18:22:01] [V] [TRT] Unsqueeze_144 [Unsqueeze] outputs: [313 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Concat_145 [Concat]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 313\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 855\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 856\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_145 [Concat] inputs: [313 -> (1)[INT32]], [855 -> (1)[INT32]], [856 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 855 for ONNX node: 855\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 856 for ONNX node: 856\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Concat_145 for ONNX node: Concat_145\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 316 for ONNX tensor: 316\n",
      "[06/21/2022-18:22:01] [V] [TRT] Concat_145 [Concat] outputs: [316 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Reshape_146 [Reshape]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 310\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 316\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_146 [Reshape] inputs: [310 -> (-1, -1, 12, 64)[FLOAT]], [316 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Reshape_146 for ONNX node: Reshape_146\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 317 for ONNX tensor: 317\n",
      "[06/21/2022-18:22:01] [V] [TRT] Reshape_146 [Reshape] outputs: [317 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: MatMul_147 [MatMul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 317\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 857\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_147 [MatMul] inputs: [317 -> (-1, -1, 768)[FLOAT]], [857 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 857 for ONNX node: 857\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: MatMul_147 for ONNX node: MatMul_147\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 319 for ONNX tensor: 319\n",
      "[06/21/2022-18:22:01] [V] [TRT] MatMul_147 [MatMul] outputs: [319 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_148 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.transformer.layer.1.attention.out_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 319\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_148 [Add] inputs: [distilbert.transformer.layer.1.attention.out_lin.bias -> (768)[FLOAT]], [319 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.transformer.layer.1.attention.out_lin.bias for ONNX node: distilbert.transformer.layer.1.attention.out_lin.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_148 for ONNX node: Add_148\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 320 for ONNX tensor: 320\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_148 [Add] outputs: [320 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_149 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 320\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 244\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_149 [Add] inputs: [320 -> (-1, -1, 768)[FLOAT]], [244 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_149 for ONNX node: Add_149\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 321 for ONNX tensor: 321\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_149 [Add] outputs: [321 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: ReduceMean_150 [ReduceMean]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 321\n",
      "[06/21/2022-18:22:01] [V] [TRT] ReduceMean_150 [ReduceMean] inputs: [321 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: ReduceMean_150 for ONNX node: ReduceMean_150\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 322 for ONNX tensor: 322\n",
      "[06/21/2022-18:22:01] [V] [TRT] ReduceMean_150 [ReduceMean] outputs: [322 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Sub_151 [Sub]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 321\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 322\n",
      "[06/21/2022-18:22:01] [V] [TRT] Sub_151 [Sub] inputs: [321 -> (-1, -1, 768)[FLOAT]], [322 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Sub_151 for ONNX node: Sub_151\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 323 for ONNX tensor: 323\n",
      "[06/21/2022-18:22:01] [V] [TRT] Sub_151 [Sub] outputs: [323 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_152 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_152 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_152 [Constant] outputs: [324 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Pow_153 [Pow]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 323\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 324\n",
      "[06/21/2022-18:22:01] [V] [TRT] Pow_153 [Pow] inputs: [323 -> (-1, -1, 768)[FLOAT]], [324 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 324 for ONNX node: 324\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Pow_153 for ONNX node: Pow_153\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 325 for ONNX tensor: 325\n",
      "[06/21/2022-18:22:01] [V] [TRT] Pow_153 [Pow] outputs: [325 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: ReduceMean_154 [ReduceMean]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 325\n",
      "[06/21/2022-18:22:01] [V] [TRT] ReduceMean_154 [ReduceMean] inputs: [325 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: ReduceMean_154 for ONNX node: ReduceMean_154\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 326 for ONNX tensor: 326\n",
      "[06/21/2022-18:22:01] [V] [TRT] ReduceMean_154 [ReduceMean] outputs: [326 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Constant_155 [Constant]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_155 [Constant] inputs: \n",
      "[06/21/2022-18:22:01] [V] [TRT] Constant_155 [Constant] outputs: [327 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_156 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 326\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 327\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_156 [Add] inputs: [326 -> (-1, -1, 1)[FLOAT]], [327 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: 327 for ONNX node: 327\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_156 for ONNX node: Add_156\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 328 for ONNX tensor: 328\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_156 [Add] outputs: [328 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Sqrt_157 [Sqrt]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 328\n",
      "[06/21/2022-18:22:01] [V] [TRT] Sqrt_157 [Sqrt] inputs: [328 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Sqrt_157 for ONNX node: Sqrt_157\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 329 for ONNX tensor: 329\n",
      "[06/21/2022-18:22:01] [V] [TRT] Sqrt_157 [Sqrt] outputs: [329 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Div_158 [Div]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 323\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 329\n",
      "[06/21/2022-18:22:01] [V] [TRT] Div_158 [Div] inputs: [323 -> (-1, -1, 768)[FLOAT]], [329 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Div_158 for ONNX node: Div_158\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 330 for ONNX tensor: 330\n",
      "[06/21/2022-18:22:01] [V] [TRT] Div_158 [Div] outputs: [330 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Mul_159 [Mul]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 330\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.transformer.layer.1.sa_layer_norm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Mul_159 [Mul] inputs: [330 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.1.sa_layer_norm.weight -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.transformer.layer.1.sa_layer_norm.weight for ONNX node: distilbert.transformer.layer.1.sa_layer_norm.weight\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Mul_159 for ONNX node: Mul_159\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering tensor: 331 for ONNX tensor: 331\n",
      "[06/21/2022-18:22:01] [V] [TRT] Mul_159 [Mul] outputs: [331 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Parsing node: Add_160 [Add]\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: 331\n",
      "[06/21/2022-18:22:01] [V] [TRT] Searching for input: distilbert.transformer.layer.1.sa_layer_norm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Add_160 [Add] inputs: [331 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.1.sa_layer_norm.bias -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: distilbert.transformer.layer.1.sa_layer_norm.bias for ONNX node: distilbert.transformer.layer.1.sa_layer_norm.bias\n",
      "[06/21/2022-18:22:01] [V] [TRT] Registering layer: Add_160 for ONNX node: Add_160\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 332 for ONNX tensor: 332\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_160 [Add] outputs: [332 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_161 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 332\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 858\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_161 [MatMul] inputs: [332 -> (-1, -1, 768)[FLOAT]], [858 -> (768, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 858 for ONNX node: 858\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_161 for ONNX node: MatMul_161\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 334 for ONNX tensor: 334\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_161 [MatMul] outputs: [334 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_162 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.1.ffn.lin1.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 334\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_162 [Add] inputs: [distilbert.transformer.layer.1.ffn.lin1.bias -> (3072)[FLOAT]], [334 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.1.ffn.lin1.bias for ONNX node: distilbert.transformer.layer.1.ffn.lin1.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_162 for ONNX node: Add_162\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 335 for ONNX tensor: 335\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_162 [Add] outputs: [335 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_163 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_163 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_163 [Constant] outputs: [336 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Div_164 [Div]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 335\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 336\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_164 [Div] inputs: [335 -> (-1, -1, 3072)[FLOAT]], [336 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 336 for ONNX node: 336\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Div_164 for ONNX node: Div_164\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 337 for ONNX tensor: 337\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_164 [Div] outputs: [337 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Erf_165 [Erf]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 337\n",
      "[06/21/2022-18:22:02] [V] [TRT] Erf_165 [Erf] inputs: [337 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Erf_165 for ONNX node: Erf_165\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 338 for ONNX tensor: 338\n",
      "[06/21/2022-18:22:02] [V] [TRT] Erf_165 [Erf] outputs: [338 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_166 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_166 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_166 [Constant] outputs: [339 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_167 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 338\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 339\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_167 [Add] inputs: [338 -> (-1, -1, 3072)[FLOAT]], [339 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 339 for ONNX node: 339\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_167 for ONNX node: Add_167\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 340 for ONNX tensor: 340\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_167 [Add] outputs: [340 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_168 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 335\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 340\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_168 [Mul] inputs: [335 -> (-1, -1, 3072)[FLOAT]], [340 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_168 for ONNX node: Mul_168\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 341 for ONNX tensor: 341\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_168 [Mul] outputs: [341 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_169 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_169 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_169 [Constant] outputs: [342 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_170 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 341\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 342\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_170 [Mul] inputs: [341 -> (-1, -1, 3072)[FLOAT]], [342 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 342 for ONNX node: 342\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_170 for ONNX node: Mul_170\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 343 for ONNX tensor: 343\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_170 [Mul] outputs: [343 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_171 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 343\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 859\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_171 [MatMul] inputs: [343 -> (-1, -1, 3072)[FLOAT]], [859 -> (3072, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 859 for ONNX node: 859\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_171 for ONNX node: MatMul_171\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 345 for ONNX tensor: 345\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_171 [MatMul] outputs: [345 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_172 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.1.ffn.lin2.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 345\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_172 [Add] inputs: [distilbert.transformer.layer.1.ffn.lin2.bias -> (768)[FLOAT]], [345 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.1.ffn.lin2.bias for ONNX node: distilbert.transformer.layer.1.ffn.lin2.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_172 for ONNX node: Add_172\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 346 for ONNX tensor: 346\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_172 [Add] outputs: [346 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_173 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 346\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 332\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_173 [Add] inputs: [346 -> (-1, -1, 768)[FLOAT]], [332 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_173 for ONNX node: Add_173\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 347 for ONNX tensor: 347\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_173 [Add] outputs: [347 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: ReduceMean_174 [ReduceMean]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 347\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_174 [ReduceMean] inputs: [347 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: ReduceMean_174 for ONNX node: ReduceMean_174\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 348 for ONNX tensor: 348\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_174 [ReduceMean] outputs: [348 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Sub_175 [Sub]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 347\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 348\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sub_175 [Sub] inputs: [347 -> (-1, -1, 768)[FLOAT]], [348 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Sub_175 for ONNX node: Sub_175\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 349 for ONNX tensor: 349\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sub_175 [Sub] outputs: [349 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_176 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_176 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_176 [Constant] outputs: [350 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Pow_177 [Pow]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 349\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 350\n",
      "[06/21/2022-18:22:02] [V] [TRT] Pow_177 [Pow] inputs: [349 -> (-1, -1, 768)[FLOAT]], [350 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 350 for ONNX node: 350\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Pow_177 for ONNX node: Pow_177\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 351 for ONNX tensor: 351\n",
      "[06/21/2022-18:22:02] [V] [TRT] Pow_177 [Pow] outputs: [351 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: ReduceMean_178 [ReduceMean]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 351\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_178 [ReduceMean] inputs: [351 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: ReduceMean_178 for ONNX node: ReduceMean_178\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 352 for ONNX tensor: 352\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_178 [ReduceMean] outputs: [352 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_179 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_179 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_179 [Constant] outputs: [353 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_180 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 352\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 353\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_180 [Add] inputs: [352 -> (-1, -1, 1)[FLOAT]], [353 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 353 for ONNX node: 353\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_180 for ONNX node: Add_180\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 354 for ONNX tensor: 354\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_180 [Add] outputs: [354 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Sqrt_181 [Sqrt]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 354\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sqrt_181 [Sqrt] inputs: [354 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Sqrt_181 for ONNX node: Sqrt_181\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 355 for ONNX tensor: 355\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sqrt_181 [Sqrt] outputs: [355 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Div_182 [Div]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 349\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 355\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_182 [Div] inputs: [349 -> (-1, -1, 768)[FLOAT]], [355 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Div_182 for ONNX node: Div_182\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 356 for ONNX tensor: 356\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_182 [Div] outputs: [356 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_183 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 356\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.1.output_layer_norm.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_183 [Mul] inputs: [356 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.1.output_layer_norm.weight -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.1.output_layer_norm.weight for ONNX node: distilbert.transformer.layer.1.output_layer_norm.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_183 for ONNX node: Mul_183\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 357 for ONNX tensor: 357\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_183 [Mul] outputs: [357 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_184 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 357\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.1.output_layer_norm.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_184 [Add] inputs: [357 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.1.output_layer_norm.bias -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.1.output_layer_norm.bias for ONNX node: distilbert.transformer.layer.1.output_layer_norm.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_184 for ONNX node: Add_184\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 358 for ONNX tensor: 358\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_184 [Add] outputs: [358 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Shape_185 [Shape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 358\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_185 [Shape] inputs: [358 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Shape_185 for ONNX node: Shape_185\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 359 for ONNX tensor: 359\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_185 [Shape] outputs: [359 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_186 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_186 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_186 [Constant] outputs: [360 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Gather_187 [Gather]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 359\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 360\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gather_187 [Gather] inputs: [359 -> (3)[INT32]], [360 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 360 for ONNX node: 360\n",
      "[06/21/2022-18:22:02] [V] [TRT] Using Gather axis: 0\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Gather_187 for ONNX node: Gather_187\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 361 for ONNX tensor: 361\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gather_187 [Gather] outputs: [361 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Shape_188 [Shape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 358\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_188 [Shape] inputs: [358 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Shape_188 for ONNX node: Shape_188\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 362 for ONNX tensor: 362\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_188 [Shape] outputs: [362 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_189 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_189 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_189 [Constant] outputs: [363 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Gather_190 [Gather]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 362\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 363\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gather_190 [Gather] inputs: [362 -> (3)[INT32]], [363 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 363 for ONNX node: 363\n",
      "[06/21/2022-18:22:02] [V] [TRT] Using Gather axis: 0\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Gather_190 for ONNX node: Gather_190\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 364 for ONNX tensor: 364\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gather_190 [Gather] outputs: [364 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_191 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 358\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 860\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_191 [MatMul] inputs: [358 -> (-1, -1, 768)[FLOAT]], [860 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 860 for ONNX node: 860\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_191 for ONNX node: MatMul_191\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 366 for ONNX tensor: 366\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_191 [MatMul] outputs: [366 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_192 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.2.attention.q_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 366\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_192 [Add] inputs: [distilbert.transformer.layer.2.attention.q_lin.bias -> (768)[FLOAT]], [366 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.2.attention.q_lin.bias for ONNX node: distilbert.transformer.layer.2.attention.q_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_192 for ONNX node: Add_192\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 367 for ONNX tensor: 367\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_192 [Add] outputs: [367 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_193 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 361\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_193 [Unsqueeze] inputs: [361 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_193 for ONNX node: Unsqueeze_193\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 371 for ONNX tensor: 371\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_193 [Unsqueeze] outputs: [371 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_194 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 371\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 861\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 862\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 863\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_194 [Concat] inputs: [371 -> (1)[INT32]], [861 -> (1)[INT32]], [862 -> (1)[INT32]], [863 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 861 for ONNX node: 861\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 862 for ONNX node: 862\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 863 for ONNX node: 863\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_194 for ONNX node: Concat_194\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 375 for ONNX tensor: 375\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_194 [Concat] outputs: [375 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_195 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 367\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 375\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_195 [Reshape] inputs: [367 -> (-1, -1, 768)[FLOAT]], [375 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_195 for ONNX node: Reshape_195\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 376 for ONNX tensor: 376\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_195 [Reshape] outputs: [376 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Transpose_196 [Transpose]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 376\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_196 [Transpose] inputs: [376 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Transpose_196 for ONNX node: Transpose_196\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 377 for ONNX tensor: 377\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_196 [Transpose] outputs: [377 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_197 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 358\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 864\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_197 [MatMul] inputs: [358 -> (-1, -1, 768)[FLOAT]], [864 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 864 for ONNX node: 864\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_197 for ONNX node: MatMul_197\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 379 for ONNX tensor: 379\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_197 [MatMul] outputs: [379 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_198 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.2.attention.k_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 379\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_198 [Add] inputs: [distilbert.transformer.layer.2.attention.k_lin.bias -> (768)[FLOAT]], [379 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.2.attention.k_lin.bias for ONNX node: distilbert.transformer.layer.2.attention.k_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_198 for ONNX node: Add_198\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 380 for ONNX tensor: 380\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_198 [Add] outputs: [380 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_199 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 361\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_199 [Unsqueeze] inputs: [361 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_199 for ONNX node: Unsqueeze_199\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 384 for ONNX tensor: 384\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_199 [Unsqueeze] outputs: [384 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_200 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 384\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 865\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 866\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 867\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_200 [Concat] inputs: [384 -> (1)[INT32]], [865 -> (1)[INT32]], [866 -> (1)[INT32]], [867 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 865 for ONNX node: 865\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 866 for ONNX node: 866\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 867 for ONNX node: 867\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_200 for ONNX node: Concat_200\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 388 for ONNX tensor: 388\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_200 [Concat] outputs: [388 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_201 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 380\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 388\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_201 [Reshape] inputs: [380 -> (-1, -1, 768)[FLOAT]], [388 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_201 for ONNX node: Reshape_201\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 389 for ONNX tensor: 389\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_201 [Reshape] outputs: [389 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_202 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 358\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 868\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_202 [MatMul] inputs: [358 -> (-1, -1, 768)[FLOAT]], [868 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 868 for ONNX node: 868\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_202 for ONNX node: MatMul_202\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 391 for ONNX tensor: 391\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_202 [MatMul] outputs: [391 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_203 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.2.attention.v_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 391\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_203 [Add] inputs: [distilbert.transformer.layer.2.attention.v_lin.bias -> (768)[FLOAT]], [391 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.2.attention.v_lin.bias for ONNX node: distilbert.transformer.layer.2.attention.v_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_203 for ONNX node: Add_203\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 392 for ONNX tensor: 392\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_203 [Add] outputs: [392 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_204 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 361\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_204 [Unsqueeze] inputs: [361 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_204 for ONNX node: Unsqueeze_204\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 396 for ONNX tensor: 396\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_204 [Unsqueeze] outputs: [396 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_205 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 396\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 869\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 870\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 871\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_205 [Concat] inputs: [396 -> (1)[INT32]], [869 -> (1)[INT32]], [870 -> (1)[INT32]], [871 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 869 for ONNX node: 869\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 870 for ONNX node: 870\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 871 for ONNX node: 871\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_205 for ONNX node: Concat_205\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 400 for ONNX tensor: 400\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_205 [Concat] outputs: [400 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_206 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 392\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 400\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_206 [Reshape] inputs: [392 -> (-1, -1, 768)[FLOAT]], [400 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_206 for ONNX node: Reshape_206\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 401 for ONNX tensor: 401\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_206 [Reshape] outputs: [401 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Transpose_207 [Transpose]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 401\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_207 [Transpose] inputs: [401 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Transpose_207 for ONNX node: Transpose_207\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 402 for ONNX tensor: 402\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_207 [Transpose] outputs: [402 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_208 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_208 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_208 [Constant] outputs: [403 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Div_209 [Div]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 377\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 403\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_209 [Div] inputs: [377 -> (-1, 12, -1, 64)[FLOAT]], [403 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 403 for ONNX node: 403\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Div_209 for ONNX node: Div_209\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 404 for ONNX tensor: 404\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_209 [Div] outputs: [404 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Transpose_210 [Transpose]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 389\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_210 [Transpose] inputs: [389 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Transpose_210 for ONNX node: Transpose_210\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 405 for ONNX tensor: 405\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_210 [Transpose] outputs: [405 -> (-1, 12, 64, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_211 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 404\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 405\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_211 [MatMul] inputs: [404 -> (-1, 12, -1, 64)[FLOAT]], [405 -> (-1, 12, 64, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_211 for ONNX node: MatMul_211\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 406 for ONNX tensor: 406\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_211 [MatMul] outputs: [406 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_212 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_212 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_212 [Constant] outputs: [407 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Equal_213 [Equal]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: attention_mask\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 407\n",
      "[06/21/2022-18:22:02] [V] [TRT] Equal_213 [Equal] inputs: [attention_mask -> (-1, -1)[INT32]], [407 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 407 for ONNX node: 407\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Equal_213 for ONNX node: Equal_213\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 408 for ONNX tensor: 408\n",
      "[06/21/2022-18:22:02] [V] [TRT] Equal_213 [Equal] outputs: [408 -> (-1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_214 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 361\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_214 [Unsqueeze] inputs: [361 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_214 for ONNX node: Unsqueeze_214\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 411 for ONNX tensor: 411\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_214 [Unsqueeze] outputs: [411 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_215 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 364\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_215 [Unsqueeze] inputs: [364 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_215 for ONNX node: Unsqueeze_215\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 414 for ONNX tensor: 414\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_215 [Unsqueeze] outputs: [414 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_216 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 411\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 872\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 873\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 414\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_216 [Concat] inputs: [411 -> (1)[INT32]], [872 -> (1)[INT32]], [873 -> (1)[INT32]], [414 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 872 for ONNX node: 872\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 873 for ONNX node: 873\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_216 for ONNX node: Concat_216\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 415 for ONNX tensor: 415\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_216 [Concat] outputs: [415 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_217 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 408\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 415\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_217 [Reshape] inputs: [408 -> (-1, -1)[BOOL]], [415 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_217 for ONNX node: Reshape_217\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 416 for ONNX tensor: 416\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_217 [Reshape] outputs: [416 -> (-1, 1, 1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Shape_218 [Shape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 406\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_218 [Shape] inputs: [406 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Shape_218 for ONNX node: Shape_218\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 417 for ONNX tensor: 417\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_218 [Shape] outputs: [417 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Expand_219 [Expand]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 416\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 417\n",
      "[06/21/2022-18:22:02] [V] [TRT] Expand_219 [Expand] inputs: [416 -> (-1, 1, 1, -1)[BOOL]], [417 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Expand_219 for ONNX node: Expand_219\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 418 for ONNX tensor: 418\n",
      "[06/21/2022-18:22:02] [V] [TRT] Expand_219 [Expand] outputs: [418 -> (-1, 12, -1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Cast_220 [Cast]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 418\n",
      "[06/21/2022-18:22:02] [V] [TRT] Cast_220 [Cast] inputs: [418 -> (-1, 12, -1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Casting to type: bool\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Cast_220 for ONNX node: Cast_220\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 419 for ONNX tensor: 419\n",
      "[06/21/2022-18:22:02] [V] [TRT] Cast_220 [Cast] outputs: [419 -> (-1, 12, -1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_221 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_221 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_221 [Constant] outputs: [420 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Where_222 [Where]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 419\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 420\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 406\n",
      "[06/21/2022-18:22:02] [V] [TRT] Where_222 [Where] inputs: [419 -> (-1, 12, -1, -1)[BOOL]], [420 -> ()[FLOAT]], [406 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 420 for ONNX node: 420\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Where_222 for ONNX node: Where_222\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 421 for ONNX tensor: 421\n",
      "[06/21/2022-18:22:02] [V] [TRT] Where_222 [Where] outputs: [421 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Softmax_223 [Softmax]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 421\n",
      "[06/21/2022-18:22:02] [V] [TRT] Softmax_223 [Softmax] inputs: [421 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Softmax_223 for ONNX node: Softmax_223\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 422 for ONNX tensor: 422\n",
      "[06/21/2022-18:22:02] [V] [TRT] Softmax_223 [Softmax] outputs: [422 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_224 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 422\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 402\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_224 [MatMul] inputs: [422 -> (-1, 12, -1, -1)[FLOAT]], [402 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_224 for ONNX node: MatMul_224\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 423 for ONNX tensor: 423\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_224 [MatMul] outputs: [423 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Transpose_225 [Transpose]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 423\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_225 [Transpose] inputs: [423 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Transpose_225 for ONNX node: Transpose_225\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 424 for ONNX tensor: 424\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_225 [Transpose] outputs: [424 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_226 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 361\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_226 [Unsqueeze] inputs: [361 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_226 for ONNX node: Unsqueeze_226\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 427 for ONNX tensor: 427\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_226 [Unsqueeze] outputs: [427 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_227 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 427\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 874\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 875\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_227 [Concat] inputs: [427 -> (1)[INT32]], [874 -> (1)[INT32]], [875 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 874 for ONNX node: 874\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 875 for ONNX node: 875\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_227 for ONNX node: Concat_227\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 430 for ONNX tensor: 430\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_227 [Concat] outputs: [430 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_228 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 424\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 430\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_228 [Reshape] inputs: [424 -> (-1, -1, 12, 64)[FLOAT]], [430 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_228 for ONNX node: Reshape_228\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 431 for ONNX tensor: 431\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_228 [Reshape] outputs: [431 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_229 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 431\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 876\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_229 [MatMul] inputs: [431 -> (-1, -1, 768)[FLOAT]], [876 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 876 for ONNX node: 876\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_229 for ONNX node: MatMul_229\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 433 for ONNX tensor: 433\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_229 [MatMul] outputs: [433 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_230 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.2.attention.out_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 433\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_230 [Add] inputs: [distilbert.transformer.layer.2.attention.out_lin.bias -> (768)[FLOAT]], [433 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.2.attention.out_lin.bias for ONNX node: distilbert.transformer.layer.2.attention.out_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_230 for ONNX node: Add_230\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 434 for ONNX tensor: 434\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_230 [Add] outputs: [434 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_231 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 434\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 358\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_231 [Add] inputs: [434 -> (-1, -1, 768)[FLOAT]], [358 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_231 for ONNX node: Add_231\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 435 for ONNX tensor: 435\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_231 [Add] outputs: [435 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: ReduceMean_232 [ReduceMean]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 435\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_232 [ReduceMean] inputs: [435 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: ReduceMean_232 for ONNX node: ReduceMean_232\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 436 for ONNX tensor: 436\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_232 [ReduceMean] outputs: [436 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Sub_233 [Sub]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 435\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 436\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sub_233 [Sub] inputs: [435 -> (-1, -1, 768)[FLOAT]], [436 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Sub_233 for ONNX node: Sub_233\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 437 for ONNX tensor: 437\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sub_233 [Sub] outputs: [437 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_234 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_234 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_234 [Constant] outputs: [438 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Pow_235 [Pow]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 437\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 438\n",
      "[06/21/2022-18:22:02] [V] [TRT] Pow_235 [Pow] inputs: [437 -> (-1, -1, 768)[FLOAT]], [438 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 438 for ONNX node: 438\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Pow_235 for ONNX node: Pow_235\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 439 for ONNX tensor: 439\n",
      "[06/21/2022-18:22:02] [V] [TRT] Pow_235 [Pow] outputs: [439 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: ReduceMean_236 [ReduceMean]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 439\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_236 [ReduceMean] inputs: [439 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: ReduceMean_236 for ONNX node: ReduceMean_236\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 440 for ONNX tensor: 440\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_236 [ReduceMean] outputs: [440 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_237 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_237 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_237 [Constant] outputs: [441 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_238 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 440\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 441\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_238 [Add] inputs: [440 -> (-1, -1, 1)[FLOAT]], [441 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 441 for ONNX node: 441\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_238 for ONNX node: Add_238\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 442 for ONNX tensor: 442\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_238 [Add] outputs: [442 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Sqrt_239 [Sqrt]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 442\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sqrt_239 [Sqrt] inputs: [442 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Sqrt_239 for ONNX node: Sqrt_239\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 443 for ONNX tensor: 443\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sqrt_239 [Sqrt] outputs: [443 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Div_240 [Div]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 437\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 443\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_240 [Div] inputs: [437 -> (-1, -1, 768)[FLOAT]], [443 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Div_240 for ONNX node: Div_240\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 444 for ONNX tensor: 444\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_240 [Div] outputs: [444 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_241 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 444\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.2.sa_layer_norm.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_241 [Mul] inputs: [444 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.2.sa_layer_norm.weight -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.2.sa_layer_norm.weight for ONNX node: distilbert.transformer.layer.2.sa_layer_norm.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_241 for ONNX node: Mul_241\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 445 for ONNX tensor: 445\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_241 [Mul] outputs: [445 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_242 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 445\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.2.sa_layer_norm.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_242 [Add] inputs: [445 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.2.sa_layer_norm.bias -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.2.sa_layer_norm.bias for ONNX node: distilbert.transformer.layer.2.sa_layer_norm.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_242 for ONNX node: Add_242\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 446 for ONNX tensor: 446\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_242 [Add] outputs: [446 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_243 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 446\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 877\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_243 [MatMul] inputs: [446 -> (-1, -1, 768)[FLOAT]], [877 -> (768, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 877 for ONNX node: 877\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_243 for ONNX node: MatMul_243\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 448 for ONNX tensor: 448\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_243 [MatMul] outputs: [448 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_244 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.2.ffn.lin1.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 448\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_244 [Add] inputs: [distilbert.transformer.layer.2.ffn.lin1.bias -> (3072)[FLOAT]], [448 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.2.ffn.lin1.bias for ONNX node: distilbert.transformer.layer.2.ffn.lin1.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_244 for ONNX node: Add_244\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 449 for ONNX tensor: 449\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_244 [Add] outputs: [449 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_245 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_245 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_245 [Constant] outputs: [450 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Div_246 [Div]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 449\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 450\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_246 [Div] inputs: [449 -> (-1, -1, 3072)[FLOAT]], [450 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 450 for ONNX node: 450\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Div_246 for ONNX node: Div_246\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 451 for ONNX tensor: 451\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_246 [Div] outputs: [451 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Erf_247 [Erf]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 451\n",
      "[06/21/2022-18:22:02] [V] [TRT] Erf_247 [Erf] inputs: [451 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Erf_247 for ONNX node: Erf_247\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 452 for ONNX tensor: 452\n",
      "[06/21/2022-18:22:02] [V] [TRT] Erf_247 [Erf] outputs: [452 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_248 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_248 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_248 [Constant] outputs: [453 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_249 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 452\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 453\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_249 [Add] inputs: [452 -> (-1, -1, 3072)[FLOAT]], [453 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 453 for ONNX node: 453\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_249 for ONNX node: Add_249\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 454 for ONNX tensor: 454\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_249 [Add] outputs: [454 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_250 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 449\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 454\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_250 [Mul] inputs: [449 -> (-1, -1, 3072)[FLOAT]], [454 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_250 for ONNX node: Mul_250\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 455 for ONNX tensor: 455\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_250 [Mul] outputs: [455 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_251 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_251 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_251 [Constant] outputs: [456 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_252 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 455\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 456\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_252 [Mul] inputs: [455 -> (-1, -1, 3072)[FLOAT]], [456 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 456 for ONNX node: 456\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_252 for ONNX node: Mul_252\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 457 for ONNX tensor: 457\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_252 [Mul] outputs: [457 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_253 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 457\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 878\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_253 [MatMul] inputs: [457 -> (-1, -1, 3072)[FLOAT]], [878 -> (3072, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 878 for ONNX node: 878\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_253 for ONNX node: MatMul_253\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 459 for ONNX tensor: 459\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_253 [MatMul] outputs: [459 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_254 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.2.ffn.lin2.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 459\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_254 [Add] inputs: [distilbert.transformer.layer.2.ffn.lin2.bias -> (768)[FLOAT]], [459 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.2.ffn.lin2.bias for ONNX node: distilbert.transformer.layer.2.ffn.lin2.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_254 for ONNX node: Add_254\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 460 for ONNX tensor: 460\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_254 [Add] outputs: [460 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_255 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 460\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 446\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_255 [Add] inputs: [460 -> (-1, -1, 768)[FLOAT]], [446 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_255 for ONNX node: Add_255\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 461 for ONNX tensor: 461\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_255 [Add] outputs: [461 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: ReduceMean_256 [ReduceMean]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 461\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_256 [ReduceMean] inputs: [461 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: ReduceMean_256 for ONNX node: ReduceMean_256\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 462 for ONNX tensor: 462\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_256 [ReduceMean] outputs: [462 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Sub_257 [Sub]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 461\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 462\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sub_257 [Sub] inputs: [461 -> (-1, -1, 768)[FLOAT]], [462 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Sub_257 for ONNX node: Sub_257\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 463 for ONNX tensor: 463\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sub_257 [Sub] outputs: [463 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_258 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_258 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_258 [Constant] outputs: [464 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Pow_259 [Pow]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 463\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 464\n",
      "[06/21/2022-18:22:02] [V] [TRT] Pow_259 [Pow] inputs: [463 -> (-1, -1, 768)[FLOAT]], [464 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 464 for ONNX node: 464\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Pow_259 for ONNX node: Pow_259\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 465 for ONNX tensor: 465\n",
      "[06/21/2022-18:22:02] [V] [TRT] Pow_259 [Pow] outputs: [465 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: ReduceMean_260 [ReduceMean]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 465\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_260 [ReduceMean] inputs: [465 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: ReduceMean_260 for ONNX node: ReduceMean_260\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 466 for ONNX tensor: 466\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_260 [ReduceMean] outputs: [466 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_261 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_261 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_261 [Constant] outputs: [467 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_262 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 466\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 467\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_262 [Add] inputs: [466 -> (-1, -1, 1)[FLOAT]], [467 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 467 for ONNX node: 467\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_262 for ONNX node: Add_262\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 468 for ONNX tensor: 468\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_262 [Add] outputs: [468 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Sqrt_263 [Sqrt]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 468\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sqrt_263 [Sqrt] inputs: [468 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Sqrt_263 for ONNX node: Sqrt_263\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 469 for ONNX tensor: 469\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sqrt_263 [Sqrt] outputs: [469 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Div_264 [Div]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 463\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 469\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_264 [Div] inputs: [463 -> (-1, -1, 768)[FLOAT]], [469 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Div_264 for ONNX node: Div_264\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 470 for ONNX tensor: 470\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_264 [Div] outputs: [470 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_265 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 470\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.2.output_layer_norm.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_265 [Mul] inputs: [470 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.2.output_layer_norm.weight -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.2.output_layer_norm.weight for ONNX node: distilbert.transformer.layer.2.output_layer_norm.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_265 for ONNX node: Mul_265\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 471 for ONNX tensor: 471\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_265 [Mul] outputs: [471 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_266 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 471\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.2.output_layer_norm.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_266 [Add] inputs: [471 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.2.output_layer_norm.bias -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.2.output_layer_norm.bias for ONNX node: distilbert.transformer.layer.2.output_layer_norm.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_266 for ONNX node: Add_266\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 472 for ONNX tensor: 472\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_266 [Add] outputs: [472 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Shape_267 [Shape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 472\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_267 [Shape] inputs: [472 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Shape_267 for ONNX node: Shape_267\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 473 for ONNX tensor: 473\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_267 [Shape] outputs: [473 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_268 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_268 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_268 [Constant] outputs: [474 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Gather_269 [Gather]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 473\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 474\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gather_269 [Gather] inputs: [473 -> (3)[INT32]], [474 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 474 for ONNX node: 474\n",
      "[06/21/2022-18:22:02] [V] [TRT] Using Gather axis: 0\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Gather_269 for ONNX node: Gather_269\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 475 for ONNX tensor: 475\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gather_269 [Gather] outputs: [475 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Shape_270 [Shape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 472\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_270 [Shape] inputs: [472 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Shape_270 for ONNX node: Shape_270\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 476 for ONNX tensor: 476\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_270 [Shape] outputs: [476 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_271 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_271 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_271 [Constant] outputs: [477 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Gather_272 [Gather]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 476\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 477\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gather_272 [Gather] inputs: [476 -> (3)[INT32]], [477 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 477 for ONNX node: 477\n",
      "[06/21/2022-18:22:02] [V] [TRT] Using Gather axis: 0\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Gather_272 for ONNX node: Gather_272\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 478 for ONNX tensor: 478\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gather_272 [Gather] outputs: [478 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_273 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 472\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 879\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_273 [MatMul] inputs: [472 -> (-1, -1, 768)[FLOAT]], [879 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 879 for ONNX node: 879\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_273 for ONNX node: MatMul_273\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 480 for ONNX tensor: 480\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_273 [MatMul] outputs: [480 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_274 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.3.attention.q_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 480\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_274 [Add] inputs: [distilbert.transformer.layer.3.attention.q_lin.bias -> (768)[FLOAT]], [480 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.3.attention.q_lin.bias for ONNX node: distilbert.transformer.layer.3.attention.q_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_274 for ONNX node: Add_274\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 481 for ONNX tensor: 481\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_274 [Add] outputs: [481 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_275 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 475\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_275 [Unsqueeze] inputs: [475 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_275 for ONNX node: Unsqueeze_275\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 485 for ONNX tensor: 485\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_275 [Unsqueeze] outputs: [485 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_276 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 485\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 880\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 881\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 882\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_276 [Concat] inputs: [485 -> (1)[INT32]], [880 -> (1)[INT32]], [881 -> (1)[INT32]], [882 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 880 for ONNX node: 880\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 881 for ONNX node: 881\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 882 for ONNX node: 882\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_276 for ONNX node: Concat_276\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 489 for ONNX tensor: 489\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_276 [Concat] outputs: [489 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_277 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 481\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 489\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_277 [Reshape] inputs: [481 -> (-1, -1, 768)[FLOAT]], [489 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_277 for ONNX node: Reshape_277\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 490 for ONNX tensor: 490\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_277 [Reshape] outputs: [490 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Transpose_278 [Transpose]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 490\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_278 [Transpose] inputs: [490 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Transpose_278 for ONNX node: Transpose_278\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 491 for ONNX tensor: 491\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_278 [Transpose] outputs: [491 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_279 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 472\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 883\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_279 [MatMul] inputs: [472 -> (-1, -1, 768)[FLOAT]], [883 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 883 for ONNX node: 883\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_279 for ONNX node: MatMul_279\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 493 for ONNX tensor: 493\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_279 [MatMul] outputs: [493 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_280 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.3.attention.k_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 493\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_280 [Add] inputs: [distilbert.transformer.layer.3.attention.k_lin.bias -> (768)[FLOAT]], [493 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.3.attention.k_lin.bias for ONNX node: distilbert.transformer.layer.3.attention.k_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_280 for ONNX node: Add_280\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 494 for ONNX tensor: 494\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_280 [Add] outputs: [494 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_281 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 475\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_281 [Unsqueeze] inputs: [475 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_281 for ONNX node: Unsqueeze_281\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 498 for ONNX tensor: 498\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_281 [Unsqueeze] outputs: [498 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_282 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 498\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 884\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 885\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 886\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_282 [Concat] inputs: [498 -> (1)[INT32]], [884 -> (1)[INT32]], [885 -> (1)[INT32]], [886 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 884 for ONNX node: 884\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 885 for ONNX node: 885\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 886 for ONNX node: 886\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_282 for ONNX node: Concat_282\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 502 for ONNX tensor: 502\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_282 [Concat] outputs: [502 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_283 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 494\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 502\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_283 [Reshape] inputs: [494 -> (-1, -1, 768)[FLOAT]], [502 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_283 for ONNX node: Reshape_283\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 503 for ONNX tensor: 503\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_283 [Reshape] outputs: [503 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_284 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 472\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 887\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_284 [MatMul] inputs: [472 -> (-1, -1, 768)[FLOAT]], [887 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 887 for ONNX node: 887\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_284 for ONNX node: MatMul_284\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 505 for ONNX tensor: 505\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_284 [MatMul] outputs: [505 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_285 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.3.attention.v_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 505\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_285 [Add] inputs: [distilbert.transformer.layer.3.attention.v_lin.bias -> (768)[FLOAT]], [505 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.3.attention.v_lin.bias for ONNX node: distilbert.transformer.layer.3.attention.v_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_285 for ONNX node: Add_285\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 506 for ONNX tensor: 506\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_285 [Add] outputs: [506 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_286 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 475\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_286 [Unsqueeze] inputs: [475 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_286 for ONNX node: Unsqueeze_286\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 510 for ONNX tensor: 510\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_286 [Unsqueeze] outputs: [510 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_287 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 510\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 888\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 889\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 890\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_287 [Concat] inputs: [510 -> (1)[INT32]], [888 -> (1)[INT32]], [889 -> (1)[INT32]], [890 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 888 for ONNX node: 888\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 889 for ONNX node: 889\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 890 for ONNX node: 890\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_287 for ONNX node: Concat_287\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 514 for ONNX tensor: 514\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_287 [Concat] outputs: [514 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_288 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 506\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 514\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_288 [Reshape] inputs: [506 -> (-1, -1, 768)[FLOAT]], [514 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_288 for ONNX node: Reshape_288\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 515 for ONNX tensor: 515\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_288 [Reshape] outputs: [515 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Transpose_289 [Transpose]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 515\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_289 [Transpose] inputs: [515 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Transpose_289 for ONNX node: Transpose_289\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 516 for ONNX tensor: 516\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_289 [Transpose] outputs: [516 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_290 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_290 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_290 [Constant] outputs: [517 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Div_291 [Div]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 491\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 517\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_291 [Div] inputs: [491 -> (-1, 12, -1, 64)[FLOAT]], [517 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 517 for ONNX node: 517\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Div_291 for ONNX node: Div_291\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 518 for ONNX tensor: 518\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_291 [Div] outputs: [518 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Transpose_292 [Transpose]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 503\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_292 [Transpose] inputs: [503 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Transpose_292 for ONNX node: Transpose_292\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 519 for ONNX tensor: 519\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_292 [Transpose] outputs: [519 -> (-1, 12, 64, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_293 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 518\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 519\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_293 [MatMul] inputs: [518 -> (-1, 12, -1, 64)[FLOAT]], [519 -> (-1, 12, 64, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_293 for ONNX node: MatMul_293\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 520 for ONNX tensor: 520\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_293 [MatMul] outputs: [520 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_294 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_294 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_294 [Constant] outputs: [521 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Equal_295 [Equal]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: attention_mask\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 521\n",
      "[06/21/2022-18:22:02] [V] [TRT] Equal_295 [Equal] inputs: [attention_mask -> (-1, -1)[INT32]], [521 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 521 for ONNX node: 521\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Equal_295 for ONNX node: Equal_295\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 522 for ONNX tensor: 522\n",
      "[06/21/2022-18:22:02] [V] [TRT] Equal_295 [Equal] outputs: [522 -> (-1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_296 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 475\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_296 [Unsqueeze] inputs: [475 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_296 for ONNX node: Unsqueeze_296\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 525 for ONNX tensor: 525\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_296 [Unsqueeze] outputs: [525 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_297 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 478\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_297 [Unsqueeze] inputs: [478 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_297 for ONNX node: Unsqueeze_297\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 528 for ONNX tensor: 528\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_297 [Unsqueeze] outputs: [528 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_298 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 525\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 891\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 892\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 528\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_298 [Concat] inputs: [525 -> (1)[INT32]], [891 -> (1)[INT32]], [892 -> (1)[INT32]], [528 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 891 for ONNX node: 891\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 892 for ONNX node: 892\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_298 for ONNX node: Concat_298\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 529 for ONNX tensor: 529\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_298 [Concat] outputs: [529 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_299 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 522\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 529\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_299 [Reshape] inputs: [522 -> (-1, -1)[BOOL]], [529 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_299 for ONNX node: Reshape_299\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 530 for ONNX tensor: 530\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_299 [Reshape] outputs: [530 -> (-1, 1, 1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Shape_300 [Shape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 520\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_300 [Shape] inputs: [520 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Shape_300 for ONNX node: Shape_300\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 531 for ONNX tensor: 531\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_300 [Shape] outputs: [531 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Expand_301 [Expand]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 530\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 531\n",
      "[06/21/2022-18:22:02] [V] [TRT] Expand_301 [Expand] inputs: [530 -> (-1, 1, 1, -1)[BOOL]], [531 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Expand_301 for ONNX node: Expand_301\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 532 for ONNX tensor: 532\n",
      "[06/21/2022-18:22:02] [V] [TRT] Expand_301 [Expand] outputs: [532 -> (-1, 12, -1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Cast_302 [Cast]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 532\n",
      "[06/21/2022-18:22:02] [V] [TRT] Cast_302 [Cast] inputs: [532 -> (-1, 12, -1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Casting to type: bool\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Cast_302 for ONNX node: Cast_302\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 533 for ONNX tensor: 533\n",
      "[06/21/2022-18:22:02] [V] [TRT] Cast_302 [Cast] outputs: [533 -> (-1, 12, -1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_303 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_303 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_303 [Constant] outputs: [534 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Where_304 [Where]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 533\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 534\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 520\n",
      "[06/21/2022-18:22:02] [V] [TRT] Where_304 [Where] inputs: [533 -> (-1, 12, -1, -1)[BOOL]], [534 -> ()[FLOAT]], [520 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 534 for ONNX node: 534\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Where_304 for ONNX node: Where_304\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 535 for ONNX tensor: 535\n",
      "[06/21/2022-18:22:02] [V] [TRT] Where_304 [Where] outputs: [535 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Softmax_305 [Softmax]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 535\n",
      "[06/21/2022-18:22:02] [V] [TRT] Softmax_305 [Softmax] inputs: [535 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Softmax_305 for ONNX node: Softmax_305\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 536 for ONNX tensor: 536\n",
      "[06/21/2022-18:22:02] [V] [TRT] Softmax_305 [Softmax] outputs: [536 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_306 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 536\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 516\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_306 [MatMul] inputs: [536 -> (-1, 12, -1, -1)[FLOAT]], [516 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_306 for ONNX node: MatMul_306\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 537 for ONNX tensor: 537\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_306 [MatMul] outputs: [537 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Transpose_307 [Transpose]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 537\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_307 [Transpose] inputs: [537 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Transpose_307 for ONNX node: Transpose_307\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 538 for ONNX tensor: 538\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_307 [Transpose] outputs: [538 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_308 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 475\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_308 [Unsqueeze] inputs: [475 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_308 for ONNX node: Unsqueeze_308\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 541 for ONNX tensor: 541\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_308 [Unsqueeze] outputs: [541 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_309 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 541\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 893\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 894\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_309 [Concat] inputs: [541 -> (1)[INT32]], [893 -> (1)[INT32]], [894 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 893 for ONNX node: 893\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 894 for ONNX node: 894\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_309 for ONNX node: Concat_309\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 544 for ONNX tensor: 544\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_309 [Concat] outputs: [544 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_310 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 538\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 544\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_310 [Reshape] inputs: [538 -> (-1, -1, 12, 64)[FLOAT]], [544 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_310 for ONNX node: Reshape_310\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 545 for ONNX tensor: 545\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_310 [Reshape] outputs: [545 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_311 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 545\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 895\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_311 [MatMul] inputs: [545 -> (-1, -1, 768)[FLOAT]], [895 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 895 for ONNX node: 895\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_311 for ONNX node: MatMul_311\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 547 for ONNX tensor: 547\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_311 [MatMul] outputs: [547 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_312 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.3.attention.out_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 547\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_312 [Add] inputs: [distilbert.transformer.layer.3.attention.out_lin.bias -> (768)[FLOAT]], [547 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.3.attention.out_lin.bias for ONNX node: distilbert.transformer.layer.3.attention.out_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_312 for ONNX node: Add_312\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 548 for ONNX tensor: 548\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_312 [Add] outputs: [548 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_313 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 548\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 472\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_313 [Add] inputs: [548 -> (-1, -1, 768)[FLOAT]], [472 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_313 for ONNX node: Add_313\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 549 for ONNX tensor: 549\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_313 [Add] outputs: [549 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: ReduceMean_314 [ReduceMean]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 549\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_314 [ReduceMean] inputs: [549 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: ReduceMean_314 for ONNX node: ReduceMean_314\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 550 for ONNX tensor: 550\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_314 [ReduceMean] outputs: [550 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Sub_315 [Sub]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 549\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 550\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sub_315 [Sub] inputs: [549 -> (-1, -1, 768)[FLOAT]], [550 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Sub_315 for ONNX node: Sub_315\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 551 for ONNX tensor: 551\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sub_315 [Sub] outputs: [551 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_316 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_316 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_316 [Constant] outputs: [552 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Pow_317 [Pow]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 551\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 552\n",
      "[06/21/2022-18:22:02] [V] [TRT] Pow_317 [Pow] inputs: [551 -> (-1, -1, 768)[FLOAT]], [552 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 552 for ONNX node: 552\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Pow_317 for ONNX node: Pow_317\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 553 for ONNX tensor: 553\n",
      "[06/21/2022-18:22:02] [V] [TRT] Pow_317 [Pow] outputs: [553 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: ReduceMean_318 [ReduceMean]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 553\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_318 [ReduceMean] inputs: [553 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: ReduceMean_318 for ONNX node: ReduceMean_318\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 554 for ONNX tensor: 554\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_318 [ReduceMean] outputs: [554 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_319 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_319 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_319 [Constant] outputs: [555 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_320 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 554\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 555\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_320 [Add] inputs: [554 -> (-1, -1, 1)[FLOAT]], [555 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 555 for ONNX node: 555\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_320 for ONNX node: Add_320\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 556 for ONNX tensor: 556\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_320 [Add] outputs: [556 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Sqrt_321 [Sqrt]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 556\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sqrt_321 [Sqrt] inputs: [556 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Sqrt_321 for ONNX node: Sqrt_321\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 557 for ONNX tensor: 557\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sqrt_321 [Sqrt] outputs: [557 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Div_322 [Div]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 551\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 557\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_322 [Div] inputs: [551 -> (-1, -1, 768)[FLOAT]], [557 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Div_322 for ONNX node: Div_322\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 558 for ONNX tensor: 558\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_322 [Div] outputs: [558 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_323 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 558\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.3.sa_layer_norm.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_323 [Mul] inputs: [558 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.3.sa_layer_norm.weight -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.3.sa_layer_norm.weight for ONNX node: distilbert.transformer.layer.3.sa_layer_norm.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_323 for ONNX node: Mul_323\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 559 for ONNX tensor: 559\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_323 [Mul] outputs: [559 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_324 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 559\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.3.sa_layer_norm.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_324 [Add] inputs: [559 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.3.sa_layer_norm.bias -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.3.sa_layer_norm.bias for ONNX node: distilbert.transformer.layer.3.sa_layer_norm.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_324 for ONNX node: Add_324\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 560 for ONNX tensor: 560\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_324 [Add] outputs: [560 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_325 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 560\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 896\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_325 [MatMul] inputs: [560 -> (-1, -1, 768)[FLOAT]], [896 -> (768, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 896 for ONNX node: 896\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_325 for ONNX node: MatMul_325\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 562 for ONNX tensor: 562\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_325 [MatMul] outputs: [562 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_326 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.3.ffn.lin1.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 562\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_326 [Add] inputs: [distilbert.transformer.layer.3.ffn.lin1.bias -> (3072)[FLOAT]], [562 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.3.ffn.lin1.bias for ONNX node: distilbert.transformer.layer.3.ffn.lin1.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_326 for ONNX node: Add_326\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 563 for ONNX tensor: 563\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_326 [Add] outputs: [563 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_327 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_327 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_327 [Constant] outputs: [564 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Div_328 [Div]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 563\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 564\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_328 [Div] inputs: [563 -> (-1, -1, 3072)[FLOAT]], [564 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 564 for ONNX node: 564\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Div_328 for ONNX node: Div_328\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 565 for ONNX tensor: 565\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_328 [Div] outputs: [565 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Erf_329 [Erf]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 565\n",
      "[06/21/2022-18:22:02] [V] [TRT] Erf_329 [Erf] inputs: [565 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Erf_329 for ONNX node: Erf_329\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 566 for ONNX tensor: 566\n",
      "[06/21/2022-18:22:02] [V] [TRT] Erf_329 [Erf] outputs: [566 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_330 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_330 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_330 [Constant] outputs: [567 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_331 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 566\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 567\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_331 [Add] inputs: [566 -> (-1, -1, 3072)[FLOAT]], [567 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 567 for ONNX node: 567\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_331 for ONNX node: Add_331\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 568 for ONNX tensor: 568\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_331 [Add] outputs: [568 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_332 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 563\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 568\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_332 [Mul] inputs: [563 -> (-1, -1, 3072)[FLOAT]], [568 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_332 for ONNX node: Mul_332\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 569 for ONNX tensor: 569\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_332 [Mul] outputs: [569 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_333 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_333 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_333 [Constant] outputs: [570 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_334 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 569\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 570\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_334 [Mul] inputs: [569 -> (-1, -1, 3072)[FLOAT]], [570 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 570 for ONNX node: 570\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_334 for ONNX node: Mul_334\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 571 for ONNX tensor: 571\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_334 [Mul] outputs: [571 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_335 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 571\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 897\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_335 [MatMul] inputs: [571 -> (-1, -1, 3072)[FLOAT]], [897 -> (3072, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 897 for ONNX node: 897\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_335 for ONNX node: MatMul_335\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 573 for ONNX tensor: 573\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_335 [MatMul] outputs: [573 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_336 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.3.ffn.lin2.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 573\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_336 [Add] inputs: [distilbert.transformer.layer.3.ffn.lin2.bias -> (768)[FLOAT]], [573 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.3.ffn.lin2.bias for ONNX node: distilbert.transformer.layer.3.ffn.lin2.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_336 for ONNX node: Add_336\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 574 for ONNX tensor: 574\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_336 [Add] outputs: [574 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_337 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 574\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 560\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_337 [Add] inputs: [574 -> (-1, -1, 768)[FLOAT]], [560 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_337 for ONNX node: Add_337\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 575 for ONNX tensor: 575\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_337 [Add] outputs: [575 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: ReduceMean_338 [ReduceMean]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 575\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_338 [ReduceMean] inputs: [575 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: ReduceMean_338 for ONNX node: ReduceMean_338\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 576 for ONNX tensor: 576\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_338 [ReduceMean] outputs: [576 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Sub_339 [Sub]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 575\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 576\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sub_339 [Sub] inputs: [575 -> (-1, -1, 768)[FLOAT]], [576 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Sub_339 for ONNX node: Sub_339\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 577 for ONNX tensor: 577\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sub_339 [Sub] outputs: [577 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_340 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_340 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_340 [Constant] outputs: [578 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Pow_341 [Pow]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 577\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 578\n",
      "[06/21/2022-18:22:02] [V] [TRT] Pow_341 [Pow] inputs: [577 -> (-1, -1, 768)[FLOAT]], [578 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 578 for ONNX node: 578\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Pow_341 for ONNX node: Pow_341\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 579 for ONNX tensor: 579\n",
      "[06/21/2022-18:22:02] [V] [TRT] Pow_341 [Pow] outputs: [579 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: ReduceMean_342 [ReduceMean]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 579\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_342 [ReduceMean] inputs: [579 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: ReduceMean_342 for ONNX node: ReduceMean_342\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 580 for ONNX tensor: 580\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_342 [ReduceMean] outputs: [580 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_343 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_343 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_343 [Constant] outputs: [581 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_344 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 580\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 581\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_344 [Add] inputs: [580 -> (-1, -1, 1)[FLOAT]], [581 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 581 for ONNX node: 581\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_344 for ONNX node: Add_344\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 582 for ONNX tensor: 582\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_344 [Add] outputs: [582 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Sqrt_345 [Sqrt]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 582\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sqrt_345 [Sqrt] inputs: [582 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Sqrt_345 for ONNX node: Sqrt_345\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 583 for ONNX tensor: 583\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sqrt_345 [Sqrt] outputs: [583 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Div_346 [Div]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 577\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 583\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_346 [Div] inputs: [577 -> (-1, -1, 768)[FLOAT]], [583 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Div_346 for ONNX node: Div_346\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 584 for ONNX tensor: 584\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_346 [Div] outputs: [584 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_347 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 584\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.3.output_layer_norm.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_347 [Mul] inputs: [584 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.3.output_layer_norm.weight -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.3.output_layer_norm.weight for ONNX node: distilbert.transformer.layer.3.output_layer_norm.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_347 for ONNX node: Mul_347\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 585 for ONNX tensor: 585\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_347 [Mul] outputs: [585 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_348 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 585\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.3.output_layer_norm.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_348 [Add] inputs: [585 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.3.output_layer_norm.bias -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.3.output_layer_norm.bias for ONNX node: distilbert.transformer.layer.3.output_layer_norm.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_348 for ONNX node: Add_348\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 586 for ONNX tensor: 586\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_348 [Add] outputs: [586 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Shape_349 [Shape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 586\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_349 [Shape] inputs: [586 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Shape_349 for ONNX node: Shape_349\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 587 for ONNX tensor: 587\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_349 [Shape] outputs: [587 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_350 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_350 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_350 [Constant] outputs: [588 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Gather_351 [Gather]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 587\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 588\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gather_351 [Gather] inputs: [587 -> (3)[INT32]], [588 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 588 for ONNX node: 588\n",
      "[06/21/2022-18:22:02] [V] [TRT] Using Gather axis: 0\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Gather_351 for ONNX node: Gather_351\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 589 for ONNX tensor: 589\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gather_351 [Gather] outputs: [589 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Shape_352 [Shape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 586\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_352 [Shape] inputs: [586 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Shape_352 for ONNX node: Shape_352\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 590 for ONNX tensor: 590\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_352 [Shape] outputs: [590 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_353 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_353 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_353 [Constant] outputs: [591 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Gather_354 [Gather]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 590\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 591\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gather_354 [Gather] inputs: [590 -> (3)[INT32]], [591 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 591 for ONNX node: 591\n",
      "[06/21/2022-18:22:02] [V] [TRT] Using Gather axis: 0\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Gather_354 for ONNX node: Gather_354\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 592 for ONNX tensor: 592\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gather_354 [Gather] outputs: [592 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_355 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 586\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 898\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_355 [MatMul] inputs: [586 -> (-1, -1, 768)[FLOAT]], [898 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 898 for ONNX node: 898\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_355 for ONNX node: MatMul_355\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 594 for ONNX tensor: 594\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_355 [MatMul] outputs: [594 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_356 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.4.attention.q_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 594\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_356 [Add] inputs: [distilbert.transformer.layer.4.attention.q_lin.bias -> (768)[FLOAT]], [594 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.4.attention.q_lin.bias for ONNX node: distilbert.transformer.layer.4.attention.q_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_356 for ONNX node: Add_356\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 595 for ONNX tensor: 595\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_356 [Add] outputs: [595 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_357 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 589\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_357 [Unsqueeze] inputs: [589 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_357 for ONNX node: Unsqueeze_357\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 599 for ONNX tensor: 599\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_357 [Unsqueeze] outputs: [599 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_358 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 599\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 899\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 900\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 901\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_358 [Concat] inputs: [599 -> (1)[INT32]], [899 -> (1)[INT32]], [900 -> (1)[INT32]], [901 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 899 for ONNX node: 899\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 900 for ONNX node: 900\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 901 for ONNX node: 901\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_358 for ONNX node: Concat_358\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 603 for ONNX tensor: 603\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_358 [Concat] outputs: [603 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_359 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 595\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 603\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_359 [Reshape] inputs: [595 -> (-1, -1, 768)[FLOAT]], [603 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_359 for ONNX node: Reshape_359\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 604 for ONNX tensor: 604\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_359 [Reshape] outputs: [604 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Transpose_360 [Transpose]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 604\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_360 [Transpose] inputs: [604 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Transpose_360 for ONNX node: Transpose_360\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 605 for ONNX tensor: 605\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_360 [Transpose] outputs: [605 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_361 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 586\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 902\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_361 [MatMul] inputs: [586 -> (-1, -1, 768)[FLOAT]], [902 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 902 for ONNX node: 902\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_361 for ONNX node: MatMul_361\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 607 for ONNX tensor: 607\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_361 [MatMul] outputs: [607 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_362 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.4.attention.k_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 607\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_362 [Add] inputs: [distilbert.transformer.layer.4.attention.k_lin.bias -> (768)[FLOAT]], [607 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.4.attention.k_lin.bias for ONNX node: distilbert.transformer.layer.4.attention.k_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_362 for ONNX node: Add_362\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 608 for ONNX tensor: 608\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_362 [Add] outputs: [608 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_363 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 589\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_363 [Unsqueeze] inputs: [589 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_363 for ONNX node: Unsqueeze_363\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 612 for ONNX tensor: 612\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_363 [Unsqueeze] outputs: [612 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_364 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 612\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 903\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 904\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 905\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_364 [Concat] inputs: [612 -> (1)[INT32]], [903 -> (1)[INT32]], [904 -> (1)[INT32]], [905 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 903 for ONNX node: 903\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 904 for ONNX node: 904\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 905 for ONNX node: 905\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_364 for ONNX node: Concat_364\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 616 for ONNX tensor: 616\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_364 [Concat] outputs: [616 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_365 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 608\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 616\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_365 [Reshape] inputs: [608 -> (-1, -1, 768)[FLOAT]], [616 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_365 for ONNX node: Reshape_365\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 617 for ONNX tensor: 617\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_365 [Reshape] outputs: [617 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_366 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 586\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 906\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_366 [MatMul] inputs: [586 -> (-1, -1, 768)[FLOAT]], [906 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 906 for ONNX node: 906\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_366 for ONNX node: MatMul_366\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 619 for ONNX tensor: 619\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_366 [MatMul] outputs: [619 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_367 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.4.attention.v_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 619\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_367 [Add] inputs: [distilbert.transformer.layer.4.attention.v_lin.bias -> (768)[FLOAT]], [619 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.4.attention.v_lin.bias for ONNX node: distilbert.transformer.layer.4.attention.v_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_367 for ONNX node: Add_367\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 620 for ONNX tensor: 620\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_367 [Add] outputs: [620 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_368 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 589\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_368 [Unsqueeze] inputs: [589 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_368 for ONNX node: Unsqueeze_368\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 624 for ONNX tensor: 624\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_368 [Unsqueeze] outputs: [624 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_369 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 624\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 907\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 908\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 909\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_369 [Concat] inputs: [624 -> (1)[INT32]], [907 -> (1)[INT32]], [908 -> (1)[INT32]], [909 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 907 for ONNX node: 907\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 908 for ONNX node: 908\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 909 for ONNX node: 909\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_369 for ONNX node: Concat_369\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 628 for ONNX tensor: 628\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_369 [Concat] outputs: [628 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_370 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 620\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 628\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_370 [Reshape] inputs: [620 -> (-1, -1, 768)[FLOAT]], [628 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_370 for ONNX node: Reshape_370\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 629 for ONNX tensor: 629\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_370 [Reshape] outputs: [629 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Transpose_371 [Transpose]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 629\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_371 [Transpose] inputs: [629 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Transpose_371 for ONNX node: Transpose_371\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 630 for ONNX tensor: 630\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_371 [Transpose] outputs: [630 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_372 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_372 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_372 [Constant] outputs: [631 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Div_373 [Div]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 605\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 631\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_373 [Div] inputs: [605 -> (-1, 12, -1, 64)[FLOAT]], [631 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 631 for ONNX node: 631\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Div_373 for ONNX node: Div_373\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 632 for ONNX tensor: 632\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_373 [Div] outputs: [632 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Transpose_374 [Transpose]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 617\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_374 [Transpose] inputs: [617 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Transpose_374 for ONNX node: Transpose_374\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 633 for ONNX tensor: 633\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_374 [Transpose] outputs: [633 -> (-1, 12, 64, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_375 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 632\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 633\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_375 [MatMul] inputs: [632 -> (-1, 12, -1, 64)[FLOAT]], [633 -> (-1, 12, 64, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_375 for ONNX node: MatMul_375\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 634 for ONNX tensor: 634\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_375 [MatMul] outputs: [634 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_376 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_376 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_376 [Constant] outputs: [635 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Equal_377 [Equal]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: attention_mask\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 635\n",
      "[06/21/2022-18:22:02] [V] [TRT] Equal_377 [Equal] inputs: [attention_mask -> (-1, -1)[INT32]], [635 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 635 for ONNX node: 635\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Equal_377 for ONNX node: Equal_377\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 636 for ONNX tensor: 636\n",
      "[06/21/2022-18:22:02] [V] [TRT] Equal_377 [Equal] outputs: [636 -> (-1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_378 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 589\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_378 [Unsqueeze] inputs: [589 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_378 for ONNX node: Unsqueeze_378\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 639 for ONNX tensor: 639\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_378 [Unsqueeze] outputs: [639 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_379 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 592\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_379 [Unsqueeze] inputs: [592 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_379 for ONNX node: Unsqueeze_379\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 642 for ONNX tensor: 642\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_379 [Unsqueeze] outputs: [642 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_380 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 639\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 910\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 911\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 642\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_380 [Concat] inputs: [639 -> (1)[INT32]], [910 -> (1)[INT32]], [911 -> (1)[INT32]], [642 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 910 for ONNX node: 910\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 911 for ONNX node: 911\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_380 for ONNX node: Concat_380\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 643 for ONNX tensor: 643\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_380 [Concat] outputs: [643 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_381 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 636\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 643\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_381 [Reshape] inputs: [636 -> (-1, -1)[BOOL]], [643 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_381 for ONNX node: Reshape_381\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 644 for ONNX tensor: 644\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_381 [Reshape] outputs: [644 -> (-1, 1, 1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Shape_382 [Shape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 634\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_382 [Shape] inputs: [634 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Shape_382 for ONNX node: Shape_382\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 645 for ONNX tensor: 645\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_382 [Shape] outputs: [645 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Expand_383 [Expand]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 644\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 645\n",
      "[06/21/2022-18:22:02] [V] [TRT] Expand_383 [Expand] inputs: [644 -> (-1, 1, 1, -1)[BOOL]], [645 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Expand_383 for ONNX node: Expand_383\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 646 for ONNX tensor: 646\n",
      "[06/21/2022-18:22:02] [V] [TRT] Expand_383 [Expand] outputs: [646 -> (-1, 12, -1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Cast_384 [Cast]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 646\n",
      "[06/21/2022-18:22:02] [V] [TRT] Cast_384 [Cast] inputs: [646 -> (-1, 12, -1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Casting to type: bool\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Cast_384 for ONNX node: Cast_384\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 647 for ONNX tensor: 647\n",
      "[06/21/2022-18:22:02] [V] [TRT] Cast_384 [Cast] outputs: [647 -> (-1, 12, -1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_385 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_385 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_385 [Constant] outputs: [648 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Where_386 [Where]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 647\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 648\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 634\n",
      "[06/21/2022-18:22:02] [V] [TRT] Where_386 [Where] inputs: [647 -> (-1, 12, -1, -1)[BOOL]], [648 -> ()[FLOAT]], [634 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 648 for ONNX node: 648\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Where_386 for ONNX node: Where_386\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 649 for ONNX tensor: 649\n",
      "[06/21/2022-18:22:02] [V] [TRT] Where_386 [Where] outputs: [649 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Softmax_387 [Softmax]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 649\n",
      "[06/21/2022-18:22:02] [V] [TRT] Softmax_387 [Softmax] inputs: [649 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Softmax_387 for ONNX node: Softmax_387\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 650 for ONNX tensor: 650\n",
      "[06/21/2022-18:22:02] [V] [TRT] Softmax_387 [Softmax] outputs: [650 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_388 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 650\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 630\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_388 [MatMul] inputs: [650 -> (-1, 12, -1, -1)[FLOAT]], [630 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_388 for ONNX node: MatMul_388\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 651 for ONNX tensor: 651\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_388 [MatMul] outputs: [651 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Transpose_389 [Transpose]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 651\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_389 [Transpose] inputs: [651 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Transpose_389 for ONNX node: Transpose_389\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 652 for ONNX tensor: 652\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_389 [Transpose] outputs: [652 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_390 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 589\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_390 [Unsqueeze] inputs: [589 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_390 for ONNX node: Unsqueeze_390\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 655 for ONNX tensor: 655\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_390 [Unsqueeze] outputs: [655 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_391 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 655\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 912\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 913\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_391 [Concat] inputs: [655 -> (1)[INT32]], [912 -> (1)[INT32]], [913 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 912 for ONNX node: 912\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 913 for ONNX node: 913\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_391 for ONNX node: Concat_391\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 658 for ONNX tensor: 658\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_391 [Concat] outputs: [658 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_392 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 652\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 658\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_392 [Reshape] inputs: [652 -> (-1, -1, 12, 64)[FLOAT]], [658 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_392 for ONNX node: Reshape_392\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 659 for ONNX tensor: 659\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_392 [Reshape] outputs: [659 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_393 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 659\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 914\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_393 [MatMul] inputs: [659 -> (-1, -1, 768)[FLOAT]], [914 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 914 for ONNX node: 914\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_393 for ONNX node: MatMul_393\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 661 for ONNX tensor: 661\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_393 [MatMul] outputs: [661 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_394 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.4.attention.out_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 661\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_394 [Add] inputs: [distilbert.transformer.layer.4.attention.out_lin.bias -> (768)[FLOAT]], [661 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.4.attention.out_lin.bias for ONNX node: distilbert.transformer.layer.4.attention.out_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_394 for ONNX node: Add_394\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 662 for ONNX tensor: 662\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_394 [Add] outputs: [662 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_395 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 662\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 586\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_395 [Add] inputs: [662 -> (-1, -1, 768)[FLOAT]], [586 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_395 for ONNX node: Add_395\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 663 for ONNX tensor: 663\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_395 [Add] outputs: [663 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: ReduceMean_396 [ReduceMean]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 663\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_396 [ReduceMean] inputs: [663 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: ReduceMean_396 for ONNX node: ReduceMean_396\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 664 for ONNX tensor: 664\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_396 [ReduceMean] outputs: [664 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Sub_397 [Sub]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 663\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 664\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sub_397 [Sub] inputs: [663 -> (-1, -1, 768)[FLOAT]], [664 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Sub_397 for ONNX node: Sub_397\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 665 for ONNX tensor: 665\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sub_397 [Sub] outputs: [665 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_398 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_398 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_398 [Constant] outputs: [666 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Pow_399 [Pow]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 665\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 666\n",
      "[06/21/2022-18:22:02] [V] [TRT] Pow_399 [Pow] inputs: [665 -> (-1, -1, 768)[FLOAT]], [666 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 666 for ONNX node: 666\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Pow_399 for ONNX node: Pow_399\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 667 for ONNX tensor: 667\n",
      "[06/21/2022-18:22:02] [V] [TRT] Pow_399 [Pow] outputs: [667 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: ReduceMean_400 [ReduceMean]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 667\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_400 [ReduceMean] inputs: [667 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: ReduceMean_400 for ONNX node: ReduceMean_400\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 668 for ONNX tensor: 668\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_400 [ReduceMean] outputs: [668 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_401 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_401 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_401 [Constant] outputs: [669 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_402 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 668\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 669\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_402 [Add] inputs: [668 -> (-1, -1, 1)[FLOAT]], [669 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 669 for ONNX node: 669\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_402 for ONNX node: Add_402\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 670 for ONNX tensor: 670\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_402 [Add] outputs: [670 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Sqrt_403 [Sqrt]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 670\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sqrt_403 [Sqrt] inputs: [670 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Sqrt_403 for ONNX node: Sqrt_403\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 671 for ONNX tensor: 671\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sqrt_403 [Sqrt] outputs: [671 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Div_404 [Div]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 665\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 671\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_404 [Div] inputs: [665 -> (-1, -1, 768)[FLOAT]], [671 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Div_404 for ONNX node: Div_404\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 672 for ONNX tensor: 672\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_404 [Div] outputs: [672 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_405 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 672\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.4.sa_layer_norm.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_405 [Mul] inputs: [672 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.4.sa_layer_norm.weight -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.4.sa_layer_norm.weight for ONNX node: distilbert.transformer.layer.4.sa_layer_norm.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_405 for ONNX node: Mul_405\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 673 for ONNX tensor: 673\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_405 [Mul] outputs: [673 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_406 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 673\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.4.sa_layer_norm.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_406 [Add] inputs: [673 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.4.sa_layer_norm.bias -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.4.sa_layer_norm.bias for ONNX node: distilbert.transformer.layer.4.sa_layer_norm.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_406 for ONNX node: Add_406\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 674 for ONNX tensor: 674\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_406 [Add] outputs: [674 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_407 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 674\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 915\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_407 [MatMul] inputs: [674 -> (-1, -1, 768)[FLOAT]], [915 -> (768, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 915 for ONNX node: 915\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_407 for ONNX node: MatMul_407\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 676 for ONNX tensor: 676\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_407 [MatMul] outputs: [676 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_408 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.4.ffn.lin1.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 676\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_408 [Add] inputs: [distilbert.transformer.layer.4.ffn.lin1.bias -> (3072)[FLOAT]], [676 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.4.ffn.lin1.bias for ONNX node: distilbert.transformer.layer.4.ffn.lin1.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_408 for ONNX node: Add_408\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 677 for ONNX tensor: 677\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_408 [Add] outputs: [677 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_409 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_409 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_409 [Constant] outputs: [678 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Div_410 [Div]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 677\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 678\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_410 [Div] inputs: [677 -> (-1, -1, 3072)[FLOAT]], [678 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 678 for ONNX node: 678\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Div_410 for ONNX node: Div_410\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 679 for ONNX tensor: 679\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_410 [Div] outputs: [679 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Erf_411 [Erf]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 679\n",
      "[06/21/2022-18:22:02] [V] [TRT] Erf_411 [Erf] inputs: [679 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Erf_411 for ONNX node: Erf_411\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 680 for ONNX tensor: 680\n",
      "[06/21/2022-18:22:02] [V] [TRT] Erf_411 [Erf] outputs: [680 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_412 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_412 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_412 [Constant] outputs: [681 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_413 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 680\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 681\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_413 [Add] inputs: [680 -> (-1, -1, 3072)[FLOAT]], [681 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 681 for ONNX node: 681\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_413 for ONNX node: Add_413\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 682 for ONNX tensor: 682\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_413 [Add] outputs: [682 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_414 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 677\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 682\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_414 [Mul] inputs: [677 -> (-1, -1, 3072)[FLOAT]], [682 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_414 for ONNX node: Mul_414\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 683 for ONNX tensor: 683\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_414 [Mul] outputs: [683 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_415 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_415 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_415 [Constant] outputs: [684 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_416 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 683\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 684\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_416 [Mul] inputs: [683 -> (-1, -1, 3072)[FLOAT]], [684 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 684 for ONNX node: 684\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_416 for ONNX node: Mul_416\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 685 for ONNX tensor: 685\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_416 [Mul] outputs: [685 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_417 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 685\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 916\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_417 [MatMul] inputs: [685 -> (-1, -1, 3072)[FLOAT]], [916 -> (3072, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 916 for ONNX node: 916\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_417 for ONNX node: MatMul_417\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 687 for ONNX tensor: 687\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_417 [MatMul] outputs: [687 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_418 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.4.ffn.lin2.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 687\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_418 [Add] inputs: [distilbert.transformer.layer.4.ffn.lin2.bias -> (768)[FLOAT]], [687 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.4.ffn.lin2.bias for ONNX node: distilbert.transformer.layer.4.ffn.lin2.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_418 for ONNX node: Add_418\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 688 for ONNX tensor: 688\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_418 [Add] outputs: [688 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_419 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 688\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 674\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_419 [Add] inputs: [688 -> (-1, -1, 768)[FLOAT]], [674 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_419 for ONNX node: Add_419\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 689 for ONNX tensor: 689\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_419 [Add] outputs: [689 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: ReduceMean_420 [ReduceMean]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 689\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_420 [ReduceMean] inputs: [689 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: ReduceMean_420 for ONNX node: ReduceMean_420\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 690 for ONNX tensor: 690\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_420 [ReduceMean] outputs: [690 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Sub_421 [Sub]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 689\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 690\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sub_421 [Sub] inputs: [689 -> (-1, -1, 768)[FLOAT]], [690 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Sub_421 for ONNX node: Sub_421\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 691 for ONNX tensor: 691\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sub_421 [Sub] outputs: [691 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_422 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_422 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_422 [Constant] outputs: [692 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Pow_423 [Pow]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 691\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 692\n",
      "[06/21/2022-18:22:02] [V] [TRT] Pow_423 [Pow] inputs: [691 -> (-1, -1, 768)[FLOAT]], [692 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 692 for ONNX node: 692\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Pow_423 for ONNX node: Pow_423\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 693 for ONNX tensor: 693\n",
      "[06/21/2022-18:22:02] [V] [TRT] Pow_423 [Pow] outputs: [693 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: ReduceMean_424 [ReduceMean]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 693\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_424 [ReduceMean] inputs: [693 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: ReduceMean_424 for ONNX node: ReduceMean_424\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 694 for ONNX tensor: 694\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_424 [ReduceMean] outputs: [694 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_425 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_425 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_425 [Constant] outputs: [695 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_426 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 694\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 695\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_426 [Add] inputs: [694 -> (-1, -1, 1)[FLOAT]], [695 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 695 for ONNX node: 695\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_426 for ONNX node: Add_426\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 696 for ONNX tensor: 696\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_426 [Add] outputs: [696 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Sqrt_427 [Sqrt]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 696\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sqrt_427 [Sqrt] inputs: [696 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Sqrt_427 for ONNX node: Sqrt_427\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 697 for ONNX tensor: 697\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sqrt_427 [Sqrt] outputs: [697 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Div_428 [Div]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 691\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 697\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_428 [Div] inputs: [691 -> (-1, -1, 768)[FLOAT]], [697 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Div_428 for ONNX node: Div_428\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 698 for ONNX tensor: 698\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_428 [Div] outputs: [698 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_429 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 698\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.4.output_layer_norm.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_429 [Mul] inputs: [698 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.4.output_layer_norm.weight -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.4.output_layer_norm.weight for ONNX node: distilbert.transformer.layer.4.output_layer_norm.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_429 for ONNX node: Mul_429\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 699 for ONNX tensor: 699\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_429 [Mul] outputs: [699 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_430 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 699\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.4.output_layer_norm.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_430 [Add] inputs: [699 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.4.output_layer_norm.bias -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.4.output_layer_norm.bias for ONNX node: distilbert.transformer.layer.4.output_layer_norm.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_430 for ONNX node: Add_430\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 700 for ONNX tensor: 700\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_430 [Add] outputs: [700 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Shape_431 [Shape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 700\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_431 [Shape] inputs: [700 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Shape_431 for ONNX node: Shape_431\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 701 for ONNX tensor: 701\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_431 [Shape] outputs: [701 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_432 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_432 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_432 [Constant] outputs: [702 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Gather_433 [Gather]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 701\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 702\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gather_433 [Gather] inputs: [701 -> (3)[INT32]], [702 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 702 for ONNX node: 702\n",
      "[06/21/2022-18:22:02] [V] [TRT] Using Gather axis: 0\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Gather_433 for ONNX node: Gather_433\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 703 for ONNX tensor: 703\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gather_433 [Gather] outputs: [703 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Shape_434 [Shape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 700\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_434 [Shape] inputs: [700 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Shape_434 for ONNX node: Shape_434\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 704 for ONNX tensor: 704\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_434 [Shape] outputs: [704 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_435 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_435 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_435 [Constant] outputs: [705 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Gather_436 [Gather]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 704\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 705\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gather_436 [Gather] inputs: [704 -> (3)[INT32]], [705 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 705 for ONNX node: 705\n",
      "[06/21/2022-18:22:02] [V] [TRT] Using Gather axis: 0\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Gather_436 for ONNX node: Gather_436\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 706 for ONNX tensor: 706\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gather_436 [Gather] outputs: [706 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_437 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 700\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 917\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_437 [MatMul] inputs: [700 -> (-1, -1, 768)[FLOAT]], [917 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 917 for ONNX node: 917\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_437 for ONNX node: MatMul_437\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 708 for ONNX tensor: 708\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_437 [MatMul] outputs: [708 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_438 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.5.attention.q_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 708\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_438 [Add] inputs: [distilbert.transformer.layer.5.attention.q_lin.bias -> (768)[FLOAT]], [708 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.5.attention.q_lin.bias for ONNX node: distilbert.transformer.layer.5.attention.q_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_438 for ONNX node: Add_438\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 709 for ONNX tensor: 709\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_438 [Add] outputs: [709 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_439 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 703\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_439 [Unsqueeze] inputs: [703 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_439 for ONNX node: Unsqueeze_439\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 713 for ONNX tensor: 713\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_439 [Unsqueeze] outputs: [713 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_440 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 713\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 918\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 919\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 920\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_440 [Concat] inputs: [713 -> (1)[INT32]], [918 -> (1)[INT32]], [919 -> (1)[INT32]], [920 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 918 for ONNX node: 918\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 919 for ONNX node: 919\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 920 for ONNX node: 920\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_440 for ONNX node: Concat_440\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 717 for ONNX tensor: 717\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_440 [Concat] outputs: [717 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_441 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 709\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 717\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_441 [Reshape] inputs: [709 -> (-1, -1, 768)[FLOAT]], [717 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_441 for ONNX node: Reshape_441\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 718 for ONNX tensor: 718\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_441 [Reshape] outputs: [718 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Transpose_442 [Transpose]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 718\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_442 [Transpose] inputs: [718 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Transpose_442 for ONNX node: Transpose_442\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 719 for ONNX tensor: 719\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_442 [Transpose] outputs: [719 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_443 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 700\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 921\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_443 [MatMul] inputs: [700 -> (-1, -1, 768)[FLOAT]], [921 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 921 for ONNX node: 921\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_443 for ONNX node: MatMul_443\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 721 for ONNX tensor: 721\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_443 [MatMul] outputs: [721 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_444 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.5.attention.k_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 721\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_444 [Add] inputs: [distilbert.transformer.layer.5.attention.k_lin.bias -> (768)[FLOAT]], [721 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.5.attention.k_lin.bias for ONNX node: distilbert.transformer.layer.5.attention.k_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_444 for ONNX node: Add_444\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 722 for ONNX tensor: 722\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_444 [Add] outputs: [722 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_445 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 703\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_445 [Unsqueeze] inputs: [703 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_445 for ONNX node: Unsqueeze_445\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 726 for ONNX tensor: 726\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_445 [Unsqueeze] outputs: [726 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_446 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 726\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 922\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 923\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 924\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_446 [Concat] inputs: [726 -> (1)[INT32]], [922 -> (1)[INT32]], [923 -> (1)[INT32]], [924 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 922 for ONNX node: 922\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 923 for ONNX node: 923\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 924 for ONNX node: 924\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_446 for ONNX node: Concat_446\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 730 for ONNX tensor: 730\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_446 [Concat] outputs: [730 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_447 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 722\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 730\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_447 [Reshape] inputs: [722 -> (-1, -1, 768)[FLOAT]], [730 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_447 for ONNX node: Reshape_447\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 731 for ONNX tensor: 731\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_447 [Reshape] outputs: [731 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_448 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 700\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 925\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_448 [MatMul] inputs: [700 -> (-1, -1, 768)[FLOAT]], [925 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 925 for ONNX node: 925\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_448 for ONNX node: MatMul_448\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 733 for ONNX tensor: 733\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_448 [MatMul] outputs: [733 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_449 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.5.attention.v_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 733\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_449 [Add] inputs: [distilbert.transformer.layer.5.attention.v_lin.bias -> (768)[FLOAT]], [733 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.5.attention.v_lin.bias for ONNX node: distilbert.transformer.layer.5.attention.v_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_449 for ONNX node: Add_449\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 734 for ONNX tensor: 734\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_449 [Add] outputs: [734 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_450 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 703\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_450 [Unsqueeze] inputs: [703 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_450 for ONNX node: Unsqueeze_450\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 738 for ONNX tensor: 738\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_450 [Unsqueeze] outputs: [738 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_451 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 738\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 926\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 927\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 928\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_451 [Concat] inputs: [738 -> (1)[INT32]], [926 -> (1)[INT32]], [927 -> (1)[INT32]], [928 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 926 for ONNX node: 926\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 927 for ONNX node: 927\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 928 for ONNX node: 928\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_451 for ONNX node: Concat_451\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 742 for ONNX tensor: 742\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_451 [Concat] outputs: [742 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_452 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 734\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 742\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_452 [Reshape] inputs: [734 -> (-1, -1, 768)[FLOAT]], [742 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_452 for ONNX node: Reshape_452\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 743 for ONNX tensor: 743\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_452 [Reshape] outputs: [743 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Transpose_453 [Transpose]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 743\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_453 [Transpose] inputs: [743 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Transpose_453 for ONNX node: Transpose_453\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 744 for ONNX tensor: 744\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_453 [Transpose] outputs: [744 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_454 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_454 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_454 [Constant] outputs: [745 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Div_455 [Div]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 719\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 745\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_455 [Div] inputs: [719 -> (-1, 12, -1, 64)[FLOAT]], [745 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 745 for ONNX node: 745\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Div_455 for ONNX node: Div_455\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 746 for ONNX tensor: 746\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_455 [Div] outputs: [746 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Transpose_456 [Transpose]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 731\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_456 [Transpose] inputs: [731 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Transpose_456 for ONNX node: Transpose_456\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 747 for ONNX tensor: 747\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_456 [Transpose] outputs: [747 -> (-1, 12, 64, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_457 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 746\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 747\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_457 [MatMul] inputs: [746 -> (-1, 12, -1, 64)[FLOAT]], [747 -> (-1, 12, 64, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_457 for ONNX node: MatMul_457\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 748 for ONNX tensor: 748\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_457 [MatMul] outputs: [748 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_458 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_458 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_458 [Constant] outputs: [749 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Equal_459 [Equal]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: attention_mask\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 749\n",
      "[06/21/2022-18:22:02] [V] [TRT] Equal_459 [Equal] inputs: [attention_mask -> (-1, -1)[INT32]], [749 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 749 for ONNX node: 749\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Equal_459 for ONNX node: Equal_459\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 750 for ONNX tensor: 750\n",
      "[06/21/2022-18:22:02] [V] [TRT] Equal_459 [Equal] outputs: [750 -> (-1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_460 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 703\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_460 [Unsqueeze] inputs: [703 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_460 for ONNX node: Unsqueeze_460\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 753 for ONNX tensor: 753\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_460 [Unsqueeze] outputs: [753 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_461 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 706\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_461 [Unsqueeze] inputs: [706 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_461 for ONNX node: Unsqueeze_461\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 756 for ONNX tensor: 756\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_461 [Unsqueeze] outputs: [756 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_462 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 753\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 929\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 930\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 756\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_462 [Concat] inputs: [753 -> (1)[INT32]], [929 -> (1)[INT32]], [930 -> (1)[INT32]], [756 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 929 for ONNX node: 929\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 930 for ONNX node: 930\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_462 for ONNX node: Concat_462\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 757 for ONNX tensor: 757\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_462 [Concat] outputs: [757 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_463 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 750\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 757\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_463 [Reshape] inputs: [750 -> (-1, -1)[BOOL]], [757 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_463 for ONNX node: Reshape_463\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 758 for ONNX tensor: 758\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_463 [Reshape] outputs: [758 -> (-1, 1, 1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Shape_464 [Shape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 748\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_464 [Shape] inputs: [748 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Shape_464 for ONNX node: Shape_464\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 759 for ONNX tensor: 759\n",
      "[06/21/2022-18:22:02] [V] [TRT] Shape_464 [Shape] outputs: [759 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Expand_465 [Expand]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 758\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 759\n",
      "[06/21/2022-18:22:02] [V] [TRT] Expand_465 [Expand] inputs: [758 -> (-1, 1, 1, -1)[BOOL]], [759 -> (4)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Expand_465 for ONNX node: Expand_465\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 760 for ONNX tensor: 760\n",
      "[06/21/2022-18:22:02] [V] [TRT] Expand_465 [Expand] outputs: [760 -> (-1, 12, -1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Cast_466 [Cast]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 760\n",
      "[06/21/2022-18:22:02] [V] [TRT] Cast_466 [Cast] inputs: [760 -> (-1, 12, -1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Casting to type: bool\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Cast_466 for ONNX node: Cast_466\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 761 for ONNX tensor: 761\n",
      "[06/21/2022-18:22:02] [V] [TRT] Cast_466 [Cast] outputs: [761 -> (-1, 12, -1, -1)[BOOL]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_467 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_467 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_467 [Constant] outputs: [762 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Where_468 [Where]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 761\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 762\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 748\n",
      "[06/21/2022-18:22:02] [V] [TRT] Where_468 [Where] inputs: [761 -> (-1, 12, -1, -1)[BOOL]], [762 -> ()[FLOAT]], [748 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 762 for ONNX node: 762\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Where_468 for ONNX node: Where_468\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 763 for ONNX tensor: 763\n",
      "[06/21/2022-18:22:02] [V] [TRT] Where_468 [Where] outputs: [763 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Softmax_469 [Softmax]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 763\n",
      "[06/21/2022-18:22:02] [V] [TRT] Softmax_469 [Softmax] inputs: [763 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Softmax_469 for ONNX node: Softmax_469\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 764 for ONNX tensor: 764\n",
      "[06/21/2022-18:22:02] [V] [TRT] Softmax_469 [Softmax] outputs: [764 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_470 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 764\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 744\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_470 [MatMul] inputs: [764 -> (-1, 12, -1, -1)[FLOAT]], [744 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_470 for ONNX node: MatMul_470\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 765 for ONNX tensor: 765\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_470 [MatMul] outputs: [765 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Transpose_471 [Transpose]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 765\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_471 [Transpose] inputs: [765 -> (-1, 12, -1, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Transpose_471 for ONNX node: Transpose_471\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 766 for ONNX tensor: 766\n",
      "[06/21/2022-18:22:02] [V] [TRT] Transpose_471 [Transpose] outputs: [766 -> (-1, -1, 12, 64)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Unsqueeze_472 [Unsqueeze]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 703\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_472 [Unsqueeze] inputs: [703 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Unsqueeze_472 for ONNX node: Unsqueeze_472\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 769 for ONNX tensor: 769\n",
      "[06/21/2022-18:22:02] [V] [TRT] Unsqueeze_472 [Unsqueeze] outputs: [769 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Concat_473 [Concat]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 769\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 931\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 932\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_473 [Concat] inputs: [769 -> (1)[INT32]], [931 -> (1)[INT32]], [932 -> (1)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 931 for ONNX node: 931\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 932 for ONNX node: 932\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Concat_473 for ONNX node: Concat_473\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 772 for ONNX tensor: 772\n",
      "[06/21/2022-18:22:02] [V] [TRT] Concat_473 [Concat] outputs: [772 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Reshape_474 [Reshape]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 766\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 772\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_474 [Reshape] inputs: [766 -> (-1, -1, 12, 64)[FLOAT]], [772 -> (3)[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Reshape_474 for ONNX node: Reshape_474\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 773 for ONNX tensor: 773\n",
      "[06/21/2022-18:22:02] [V] [TRT] Reshape_474 [Reshape] outputs: [773 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_475 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 773\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 933\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_475 [MatMul] inputs: [773 -> (-1, -1, 768)[FLOAT]], [933 -> (768, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 933 for ONNX node: 933\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_475 for ONNX node: MatMul_475\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 775 for ONNX tensor: 775\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_475 [MatMul] outputs: [775 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_476 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.5.attention.out_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 775\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_476 [Add] inputs: [distilbert.transformer.layer.5.attention.out_lin.bias -> (768)[FLOAT]], [775 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.5.attention.out_lin.bias for ONNX node: distilbert.transformer.layer.5.attention.out_lin.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_476 for ONNX node: Add_476\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 776 for ONNX tensor: 776\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_476 [Add] outputs: [776 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_477 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 776\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 700\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_477 [Add] inputs: [776 -> (-1, -1, 768)[FLOAT]], [700 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_477 for ONNX node: Add_477\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 777 for ONNX tensor: 777\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_477 [Add] outputs: [777 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: ReduceMean_478 [ReduceMean]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 777\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_478 [ReduceMean] inputs: [777 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: ReduceMean_478 for ONNX node: ReduceMean_478\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 778 for ONNX tensor: 778\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_478 [ReduceMean] outputs: [778 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Sub_479 [Sub]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 777\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 778\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sub_479 [Sub] inputs: [777 -> (-1, -1, 768)[FLOAT]], [778 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Sub_479 for ONNX node: Sub_479\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 779 for ONNX tensor: 779\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sub_479 [Sub] outputs: [779 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_480 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_480 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_480 [Constant] outputs: [780 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Pow_481 [Pow]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 779\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 780\n",
      "[06/21/2022-18:22:02] [V] [TRT] Pow_481 [Pow] inputs: [779 -> (-1, -1, 768)[FLOAT]], [780 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 780 for ONNX node: 780\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Pow_481 for ONNX node: Pow_481\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 781 for ONNX tensor: 781\n",
      "[06/21/2022-18:22:02] [V] [TRT] Pow_481 [Pow] outputs: [781 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: ReduceMean_482 [ReduceMean]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 781\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_482 [ReduceMean] inputs: [781 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: ReduceMean_482 for ONNX node: ReduceMean_482\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 782 for ONNX tensor: 782\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_482 [ReduceMean] outputs: [782 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_483 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_483 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_483 [Constant] outputs: [783 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_484 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 782\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 783\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_484 [Add] inputs: [782 -> (-1, -1, 1)[FLOAT]], [783 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 783 for ONNX node: 783\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_484 for ONNX node: Add_484\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 784 for ONNX tensor: 784\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_484 [Add] outputs: [784 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Sqrt_485 [Sqrt]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 784\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sqrt_485 [Sqrt] inputs: [784 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Sqrt_485 for ONNX node: Sqrt_485\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 785 for ONNX tensor: 785\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sqrt_485 [Sqrt] outputs: [785 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Div_486 [Div]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 779\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 785\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_486 [Div] inputs: [779 -> (-1, -1, 768)[FLOAT]], [785 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Div_486 for ONNX node: Div_486\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 786 for ONNX tensor: 786\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_486 [Div] outputs: [786 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_487 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 786\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.5.sa_layer_norm.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_487 [Mul] inputs: [786 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.5.sa_layer_norm.weight -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.5.sa_layer_norm.weight for ONNX node: distilbert.transformer.layer.5.sa_layer_norm.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_487 for ONNX node: Mul_487\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 787 for ONNX tensor: 787\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_487 [Mul] outputs: [787 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_488 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 787\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.5.sa_layer_norm.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_488 [Add] inputs: [787 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.5.sa_layer_norm.bias -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.5.sa_layer_norm.bias for ONNX node: distilbert.transformer.layer.5.sa_layer_norm.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_488 for ONNX node: Add_488\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 788 for ONNX tensor: 788\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_488 [Add] outputs: [788 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_489 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 788\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 934\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_489 [MatMul] inputs: [788 -> (-1, -1, 768)[FLOAT]], [934 -> (768, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 934 for ONNX node: 934\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_489 for ONNX node: MatMul_489\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 790 for ONNX tensor: 790\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_489 [MatMul] outputs: [790 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_490 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.5.ffn.lin1.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 790\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_490 [Add] inputs: [distilbert.transformer.layer.5.ffn.lin1.bias -> (3072)[FLOAT]], [790 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.5.ffn.lin1.bias for ONNX node: distilbert.transformer.layer.5.ffn.lin1.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_490 for ONNX node: Add_490\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 791 for ONNX tensor: 791\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_490 [Add] outputs: [791 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_491 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_491 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_491 [Constant] outputs: [792 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Div_492 [Div]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 791\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 792\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_492 [Div] inputs: [791 -> (-1, -1, 3072)[FLOAT]], [792 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 792 for ONNX node: 792\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Div_492 for ONNX node: Div_492\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 793 for ONNX tensor: 793\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_492 [Div] outputs: [793 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Erf_493 [Erf]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 793\n",
      "[06/21/2022-18:22:02] [V] [TRT] Erf_493 [Erf] inputs: [793 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Erf_493 for ONNX node: Erf_493\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 794 for ONNX tensor: 794\n",
      "[06/21/2022-18:22:02] [V] [TRT] Erf_493 [Erf] outputs: [794 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_494 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_494 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_494 [Constant] outputs: [795 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_495 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 794\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 795\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_495 [Add] inputs: [794 -> (-1, -1, 3072)[FLOAT]], [795 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 795 for ONNX node: 795\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_495 for ONNX node: Add_495\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 796 for ONNX tensor: 796\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_495 [Add] outputs: [796 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_496 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 791\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 796\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_496 [Mul] inputs: [791 -> (-1, -1, 3072)[FLOAT]], [796 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_496 for ONNX node: Mul_496\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 797 for ONNX tensor: 797\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_496 [Mul] outputs: [797 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_497 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_497 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_497 [Constant] outputs: [798 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_498 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 797\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 798\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_498 [Mul] inputs: [797 -> (-1, -1, 3072)[FLOAT]], [798 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 798 for ONNX node: 798\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_498 for ONNX node: Mul_498\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 799 for ONNX tensor: 799\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_498 [Mul] outputs: [799 -> (-1, -1, 3072)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: MatMul_499 [MatMul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 799\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 935\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_499 [MatMul] inputs: [799 -> (-1, -1, 3072)[FLOAT]], [935 -> (3072, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 935 for ONNX node: 935\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: MatMul_499 for ONNX node: MatMul_499\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 801 for ONNX tensor: 801\n",
      "[06/21/2022-18:22:02] [V] [TRT] MatMul_499 [MatMul] outputs: [801 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_500 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.5.ffn.lin2.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 801\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_500 [Add] inputs: [distilbert.transformer.layer.5.ffn.lin2.bias -> (768)[FLOAT]], [801 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.5.ffn.lin2.bias for ONNX node: distilbert.transformer.layer.5.ffn.lin2.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_500 for ONNX node: Add_500\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 802 for ONNX tensor: 802\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_500 [Add] outputs: [802 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_501 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 802\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 788\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_501 [Add] inputs: [802 -> (-1, -1, 768)[FLOAT]], [788 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_501 for ONNX node: Add_501\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 803 for ONNX tensor: 803\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_501 [Add] outputs: [803 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: ReduceMean_502 [ReduceMean]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 803\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_502 [ReduceMean] inputs: [803 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: ReduceMean_502 for ONNX node: ReduceMean_502\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 804 for ONNX tensor: 804\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_502 [ReduceMean] outputs: [804 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Sub_503 [Sub]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 803\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 804\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sub_503 [Sub] inputs: [803 -> (-1, -1, 768)[FLOAT]], [804 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Sub_503 for ONNX node: Sub_503\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 805 for ONNX tensor: 805\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sub_503 [Sub] outputs: [805 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_504 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_504 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_504 [Constant] outputs: [806 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Pow_505 [Pow]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 805\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 806\n",
      "[06/21/2022-18:22:02] [V] [TRT] Pow_505 [Pow] inputs: [805 -> (-1, -1, 768)[FLOAT]], [806 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 806 for ONNX node: 806\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Pow_505 for ONNX node: Pow_505\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 807 for ONNX tensor: 807\n",
      "[06/21/2022-18:22:02] [V] [TRT] Pow_505 [Pow] outputs: [807 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: ReduceMean_506 [ReduceMean]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 807\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_506 [ReduceMean] inputs: [807 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: ReduceMean_506 for ONNX node: ReduceMean_506\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 808 for ONNX tensor: 808\n",
      "[06/21/2022-18:22:02] [V] [TRT] ReduceMean_506 [ReduceMean] outputs: [808 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_507 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_507 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_507 [Constant] outputs: [809 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_508 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 808\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 809\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_508 [Add] inputs: [808 -> (-1, -1, 1)[FLOAT]], [809 -> ()[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 809 for ONNX node: 809\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_508 for ONNX node: Add_508\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 810 for ONNX tensor: 810\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_508 [Add] outputs: [810 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Sqrt_509 [Sqrt]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 810\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sqrt_509 [Sqrt] inputs: [810 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Sqrt_509 for ONNX node: Sqrt_509\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 811 for ONNX tensor: 811\n",
      "[06/21/2022-18:22:02] [V] [TRT] Sqrt_509 [Sqrt] outputs: [811 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Div_510 [Div]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 805\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 811\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_510 [Div] inputs: [805 -> (-1, -1, 768)[FLOAT]], [811 -> (-1, -1, 1)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Div_510 for ONNX node: Div_510\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 812 for ONNX tensor: 812\n",
      "[06/21/2022-18:22:02] [V] [TRT] Div_510 [Div] outputs: [812 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Mul_511 [Mul]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 812\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.5.output_layer_norm.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_511 [Mul] inputs: [812 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.5.output_layer_norm.weight -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.5.output_layer_norm.weight for ONNX node: distilbert.transformer.layer.5.output_layer_norm.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Mul_511 for ONNX node: Mul_511\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 813 for ONNX tensor: 813\n",
      "[06/21/2022-18:22:02] [V] [TRT] Mul_511 [Mul] outputs: [813 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Add_512 [Add]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 813\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: distilbert.transformer.layer.5.output_layer_norm.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_512 [Add] inputs: [813 -> (-1, -1, 768)[FLOAT]], [distilbert.transformer.layer.5.output_layer_norm.bias -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: distilbert.transformer.layer.5.output_layer_norm.bias for ONNX node: distilbert.transformer.layer.5.output_layer_norm.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Add_512 for ONNX node: Add_512\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 814 for ONNX tensor: 814\n",
      "[06/21/2022-18:22:02] [V] [TRT] Add_512 [Add] outputs: [814 -> (-1, -1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Constant_513 [Constant]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_513 [Constant] inputs: \n",
      "[06/21/2022-18:22:02] [V] [TRT] Constant_513 [Constant] outputs: [815 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Gather_514 [Gather]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 814\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 815\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gather_514 [Gather] inputs: [814 -> (-1, -1, 768)[FLOAT]], [815 -> ()[INT32]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: 815 for ONNX node: 815\n",
      "[06/21/2022-18:22:02] [V] [TRT] Using Gather axis: 1\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Gather_514 for ONNX node: Gather_514\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 816 for ONNX tensor: 816\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gather_514 [Gather] outputs: [816 -> (-1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Gemm_515 [Gemm]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 816\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: pre_classifier.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: pre_classifier.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gemm_515 [Gemm] inputs: [816 -> (-1, 768)[FLOAT]], [pre_classifier.weight -> (768, 768)[FLOAT]], [pre_classifier.bias -> (768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] GEMM: using FC layer instead of MM because all criteria were met.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (_, 768), unsqueezing to: (_, _, _, _)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Gemm_515 for ONNX node: Gemm_515\n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (_, 768, 1, 1), squeezing to: (_, _)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 817 for ONNX tensor: 817\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gemm_515 [Gemm] outputs: [817 -> (-1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Relu_516 [Relu]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 817\n",
      "[06/21/2022-18:22:02] [V] [TRT] Relu_516 [Relu] inputs: [817 -> (-1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Relu_516 for ONNX node: Relu_516\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: 818 for ONNX tensor: 818\n",
      "[06/21/2022-18:22:02] [V] [TRT] Relu_516 [Relu] outputs: [818 -> (-1, 768)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Parsing node: Gemm_517 [Gemm]\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: 818\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: classifier.weight\n",
      "[06/21/2022-18:22:02] [V] [TRT] Searching for input: classifier.bias\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gemm_517 [Gemm] inputs: [818 -> (-1, 768)[FLOAT]], [classifier.weight -> (2, 768)[FLOAT]], [classifier.bias -> (2)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] GEMM: using FC layer instead of MM because all criteria were met.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (_, 768), unsqueezing to: (_, _, _, _)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering layer: Gemm_517 for ONNX node: Gemm_517\n",
      "[06/21/2022-18:22:02] [V] [TRT] Original shape: (_, 2, 1, 1), squeezing to: (_, _)\n",
      "[06/21/2022-18:22:02] [V] [TRT] Registering tensor: logits_0 for ONNX tensor: logits\n",
      "[06/21/2022-18:22:02] [V] [TRT] Gemm_517 [Gemm] outputs: [logits -> (-1, 2)[FLOAT]], \n",
      "[06/21/2022-18:22:02] [V] [TRT] Marking logits_0 as output: logits\n",
      "[06/21/2022-18:22:02] [I] Finish parsing network model\n",
      "[06/21/2022-18:22:02] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 514, GPU 3356 (MiB)\n",
      "[06/21/2022-18:22:02] [I] [TRT] [MemUsageSnapshot] Builder begin: CPU 514 MiB, GPU 3356 MiB\n",
      "[06/21/2022-18:22:02] [V] [TRT] Applying generic optimizations to the graph for inference.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Original: 681 layers\n",
      "[06/21/2022-18:22:02] [V] [TRT] After dead-layer removal: 681 layers\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 122 with (Unnamed Layer* 27) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 125 with (Unnamed Layer* 31) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.embeddings.LayerNorm.weight with (Unnamed Layer* 36) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.embeddings.LayerNorm.bias with (Unnamed Layer* 39) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 822 with (Unnamed Layer* 48) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.0.attention.q_lin.bias with (Unnamed Layer* 51) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 826 with (Unnamed Layer* 61) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.0.attention.k_lin.bias with (Unnamed Layer* 64) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 830 with (Unnamed Layer* 73) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.0.attention.v_lin.bias with (Unnamed Layer* 76) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 175 with (Unnamed Layer* 86) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 179 with (Unnamed Layer* 91) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 192 with (Unnamed Layer* 112) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 838 with (Unnamed Layer* 137) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.0.attention.out_lin.bias with (Unnamed Layer* 140) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 210 with (Unnamed Layer* 146) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 213 with (Unnamed Layer* 150) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.0.sa_layer_norm.weight with (Unnamed Layer* 155) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.0.sa_layer_norm.bias with (Unnamed Layer* 158) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 839 with (Unnamed Layer* 161) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.0.ffn.lin1.bias with (Unnamed Layer* 164) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 222 with (Unnamed Layer* 167) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 225 with (Unnamed Layer* 171) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 228 with (Unnamed Layer* 175) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 840 with (Unnamed Layer* 178) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.0.ffn.lin2.bias with (Unnamed Layer* 181) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 236 with (Unnamed Layer* 187) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 239 with (Unnamed Layer* 191) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.0.output_layer_norm.weight with (Unnamed Layer* 196) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.0.output_layer_norm.bias with (Unnamed Layer* 199) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 841 with (Unnamed Layer* 208) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.1.attention.q_lin.bias with (Unnamed Layer* 211) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 845 with (Unnamed Layer* 221) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.1.attention.k_lin.bias with (Unnamed Layer* 224) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 849 with (Unnamed Layer* 233) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.1.attention.v_lin.bias with (Unnamed Layer* 236) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 289 with (Unnamed Layer* 246) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 293 with (Unnamed Layer* 251) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 306 with (Unnamed Layer* 272) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 857 with (Unnamed Layer* 297) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.1.attention.out_lin.bias with (Unnamed Layer* 300) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 324 with (Unnamed Layer* 306) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 327 with (Unnamed Layer* 310) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.1.sa_layer_norm.weight with (Unnamed Layer* 315) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.1.sa_layer_norm.bias with (Unnamed Layer* 318) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 858 with (Unnamed Layer* 321) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.1.ffn.lin1.bias with (Unnamed Layer* 324) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 336 with (Unnamed Layer* 327) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 339 with (Unnamed Layer* 331) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 342 with (Unnamed Layer* 335) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 859 with (Unnamed Layer* 338) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.1.ffn.lin2.bias with (Unnamed Layer* 341) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 350 with (Unnamed Layer* 347) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 353 with (Unnamed Layer* 351) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.1.output_layer_norm.weight with (Unnamed Layer* 356) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.1.output_layer_norm.bias with (Unnamed Layer* 359) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 860 with (Unnamed Layer* 368) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.2.attention.q_lin.bias with (Unnamed Layer* 371) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 864 with (Unnamed Layer* 381) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.2.attention.k_lin.bias with (Unnamed Layer* 384) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 868 with (Unnamed Layer* 393) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.2.attention.v_lin.bias with (Unnamed Layer* 396) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 403 with (Unnamed Layer* 406) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 407 with (Unnamed Layer* 411) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 420 with (Unnamed Layer* 432) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 876 with (Unnamed Layer* 457) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.2.attention.out_lin.bias with (Unnamed Layer* 460) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 438 with (Unnamed Layer* 466) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 441 with (Unnamed Layer* 470) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.2.sa_layer_norm.weight with (Unnamed Layer* 475) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.2.sa_layer_norm.bias with (Unnamed Layer* 478) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 877 with (Unnamed Layer* 481) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.2.ffn.lin1.bias with (Unnamed Layer* 484) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 450 with (Unnamed Layer* 487) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 453 with (Unnamed Layer* 491) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 456 with (Unnamed Layer* 495) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 878 with (Unnamed Layer* 498) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.2.ffn.lin2.bias with (Unnamed Layer* 501) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 464 with (Unnamed Layer* 507) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 467 with (Unnamed Layer* 511) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.2.output_layer_norm.weight with (Unnamed Layer* 516) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.2.output_layer_norm.bias with (Unnamed Layer* 519) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 879 with (Unnamed Layer* 528) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.3.attention.q_lin.bias with (Unnamed Layer* 531) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 883 with (Unnamed Layer* 541) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.3.attention.k_lin.bias with (Unnamed Layer* 544) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 887 with (Unnamed Layer* 553) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.3.attention.v_lin.bias with (Unnamed Layer* 556) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 517 with (Unnamed Layer* 566) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 521 with (Unnamed Layer* 571) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 534 with (Unnamed Layer* 592) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 895 with (Unnamed Layer* 617) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.3.attention.out_lin.bias with (Unnamed Layer* 620) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 552 with (Unnamed Layer* 626) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 555 with (Unnamed Layer* 630) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.3.sa_layer_norm.weight with (Unnamed Layer* 635) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.3.sa_layer_norm.bias with (Unnamed Layer* 638) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 896 with (Unnamed Layer* 641) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.3.ffn.lin1.bias with (Unnamed Layer* 644) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 564 with (Unnamed Layer* 647) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 567 with (Unnamed Layer* 651) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 570 with (Unnamed Layer* 655) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 897 with (Unnamed Layer* 658) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.3.ffn.lin2.bias with (Unnamed Layer* 661) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 578 with (Unnamed Layer* 667) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 581 with (Unnamed Layer* 671) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.3.output_layer_norm.weight with (Unnamed Layer* 676) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.3.output_layer_norm.bias with (Unnamed Layer* 679) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 898 with (Unnamed Layer* 688) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.4.attention.q_lin.bias with (Unnamed Layer* 691) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 902 with (Unnamed Layer* 701) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.4.attention.k_lin.bias with (Unnamed Layer* 704) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 906 with (Unnamed Layer* 713) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.4.attention.v_lin.bias with (Unnamed Layer* 716) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 631 with (Unnamed Layer* 726) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 635 with (Unnamed Layer* 731) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 648 with (Unnamed Layer* 752) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 914 with (Unnamed Layer* 777) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.4.attention.out_lin.bias with (Unnamed Layer* 780) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 666 with (Unnamed Layer* 786) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 669 with (Unnamed Layer* 790) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.4.sa_layer_norm.weight with (Unnamed Layer* 795) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.4.sa_layer_norm.bias with (Unnamed Layer* 798) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 915 with (Unnamed Layer* 801) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.4.ffn.lin1.bias with (Unnamed Layer* 804) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 678 with (Unnamed Layer* 807) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 681 with (Unnamed Layer* 811) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 684 with (Unnamed Layer* 815) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 916 with (Unnamed Layer* 818) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.4.ffn.lin2.bias with (Unnamed Layer* 821) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 692 with (Unnamed Layer* 827) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 695 with (Unnamed Layer* 831) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.4.output_layer_norm.weight with (Unnamed Layer* 836) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.4.output_layer_norm.bias with (Unnamed Layer* 839) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 917 with (Unnamed Layer* 848) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.5.attention.q_lin.bias with (Unnamed Layer* 851) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 921 with (Unnamed Layer* 861) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.5.attention.k_lin.bias with (Unnamed Layer* 864) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 925 with (Unnamed Layer* 873) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.5.attention.v_lin.bias with (Unnamed Layer* 876) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 745 with (Unnamed Layer* 886) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 749 with (Unnamed Layer* 891) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 762 with (Unnamed Layer* 912) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 933 with (Unnamed Layer* 937) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.5.attention.out_lin.bias with (Unnamed Layer* 940) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 780 with (Unnamed Layer* 946) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 783 with (Unnamed Layer* 950) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.5.sa_layer_norm.weight with (Unnamed Layer* 955) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.5.sa_layer_norm.bias with (Unnamed Layer* 958) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 934 with (Unnamed Layer* 961) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.5.ffn.lin1.bias with (Unnamed Layer* 964) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 792 with (Unnamed Layer* 967) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 795 with (Unnamed Layer* 971) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 798 with (Unnamed Layer* 975) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 935 with (Unnamed Layer* 978) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.5.ffn.lin2.bias with (Unnamed Layer* 981) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 806 with (Unnamed Layer* 987) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing 809 with (Unnamed Layer* 991) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.5.output_layer_norm.weight with (Unnamed Layer* 996) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConstShuffleFusion: Fusing distilbert.transformer.layer.5.output_layer_norm.bias with (Unnamed Layer* 999) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_31 with Transpose_32\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_37 with Transpose_46\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_42 with Transpose_43\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_61 with Reshape_64\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_113 with Transpose_114\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_119 with Transpose_128\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_124 with Transpose_125\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_143 with Reshape_146\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_195 with Transpose_196\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_201 with Transpose_210\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_206 with Transpose_207\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_225 with Reshape_228\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_277 with Transpose_278\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_283 with Transpose_292\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_288 with Transpose_289\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_307 with Reshape_310\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_359 with Transpose_360\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_365 with Transpose_374\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_370 with Transpose_371\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_389 with Reshape_392\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_441 with Transpose_442\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_447 with Transpose_456\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_452 with Transpose_453\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_471 with Reshape_474\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_33 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_27 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_38 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_60 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found Softmax_59 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_115 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_109 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_120 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_142 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found Softmax_141 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_197 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_191 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_202 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_224 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found Softmax_223 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_279 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_273 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_284 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_306 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found Softmax_305 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_361 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_355 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_366 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_388 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found Softmax_387 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_443 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_437 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_448 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found MatMul_470 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found Softmax_469 to be part of self-attention pattern.\n",
      "[06/21/2022-18:22:02] [V] [TRT] Found and reassigned Myelin backends for Self-Attention nodes\n",
      "[06/21/2022-18:22:02] [V] [TRT] After Myelin optimization: 16 layers\n",
      "[06/21/2022-18:22:02] [V] [TRT] Convert layer type of Gemm_515 from FULLY_CONNECTED to CONVOLUTION\n",
      "[06/21/2022-18:22:02] [V] [TRT] Removing shuffle_between_(Unnamed Layer* 1008) [Shuffle]_output_and_Gemm_515\n",
      "[06/21/2022-18:22:02] [V] [TRT] Convert layer type of Gemm_517 from FULLY_CONNECTED to CONVOLUTION\n",
      "[06/21/2022-18:22:02] [V] [TRT] Removing shuffle_between_(Unnamed Layer* 1020) [Shuffle]_output_and_Gemm_517\n",
      "[06/21/2022-18:22:02] [V] [TRT] After scale fusion: 16 layers\n",
      "[06/21/2022-18:22:02] [V] [TRT] -----------SqueezePushDown kSQUEEZE_FORK case: Gemm_515 --> (Unnamed Layer* 1013) [Shuffle] --> Relu_516\n",
      "[06/21/2022-18:22:02] [V] [TRT] ShuffleShuffleFusion: Fusing squeeze_after_Relu_516 with (Unnamed Layer* 1020) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] ConvReluFusion: Fusing Gemm_515 with Relu_516\n",
      "[06/21/2022-18:22:02] [V] [TRT] Removing squeeze_after_Relu_516 + (Unnamed Layer* 1020) [Shuffle]\n",
      "[06/21/2022-18:22:02] [V] [TRT] After vertical fusions: 13 layers\n",
      "[06/21/2022-18:22:02] [V] [TRT] After dupe layer removal: 13 layers\n",
      "[06/21/2022-18:22:02] [V] [TRT] After final dead-layer removal: 13 layers\n",
      "[06/21/2022-18:22:02] [V] [TRT] After tensor merging: 13 layers\n",
      "[06/21/2022-18:22:02] [V] [TRT] Replacing slice Slice_6 with copy from (Unnamed Layer* 4) [Constant]_output to 116\n",
      "[06/21/2022-18:22:02] [V] [TRT] After concat removal: 13 layers\n",
      "[06/21/2022-18:22:02] [V] [TRT] Graph construction and optimization completed in 0.213195 seconds.\n",
      "[06/21/2022-18:22:03] [V] [TRT] Using cublasLt a tactic source\n",
      "[06/21/2022-18:22:03] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +358, GPU +166, now: CPU 873, GPU 3522 (MiB)\n",
      "[06/21/2022-18:22:03] [V] [TRT] Using cuDNN as a tactic source\n",
      "[06/21/2022-18:22:04] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +277, GPU +164, now: CPU 1150, GPU 3686 (MiB)\n",
      "[W] [TRT] Detected invalid timing cache, setup a local cache instead\n",
      "[06/21/2022-18:22:04] [06/21/2022-18:22:04] [V] [TRT] Constructing optimization profile number 0 [1/1].\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning format combination:  -> Float(768,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning format combination:  -> Half(768,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning format combination:  -> Int32(512,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning Reformat:Int32(512,1) -> Int32(128,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] --------------- Timing Runner: Slice_6 (Reformat)\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 1002 Time: 0.008192\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 0 Time: 0.00704\n",
      "[06/21/2022-18:22:04] [V] [TRT] Fastest Tactic: 0 Time: 0.00704\n",
      "[06/21/2022-18:22:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning format combination:  -> Float(768,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning format combination:  -> Half(768,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning Reformat:Float(768,1) -> Half(768,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 1002 Time: 0.211968\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 0 Time: 0.339072\n",
      "[06/21/2022-18:22:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.211968\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning Reformat:Half(768,1) -> Float(768,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 1002 Time: 0.341632\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 0 Time: 0.341888\n",
      "[06/21/2022-18:22:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.341632\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning format combination: Float(768,1), Int32(128,1) -> Float(98304,768,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] --------------- Timing Runner: Gather_7 (Gather)\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 1 Time: 0.013056\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 2 Time: 0.011264\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 3 Time: 0.025856\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 4 Time: 0.10816\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 6 Time: 0.060416\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 7 Time: 0.009216\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 8 Time: 0.007168\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 9 Time: 0.007168\n",
      "[06/21/2022-18:22:04] [V] [TRT] Fastest Tactic: 8 Time: 0.007168\n",
      "[06/21/2022-18:22:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Gather Tactic: 8\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning format combination: Half(768,1), Int32(128,1) -> Half(98304,768,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] --------------- Timing Runner: Gather_7 (Gather)\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 1 Time: 0.012288\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 2 Time: 0.011264\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 3 Time: 0.0256\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 4 Time: 0.1024\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 6 Time: 0.05972\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 7 Time: 0.009088\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 8 Time: 0.007168\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 9 Time: 0.00704\n",
      "[06/21/2022-18:22:04] [V] [TRT] Fastest Tactic: 9 Time: 0.00704\n",
      "[06/21/2022-18:22:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Gather Tactic: 9\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning Reformat:Float(768,1) -> Half(768,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 1002 Time: 0.01216\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 0 Time: 0.01216\n",
      "[06/21/2022-18:22:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.01216\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning Reformat:Half(768,1) -> Float(768,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 1002 Time: 0.014336\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 0 Time: 0.012032\n",
      "[06/21/2022-18:22:04] [V] [TRT] Fastest Tactic: 0 Time: 0.012032\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning format combination: Float(768,1), Int32(128,1) -> Float(98304,768,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] --------------- Timing Runner: Gather_8 (Gather)\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 1 Time: 0.012288\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 2 Time: 0.011264\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 3 Time: 0.025344\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 4 Time: 0.107392\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 6 Time: 0.060032\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 7 Time: 0.008832\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 8 Time: 0.007168\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 9 Time: 0.007168\n",
      "[06/21/2022-18:22:04] [V] [TRT] Fastest Tactic: 8 Time: 0.007168\n",
      "[06/21/2022-18:22:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Gather Tactic: 8\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning format combination: Half(768,1), Int32(128,1) -> Half(98304,768,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] --------------- Timing Runner: Gather_8 (Gather)\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 1 Time: 0.012288\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 2 Time: 0.011264\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 3 Time: 0.025088\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 4 Time: 0.100608\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 6 Time: 0.059776\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 7 Time: 0.009216\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 8 Time: 0.007168\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 9 Time: 0.00704\n",
      "[06/21/2022-18:22:04] [V] [TRT] Fastest Tactic: 9 Time: 0.00704\n",
      "[06/21/2022-18:22:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Gather Tactic: 9\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning Reformat:Float(98304,768,1) -> Half(98304,768,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 1002 Time: 0.009088\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 0 Time: 0.008064\n",
      "[06/21/2022-18:22:04] [V] [TRT] Fastest Tactic: 0 Time: 0.008064\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning Reformat:Half(98304,768,1) -> Float(98304,768,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 1002 Time: 0.01024\n",
      "[06/21/2022-18:22:04] [V] [TRT] Tactic: 0 Time: 0.008064\n",
      "[06/21/2022-18:22:04] [V] [TRT] Fastest Tactic: 0 Time: 0.008064\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning Reformat:Float(98304,768,1) -> Half(98304,768,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning Reformat:Half(98304,768,1) -> Float(98304,768,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] *************** Autotuning format combination: Float(98304,768,1), Float(98304,768,1), Int32(128,1) -> Float(98304,768,1) ***************\n",
      "[06/21/2022-18:22:04] [V] [TRT] --------------- Timing Runner: {ForeignNode[830 + (Unnamed Layer* 73) [Shuffle]...Add_512]} (Myelin)\n",
      "[06/21/2022-18:22:12] [V] [TRT] myelinAllocCb allocated GPU (data-constants) 8 bytes at 0x302000000.\n",
      "[06/21/2022-18:22:12] [V] [TRT] myelinAllocCb allocated GPU 8650752 bytes at 0x30c35c300.\n",
      "[06/21/2022-18:22:12] [V] [TRT] Tactic: 0 Time: 1.66506\n",
      "[06/21/2022-18:22:12] [V] [TRT] myelinFreeCb freeing GPU at 0x30c35c300.\n",
      "[06/21/2022-18:22:12] [V] [TRT] myelinFreeCb freeing GPU at 0x302000000.\n",
      "[06/21/2022-18:22:12] [V] [TRT] Fastest Tactic: 0 Time: 1.66506\n",
      "[06/21/2022-18:22:12] [V] [TRT] *************** Autotuning format combination: Half(98304,768,1), Half(98304,768,1), Int32(128,1) -> Half(98304,768,1) ***************\n",
      "[06/21/2022-18:22:12] [V] [TRT] --------------- Timing Runner: {ForeignNode[830 + (Unnamed Layer* 73) [Shuffle]...Add_512]} (Myelin)\n",
      "[W] [TRT] Weights [name=192 + (Unnamed Layer* 112) [Shuffle]{ForeignNode[830 + (Unnamed Layer* 73) [Shuffle]...Add_512]}]: Converted FP32 positive or negative infinity in weights to corresponding FP16 infinity. Please modify the weights if this is not the desired behavior.\n",
      "[06/21/2022-18:22:12] [W] [TRT] Weights [name=306 + (Unnamed Layer* 272) [Shuffle]{ForeignNode[830 + (Unnamed Layer* 73) [Shuffle]...Add_512]}]: Converted FP32 positive or negative infinity in weights to corresponding FP16 infinity. Please modify the weights if this is not the desired behavior.\n",
      "[06/21/2022-18:22:12] [W] [TRT] Weights [name=420 + (Unnamed Layer* 432) [Shuffle]{ForeignNode[830 + (Unnamed Layer* 73) [Shuffle]...Add_512]}]: Converted FP32 positive or negative infinity in weights to corresponding FP16 infinity. Please modify the weights if this is not the desired behavior.\n",
      "[06/21/2022-18:22:12] [W] [TRT] Weights [name=534 + (Unnamed Layer* 592) [Shuffle]{ForeignNode[830 + (Unnamed Layer* 73) [Shuffle]...Add_512]}]: Converted FP32 positive or negative infinity in weights to corresponding FP16 infinity. Please modify the weights if this is not the desired behavior.\n",
      "[06/21/2022-18:22:12] [W] [TRT] Weights [name=648 + (Unnamed Layer* 752) [Shuffle]{ForeignNode[830 + (Unnamed Layer* 73) [Shuffle]...Add_512]}]: Converted FP32 positive or negative infinity in weights to corresponding FP16 infinity. Please modify the weights if this is not the desired behavior.\n",
      "[06/21/2022-18:22:12] [W] [TRT] Weights [name=762 + (Unnamed Layer* 912) [Shuffle]{ForeignNode[830 + (Unnamed Layer* 73) [Shuffle]...Add_512]}]: Converted FP32 positive or negative infinity in weights to corresponding FP16 infinity. Please modify the weights if this is not the desired behavior.\n",
      "[06/21/2022-18:22:12] [06/21/2022-18:22:21] [V] [TRT] myelinAllocCb allocated GPU (data-constants) 8 bytes at 0x302000000.\n",
      "[06/21/2022-18:22:21] [V] [TRT] myelinAllocCb allocated GPU 4521984 bytes at 0x3071ae300.\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.799008\n",
      "[06/21/2022-18:22:21] [V] [TRT] myelinFreeCb freeing GPU at 0x3071ae300.\n",
      "[06/21/2022-18:22:21] [V] [TRT] myelinFreeCb freeing GPU at 0x302000000.\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.799008\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning format combination:  -> Int32() ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Float(98304,768,1) -> Half(98304,768,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Half(98304,768,1) -> Float(98304,768,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning format combination: Float(98304,768,1), Int32() -> Float(768,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Gather_514 (Gather)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 5 Time: 0.011776\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 6 Time: 0.008192\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 7 Time: 0.007296\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 8 Time: 0.006912\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 9 Time: 0.006784\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 9 Time: 0.006784\n",
      "[06/21/2022-18:22:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Gather Tactic: 9\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning format combination: Half(98304,768,1), Int32() -> Half(768,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Gather_514 (Gather)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 5 Time: 0.011648\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 6 Time: 0.00832\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 7 Time: 0.007168\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 8 Time: 0.00704\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 9 Time: 0.00704\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 8 Time: 0.00704\n",
      "[06/21/2022-18:22:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Gather Tactic: 8\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Float(768,1) -> Half(768,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.007936\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.00704\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.00704\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Half(768,1) -> Float(768,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.008192\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.006528\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.006528\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning format combination: Float(768,1) -> Float(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 1008) [Shuffle] (Shuffle)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.006144\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1 Time: 0.011264\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.006144\n",
      "[06/21/2022-18:22:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning format combination: Half(768,1) -> Half(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 1008) [Shuffle] (Shuffle)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.006144\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1 Time: 0.01216\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.006144\n",
      "[06/21/2022-18:22:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Float(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.008192\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.007168\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.007168\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Float(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.008064\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.00704\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.00704\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Float(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.008192\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.0064\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.0064\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Float(768,1,1,1) -> Half(96,1:8,96,96) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.008192\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.006784\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.006784\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Float(768,1,768,768) -> Float(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.007936\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.00704\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.00704\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Float(768,1,768,768) -> Half(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.007936\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.00704\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.00704\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Float(768,1,768,768) -> Half(384,1:2,1,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.00832\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.00704\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.00704\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Float(768,1,768,768) -> Half(96,1:8,96,96) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.007936\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.007168\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.007168\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Half(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.008192\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.006528\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.006528\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Half(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.00768\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.007168\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.007168\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Half(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.00832\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.0064\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.0064\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Half(768,1,1,1) -> Half(96,1:8,96,96) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.00832\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.006912\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.006912\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Half(384,1:2,1,1) -> Float(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.008192\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.006144\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.006144\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Half(384,1:2,1,1) -> Float(768,1,768,768) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.008192\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.007168\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.007168\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Half(384,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.00832\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.006272\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.006272\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Half(384,1:2,1,1) -> Half(96,1:8,96,96) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.00832\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.006912\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.006912\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Half(96,1:8,96,96) -> Float(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.008192\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.006148\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.006148\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Half(96,1:8,96,96) -> Float(768,1,768,768) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.00768\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.007168\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.007168\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Half(96,1:8,96,96) -> Half(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.008192\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.006144\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.006144\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning Reformat:Half(96,1:8,96,96) -> Half(384,1:2,1,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 1002 Time: 0.008192\n",
      "[06/21/2022-18:22:21] [V] [TRT] Tactic: 0 Time: 0.00704\n",
      "[06/21/2022-18:22:21] [V] [TRT] Fastest Tactic: 0 Time: 0.00704\n",
      "[06/21/2022-18:22:21] [V] [TRT] *************** Autotuning format combination: Float(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (FusedConvActConvolution)\n",
      "[06/21/2022-18:22:21] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:21] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CudaDepthwiseConvolution)\n",
      "[06/21/2022-18:22:21] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:22] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CudnnConvolution)\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 0 Time: 0.057344\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 1 Time: 0.05824\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 2 Time: 0.15936\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 4 Time: 2.62554\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 5 Time: 0.333056\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 56 Time: 0.05632\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 57 Time: 0.057472\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 58 Time: 0.159616\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 60 Time: 2.62349\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 61 Time: 0.3328\n",
      "[06/21/2022-18:22:23] [V] [TRT] Fastest Tactic: 56 Time: 0.05632\n",
      "[06/21/2022-18:22:23] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CublasConvolution)\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 0 Time: 0.012288\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 1 Time: 0.013312\n",
      "[06/21/2022-18:22:23] [V] [TRT] Fastest Tactic: 0 Time: 0.012288\n",
      "[06/21/2022-18:22:23] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CaskConvolution)\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x128_relu_interior_nn_v1 Tactic: 1754569683116234317\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 1754569683116234317 Time: 0.149504\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x128_relu_medium_nn_v1 Tactic: 1825138533642645384\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 1825138533642645384 Time: 0.150528\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x32_relu_interior_nn_v1 Tactic: 2733356012094739613\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 2733356012094739613 Time: 0.100352\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x128_relu_small_nn_v1 Tactic: 3915320020053085238\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 3915320020053085238 Time: 0.149888\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x64_relu_small_nn_v1 Tactic: 6808617066150061604\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 6808617066150061604 Time: 0.090112\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x64_relu_interior_nn_v1 Tactic: 9091006216302412844\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 9091006216302412844 Time: 0.086912\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x64_relu_medium_nn_v1 Tactic: -8060443123034038864\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: -8060443123034038864 Time: 0.095232\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_conv1x1_f32f32_f32_f32_nchwkcrs_nchw_simt_small_batch_bias_relu Tactic: -6194327789991425125\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: -6194327789991425125 Time: 0.010496\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x32_relu_medium_nn_v1 Tactic: -4420849921117327522\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: -4420849921117327522 Time: 0.076928\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x32_relu_small_nn_v1 Tactic: -3946921629105938337\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: -3946921629105938337 Time: 0.102528\n",
      "[06/21/2022-18:22:23] [V] [TRT] Fastest Tactic: -6194327789991425125 Time: 0.010496\n",
      "[06/21/2022-18:22:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -6194327789991425125\n",
      "[06/21/2022-18:22:23] [V] [TRT] *************** Autotuning format combination: Float(768,1,768,768) -> Float(768,1,768,768) ***************\n",
      "[06/21/2022-18:22:23] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CudnnConvolution)\n",
      "[06/21/2022-18:22:23] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:23] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CublasConvolution)\n",
      "[06/21/2022-18:22:23] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:23] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CaskConvolution)\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 861694390046228376\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 861694390046228376 Time: 0.148864\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 5258189349241541167\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 5258189349241541167 Time: 0.081024\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5821621277990374316\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 5821621277990374316 Time: 0.14912\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 5863767799113001648\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 5863767799113001648 Time: 0.045952\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: -9147980667639709536\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: -9147980667639709536 Time: 0.147456\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -8892196987859366827\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: -8892196987859366827 Time: 0.14656\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: -8850904373104590857\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: -8850904373104590857 Time: 0.08192\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -8010679767156598961\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: -8010679767156598961 Time: 0.045952\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7751035352149795660\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: -7751035352149795660 Time: 0.148736\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: -5115676123557684531\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: -5115676123557684531 Time: 0.14848\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -493597327599791285\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: -493597327599791285 Time: 0.079616\n",
      "[06/21/2022-18:22:23] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: -423878181466897819\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: -423878181466897819 Time: 0.04608\n",
      "[06/21/2022-18:22:23] [V] [TRT] Fastest Tactic: 5863767799113001648 Time: 0.045952\n",
      "[06/21/2022-18:22:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5863767799113001648\n",
      "[06/21/2022-18:22:23] [V] [TRT] *************** Autotuning format combination: Half(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:23] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CudnnConvolution)\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 0 Time: 0.137728\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 1 Time: 0.104832\n",
      "[06/21/2022-18:22:23] [V] [TRT] Tactic: 2 Time: 0.14528\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 4 Time: 2.51423\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 5 Time: 0.321536\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 56 Time: 0.137472\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 58 Time: 0.145408\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 60 Time: 2.46515\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 61 Time: 0.317184\n",
      "[06/21/2022-18:22:24] [V] [TRT] Fastest Tactic: 1 Time: 0.104832\n",
      "[06/21/2022-18:22:24] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CublasConvolution)\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 0 Time: 0.012928\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 1 Time: 0.011392\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 2 Time: 0.013312\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 3 Time: 0.011264\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 4 Time: 0.08512\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 5 Time: 0.025088\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 6 Time: 0.034304\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 7 Time: 0.01344\n",
      "[06/21/2022-18:22:24] [V] [TRT] Fastest Tactic: 3 Time: 0.011264\n",
      "[06/21/2022-18:22:24] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CaskConvolution)\n",
      "[06/21/2022-18:22:24] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 3\n",
      "[06/21/2022-18:22:24] [V] [TRT] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:24] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CaskConvolution)\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_conv1x1_f16f16_f16_f16_nchw_vect_c_2kcrs_vect_c_2_nchw_simt_small_batch_bias_relu Tactic: -7852373803729529742\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: -7852373803729529742 Time: 0.009344\n",
      "[06/21/2022-18:22:24] [V] [TRT] Fastest Tactic: -7852373803729529742 Time: 0.009344\n",
      "[06/21/2022-18:22:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7852373803729529742\n",
      "[06/21/2022-18:22:24] [V] [TRT] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[06/21/2022-18:22:24] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (FusedConvActConvolution)\n",
      "[06/21/2022-18:22:24] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:24] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CudnnConvolution)\n",
      "[06/21/2022-18:22:24] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:24] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CublasConvolution)\n",
      "[06/21/2022-18:22:24] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:24] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CaskConvolution)\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 2418518597804310654\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 2418518597804310654 Time: 0.050176\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 8292881859266835088\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 8292881859266835088 Time: 0.052864\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 8401509141903434922\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 8401509141903434922 Time: 0.047616\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -8654297089785671176\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: -8654297089785671176 Time: 0.076288\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: -7140760933967189247\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: -7140760933967189247 Time: 0.046208\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: -4097850214384059472\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: -4097850214384059472 Time: 0.04736\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3689982367035295496\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: -3689982367035295496 Time: 0.0768\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -2534402059426524406\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: -2534402059426524406 Time: 0.075776\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -2027588946874785071\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: -2027588946874785071 Time: 0.048128\n",
      "[06/21/2022-18:22:24] [V] [TRT] Fastest Tactic: -7140760933967189247 Time: 0.046208\n",
      "[06/21/2022-18:22:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7140760933967189247\n",
      "[06/21/2022-18:22:24] [V] [TRT] *************** Autotuning format combination: Half(96,1:8,96,96) -> Float(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:24] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CudnnConvolution)\n",
      "[06/21/2022-18:22:24] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:24] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CublasConvolution)\n",
      "[06/21/2022-18:22:24] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:24] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CaskConvolution)\n",
      "[06/21/2022-18:22:24] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:24] [V] [TRT] *************** Autotuning format combination: Half(96,1:8,96,96) -> Half(96,1:8,96,96) ***************\n",
      "[06/21/2022-18:22:24] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CudaDepthwiseConvolution)\n",
      "[06/21/2022-18:22:24] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:24] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CudnnConvolution)\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 0 Time: 0.130944\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 1 Time: 0.099712\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 2 Time: 0.13824\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 4 Time: 2.46554\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 5 Time: 0.316672\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 56 Time: 0.131072\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 58 Time: 0.13824\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 60 Time: 2.46528\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 61 Time: 0.316288\n",
      "[06/21/2022-18:22:24] [V] [TRT] Fastest Tactic: 1 Time: 0.099712\n",
      "[06/21/2022-18:22:24] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CublasConvolution)\n",
      "[06/21/2022-18:22:24] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:24] [V] [TRT] --------------- Timing Runner: Gemm_515 + Relu_516 (CaskConvolution)\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_h884cudnn_256x64_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 2105695814191699972\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 2105695814191699972 Time: 0.029568\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 2689212690707793357\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 2689212690707793357 Time: 0.04416\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 2798075085844016892\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 2798075085844016892 Time: 0.028544\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 3091156937974993800\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 3091156937974993800 Time: 0.027776\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_h884cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3754069740140581927\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 3754069740140581927 Time: 0.030976\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 3932578551652369355\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 3932578551652369355 Time: 0.014592\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 5483093640784800285\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 5483093640784800285 Time: 0.02048\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_h884cudnn_128x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 5666160310350604399\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 5666160310350604399 Time: 0.031488\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_t1r1s1 Tactic: 5900614001783877430\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 5900614001783877430 Time: 0.021632\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_h884cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 5925270497649423688\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 5925270497649423688 Time: 0.043904\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 5999406432703271895\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 5999406432703271895 Time: 0.021504\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_h884cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 6680916730816870145\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 6680916730816870145 Time: 0.029568\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_h884cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7158029511300006471\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 7158029511300006471 Time: 0.029696\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_h884cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 7859952145590271433\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 7859952145590271433 Time: 0.028672\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_h884cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 8283847742354150423\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 8283847742354150423 Time: 0.030976\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 8642279798680442080\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 8642279798680442080 Time: 0.028672\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 9108067304506990859\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: 9108067304506990859 Time: 0.021376\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor8x8x4_simple_t1r1s1 Tactic: -9104099172933216230\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: -9104099172933216230 Time: 0.012032\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: -8956720569082607796\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: -8956720569082607796 Time: 0.021248\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor8x8x4_t1r1s1 Tactic: -8952042869709043207\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: -8952042869709043207 Time: 0.028672\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: -8898856569474934280\n",
      "[06/21/2022-18:22:24] [V] [TRT] Tactic: -8898856569474934280 Time: 0.0288\n",
      "[06/21/2022-18:22:24] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor8x8x4_t1r1s1 Tactic: -8774805574135441656\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -8774805574135441656 Time: 0.027136\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: -8520017388966620486\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -8520017388966620486 Time: 0.01536\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor8x8x4_t1r1s1 Tactic: -8487084252145372186\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -8487084252145372186 Time: 0.04416\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_h884cudnn_256x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: -8391760416076885205\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -8391760416076885205 Time: 0.043904\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: -7990268040387498660\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -7990268040387498660 Time: 0.016384\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor8x8x4_t1r1s1 Tactic: -7849113095413980300\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -7849113095413980300 Time: 0.044032\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: -5590418898350402100\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -5590418898350402100 Time: 0.020352\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: -5389631537202601150\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -5389631537202601150 Time: 0.044032\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_h884cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4534876761957424274\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -4534876761957424274 Time: 0.043008\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_h884cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3237051169894153788\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -3237051169894153788 Time: 0.029696\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_t1r1s1 Tactic: -2676138141351394855\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -2676138141351394855 Time: 0.016384\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: volta_h884cudnn_256x64_sliced1x2_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: -2422160065350346448\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -2422160065350346448 Time: 0.028672\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor8x8x4_simple_t1r1s1 Tactic: -2125188058121029448\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -2125188058121029448 Time: 0.027008\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: -2123887091022542343\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -2123887091022542343 Time: 0.027776\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor8x8x4_t1r1s1 Tactic: -539379305772590030\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -539379305772590030 Time: 0.012288\n",
      "[06/21/2022-18:22:25] [V] [TRT] Fastest Tactic: -9104099172933216230 Time: 0.012032\n",
      "[06/21/2022-18:22:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9104099172933216230\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Float(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Float(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Float(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Float(768,1,1,1) -> Half(96,1:8,96,96) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Float(768,1,768,768) -> Float(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Float(768,1,768,768) -> Half(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Float(768,1,768,768) -> Half(384,1:2,1,1) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Float(768,1,768,768) -> Half(96,1:8,96,96) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Half(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Half(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Half(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Half(768,1,1,1) -> Half(96,1:8,96,96) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Half(384,1:2,1,1) -> Float(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Half(384,1:2,1,1) -> Float(768,1,768,768) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Half(384,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Half(384,1:2,1,1) -> Half(96,1:8,96,96) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Half(96,1:8,96,96) -> Float(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Half(96,1:8,96,96) -> Float(768,1,768,768) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Half(96,1:8,96,96) -> Half(768,1,1,1) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning Reformat:Half(96,1:8,96,96) -> Half(384,1:2,1,1) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning format combination: Float(768,1,1,1) -> Float(2,1,1,1) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] --------------- Timing Runner: Gemm_517 (FusedConvActConvolution)\n",
      "[06/21/2022-18:22:25] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:25] [V] [TRT] --------------- Timing Runner: Gemm_517 (CudaDepthwiseConvolution)\n",
      "[06/21/2022-18:22:25] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:25] [V] [TRT] --------------- Timing Runner: Gemm_517 (CudnnConvolution)\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 0 Time: 0.112512\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 1 Time: 0.095616\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 2 Time: 0.13312\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 4 Time: 0.0256\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 5 Time: 0.027392\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 56 Time: 0.112384\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 57 Time: 0.095744\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 58 Time: 0.13312\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 60 Time: 0.0256\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 61 Time: 0.027136\n",
      "[06/21/2022-18:22:25] [V] [TRT] Fastest Tactic: 4 Time: 0.0256\n",
      "[06/21/2022-18:22:25] [V] [TRT] --------------- Timing Runner: Gemm_517 (CublasConvolution)\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 0 Time: 0.01024\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 1 Time: 0.009856\n",
      "[06/21/2022-18:22:25] [V] [TRT] Fastest Tactic: 1 Time: 0.009856\n",
      "[06/21/2022-18:22:25] [V] [TRT] --------------- Timing Runner: Gemm_517 (CaskConvolution)\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_517 Set Tactic Name: volta_scudnn_128x128_relu_interior_nn_v1 Tactic: 1754569683116234317\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 1754569683116234317 Time: 0.140288\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_517 Set Tactic Name: volta_scudnn_128x128_relu_medium_nn_v1 Tactic: 1825138533642645384\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 1825138533642645384 Time: 0.141696\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_517 Set Tactic Name: volta_scudnn_128x32_relu_interior_nn_v1 Tactic: 2733356012094739613\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 2733356012094739613 Time: 0.09216\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_517 Set Tactic Name: volta_scudnn_128x128_relu_small_nn_v1 Tactic: 3915320020053085238\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 3915320020053085238 Time: 0.140928\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_517 Set Tactic Name: volta_scudnn_128x64_relu_small_nn_v1 Tactic: 6808617066150061604\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 6808617066150061604 Time: 0.084224\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_517 Set Tactic Name: volta_scudnn_128x64_relu_interior_nn_v1 Tactic: 9091006216302412844\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 9091006216302412844 Time: 0.08192\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_517 Set Tactic Name: volta_scudnn_128x64_relu_medium_nn_v1 Tactic: -8060443123034038864\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -8060443123034038864 Time: 0.089088\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_conv1x1_f32f32_f32_f32_nchwkcrs_nchw_simt_small_batch_bias_relu Tactic: -6194327789991425125\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -6194327789991425125 Time: 0.00896\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_517 Set Tactic Name: volta_scudnn_128x32_relu_medium_nn_v1 Tactic: -4420849921117327522\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -4420849921117327522 Time: 0.07168\n",
      "[06/21/2022-18:22:25] [V] [TRT] Gemm_517 Set Tactic Name: volta_scudnn_128x32_relu_small_nn_v1 Tactic: -3946921629105938337\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: -3946921629105938337 Time: 0.093312\n",
      "[06/21/2022-18:22:25] [V] [TRT] Fastest Tactic: -6194327789991425125 Time: 0.00896\n",
      "[06/21/2022-18:22:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -6194327789991425125\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning format combination: Float(768,1,768,768) -> Float(2,1,2,2) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] --------------- Timing Runner: Gemm_517 (CudnnConvolution)\n",
      "[06/21/2022-18:22:25] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:25] [V] [TRT] --------------- Timing Runner: Gemm_517 (CublasConvolution)\n",
      "[06/21/2022-18:22:25] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:25] [V] [TRT] --------------- Timing Runner: Gemm_517 (CaskConvolution)\n",
      "[06/21/2022-18:22:25] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:25] [V] [TRT] *************** Autotuning format combination: Half(768,1,1,1) -> Half(2,1,1,1) ***************\n",
      "[06/21/2022-18:22:25] [V] [TRT] --------------- Timing Runner: Gemm_517 (CudnnConvolution)\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 0 Time: 0.114688\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 1 Time: 0.095232\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 2 Time: 0.132096\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 4 Time: 0.025728\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 5 Time: 0.027136\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 56 Time: 0.11456\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 58 Time: 0.132096\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 60 Time: 0.0256\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 61 Time: 0.026752\n",
      "[06/21/2022-18:22:25] [V] [TRT] Fastest Tactic: 60 Time: 0.0256\n",
      "[06/21/2022-18:22:25] [V] [TRT] --------------- Timing Runner: Gemm_517 (CublasConvolution)\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 0 Time: 0.01024\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 1 Time: 0.010112\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 2 Time: 0.009984\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 3 Time: 0.01024\n",
      "[06/21/2022-18:22:25] [V] [TRT] Tactic: 4 Time: 0.08256\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 5 Time: 0.024576\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 6 Time: 0.011776\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 7 Time: 0.01216\n",
      "[06/21/2022-18:22:26] [V] [TRT] Fastest Tactic: 2 Time: 0.009984\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Gemm_517 (CaskConvolution)\n",
      "[06/21/2022-18:22:26] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 2\n",
      "[06/21/2022-18:22:26] [V] [TRT] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(2,1,1,1) ***************\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Gemm_517 (CaskConvolution)\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_conv1x1_f16f16_f16_f16_nchw_vect_c_2kcrs_vect_c_2_nchw_simt_small_batch_bias_relu Tactic: -7852373803729529742\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -7852373803729529742 Time: 0.00896\n",
      "[06/21/2022-18:22:26] [V] [TRT] Fastest Tactic: -7852373803729529742 Time: 0.00896\n",
      "[06/21/2022-18:22:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7852373803729529742\n",
      "[06/21/2022-18:22:26] [V] [TRT] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(1,1:2,1,1) ***************\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Gemm_517 (FusedConvActConvolution)\n",
      "[06/21/2022-18:22:26] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Gemm_517 (CudnnConvolution)\n",
      "[06/21/2022-18:22:26] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Gemm_517 (CublasConvolution)\n",
      "[06/21/2022-18:22:26] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Gemm_517 (CaskConvolution)\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 2418518597804310654\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 2418518597804310654 Time: 0.04928\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 8292881859266835088\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 8292881859266835088 Time: 0.050176\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 8401509141903434922\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 8401509141903434922 Time: 0.047104\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -8654297089785671176\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -8654297089785671176 Time: 0.075136\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: -7140760933967189247\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -7140760933967189247 Time: 0.045824\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: -4097850214384059472\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -4097850214384059472 Time: 0.047104\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3689982367035295496\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -3689982367035295496 Time: 0.07552\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -2534402059426524406\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -2534402059426524406 Time: 0.074752\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -2027588946874785071\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -2027588946874785071 Time: 0.046976\n",
      "[06/21/2022-18:22:26] [V] [TRT] Fastest Tactic: -7140760933967189247 Time: 0.045824\n",
      "[06/21/2022-18:22:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7140760933967189247\n",
      "[06/21/2022-18:22:26] [V] [TRT] *************** Autotuning format combination: Half(96,1:8,96,96) -> Float(2,1,1,1) ***************\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Gemm_517 (CudnnConvolution)\n",
      "[06/21/2022-18:22:26] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Gemm_517 (CublasConvolution)\n",
      "[06/21/2022-18:22:26] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Gemm_517 (CaskConvolution)\n",
      "[06/21/2022-18:22:26] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:26] [V] [TRT] *************** Autotuning format combination: Half(96,1:8,96,96) -> Half(1,1:8,1,1) ***************\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Gemm_517 (CudaDepthwiseConvolution)\n",
      "[06/21/2022-18:22:26] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Gemm_517 (CudnnConvolution)\n",
      "[06/21/2022-18:22:26] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Gemm_517 (CublasConvolution)\n",
      "[06/21/2022-18:22:26] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Gemm_517 (CaskConvolution)\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_h884cudnn_256x64_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 2105695814191699972\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 2105695814191699972 Time: 0.0288\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 2689212690707793357\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 2689212690707793357 Time: 0.043904\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 2798075085844016892\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 2798075085844016892 Time: 0.027776\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 3091156937974993800\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 3091156937974993800 Time: 0.027648\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_h884cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3754069740140581927\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 3754069740140581927 Time: 0.030336\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 3932578551652369355\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 3932578551652369355 Time: 0.014336\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 5483093640784800285\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 5483093640784800285 Time: 0.019584\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_h884cudnn_128x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 5666160310350604399\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 5666160310350604399 Time: 0.030592\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_t1r1s1 Tactic: 5900614001783877430\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 5900614001783877430 Time: 0.021376\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_h884cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 5925270497649423688\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 5925270497649423688 Time: 0.043776\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 5999406432703271895\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 5999406432703271895 Time: 0.019328\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_h884cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 6680916730816870145\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 6680916730816870145 Time: 0.029056\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_h884cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7158029511300006471\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 7158029511300006471 Time: 0.02944\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_h884cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 7859952145590271433\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 7859952145590271433 Time: 0.028672\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_h884cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 8283847742354150423\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 8283847742354150423 Time: 0.030592\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 8642279798680442080\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 8642279798680442080 Time: 0.027648\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 9108067304506990859\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 9108067304506990859 Time: 0.019328\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor8x8x4_simple_t1r1s1 Tactic: -9104099172933216230\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -9104099172933216230 Time: 0.012032\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: -8956720569082607796\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -8956720569082607796 Time: 0.020864\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor8x8x4_t1r1s1 Tactic: -8952042869709043207\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -8952042869709043207 Time: 0.028672\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: -8898856569474934280\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -8898856569474934280 Time: 0.028544\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor8x8x4_t1r1s1 Tactic: -8774805574135441656\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -8774805574135441656 Time: 0.026496\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: -8520017388966620486\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -8520017388966620486 Time: 0.014336\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor8x8x4_t1r1s1 Tactic: -8487084252145372186\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -8487084252145372186 Time: 0.043904\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_h884cudnn_256x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: -8391760416076885205\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -8391760416076885205 Time: 0.043008\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: -7990268040387498660\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -7990268040387498660 Time: 0.016384\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor8x8x4_t1r1s1 Tactic: -7849113095413980300\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -7849113095413980300 Time: 0.04352\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: -5590418898350402100\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -5590418898350402100 Time: 0.019456\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: -5389631537202601150\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -5389631537202601150 Time: 0.043776\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_h884cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4534876761957424274\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -4534876761957424274 Time: 0.043008\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_h884cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3237051169894153788\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -3237051169894153788 Time: 0.028544\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_t1r1s1 Tactic: -2676138141351394855\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -2676138141351394855 Time: 0.016384\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: volta_h884cudnn_256x64_sliced1x2_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: -2422160065350346448\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -2422160065350346448 Time: 0.028544\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor8x8x4_simple_t1r1s1 Tactic: -2125188058121029448\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -2125188058121029448 Time: 0.026496\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: -2123887091022542343\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -2123887091022542343 Time: 0.027776\n",
      "[06/21/2022-18:22:26] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor8x8x4_t1r1s1 Tactic: -539379305772590030\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: -539379305772590030 Time: 0.012288\n",
      "[06/21/2022-18:22:26] [V] [TRT] Fastest Tactic: -9104099172933216230 Time: 0.012032\n",
      "[06/21/2022-18:22:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9104099172933216230\n",
      "[06/21/2022-18:22:26] [V] [TRT] *************** Autotuning Reformat:Float(2,1,1,1) -> Half(2,1,1,1) ***************\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 1002 Time: 0.007296\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 0 Time: 0.006144\n",
      "[06/21/2022-18:22:26] [V] [TRT] Fastest Tactic: 0 Time: 0.006144\n",
      "[06/21/2022-18:22:26] [V] [TRT] *************** Autotuning Reformat:Float(2,1,2,2) -> Float(2,1,1,1) ***************\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 1002 Time: 0.008064\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 0 Time: 0.006144\n",
      "[06/21/2022-18:22:26] [V] [TRT] Fastest Tactic: 0 Time: 0.006144\n",
      "[06/21/2022-18:22:26] [V] [TRT] *************** Autotuning Reformat:Float(2,1,2,2) -> Half(2,1,1,1) ***************\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 1002 Time: 0.007168\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 0 Time: 0.006144\n",
      "[06/21/2022-18:22:26] [V] [TRT] Fastest Tactic: 0 Time: 0.006144\n",
      "[06/21/2022-18:22:26] [V] [TRT] *************** Autotuning Reformat:Half(2,1,1,1) -> Float(2,1,1,1) ***************\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 1002 Time: 0.007168\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 0 Time: 0.005888\n",
      "[06/21/2022-18:22:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005888\n",
      "[06/21/2022-18:22:26] [V] [TRT] *************** Autotuning Reformat:Half(1,1:2,1,1) -> Float(2,1,1,1) ***************\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 1002 Time: 0.007168\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 0 Time: 0.006016\n",
      "[06/21/2022-18:22:26] [V] [TRT] Fastest Tactic: 0 Time: 0.006016\n",
      "[06/21/2022-18:22:26] [V] [TRT] *************** Autotuning Reformat:Half(1,1:2,1,1) -> Half(2,1,1,1) ***************\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 1002 Time: 0.007168\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 0 Time: 0.006016\n",
      "[06/21/2022-18:22:26] [V] [TRT] Fastest Tactic: 0 Time: 0.006016\n",
      "[06/21/2022-18:22:26] [V] [TRT] *************** Autotuning Reformat:Half(1,1:8,1,1) -> Float(2,1,1,1) ***************\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 1002 Time: 0.008064\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 0 Time: 0.006144\n",
      "[06/21/2022-18:22:26] [V] [TRT] Fastest Tactic: 0 Time: 0.006144\n",
      "[06/21/2022-18:22:26] [V] [TRT] *************** Autotuning Reformat:Half(1,1:8,1,1) -> Half(2,1,1,1) ***************\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 1002 Time: 0.007296\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 0 Time: 0.006144\n",
      "[06/21/2022-18:22:26] [V] [TRT] Fastest Tactic: 0 Time: 0.006144\n",
      "[06/21/2022-18:22:26] [V] [TRT] *************** Autotuning format combination: Float(2,1,1,1) -> Float(2,1) ***************\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 1025) [Shuffle] (Shuffle)\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 0 Time: 0.006016\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 1 Time: 0.01024\n",
      "[06/21/2022-18:22:26] [V] [TRT] Fastest Tactic: 0 Time: 0.006016\n",
      "[06/21/2022-18:22:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[06/21/2022-18:22:26] [V] [TRT] *************** Autotuning format combination: Half(2,1,1,1) -> Half(2,1) ***************\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 1025) [Shuffle] (Shuffle)\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 0 Time: 0.005888\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 1 Time: 0.010496\n",
      "[06/21/2022-18:22:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005888\n",
      "[06/21/2022-18:22:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[06/21/2022-18:22:26] [V] [TRT] *************** Autotuning Reformat:Half(2,1) -> Float(2,1) ***************\n",
      "[06/21/2022-18:22:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 1002 Time: 0.007168\n",
      "[06/21/2022-18:22:26] [V] [TRT] Tactic: 0 Time: 0.005888\n",
      "[06/21/2022-18:22:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005888\n",
      "[06/21/2022-18:22:26] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Gemm_515 + Relu_516 ((Unnamed Layer* 1008) [Shuffle]_output) from Half(768,1,1,1) to Half(384,1:2,1,1)\n",
      "[06/21/2022-18:22:26] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Gemm_517 (Relu_516_out_tensor) from Half(768,1,1,1) to Half(384,1:2,1,1)\n",
      "[06/21/2022-18:22:26] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to (Unnamed Layer* 1025) [Shuffle] ((Unnamed Layer* 1021) [Fully Connected]_output) from Half(2,1,1,1) to Float(2,1,1,1)\n",
      "[06/21/2022-18:22:26] [V] [TRT] For layer (Unnamed Layer* 1025) [Shuffle] a non-conforming implementation was chosen than was requested i.e. requested layer computation precision and output precision types were ignored because it resulted in faster network performance. Enable strict mode to try force choose a conforming implementation.\n",
      "[06/21/2022-18:22:26] [V] [TRT] Formats and tactics selection completed in 22.5861 seconds.\n",
      "[06/21/2022-18:22:26] [V] [TRT] After reformat layers: 16 layers\n",
      "[06/21/2022-18:22:26] [V] [TRT] Block size 14680064000\n",
      "[06/21/2022-18:22:26] [V] [TRT] Block size 196608\n",
      "[06/21/2022-18:22:26] [V] [TRT] Block size 196608\n",
      "[06/21/2022-18:22:26] [V] [TRT] Block size 196608\n",
      "[06/21/2022-18:22:26] [V] [TRT] Block size 1\n",
      "[06/21/2022-18:22:26] [V] [TRT] Total Activation Memory: 14680653825\n",
      "[06/21/2022-18:22:26] [I] [TRT] Detected 2 inputs and 1 output network tensors.\n",
      "[W] [06/21/2022-18:22:27] [TRT] Weights [name=192 + (Unnamed Layer* 112) [Shuffle]{ForeignNode[830 + (Unnamed Layer* 73) [Shuffle]...Add_512]}]: Converted FP32 positive or negative infinity in weights to corresponding FP16 infinity. Please modify the weights if this is not the desired behavior.\n",
      "[W] [TRT] Weights [name=306 + (Unnamed Layer* 272) [Shuffle]{ForeignNode[830 + (Unnamed Layer* 73) [Shuffle]...Add_512]}]: Converted FP32 positive or negative infinity in weights to corresponding FP16 infinity. Please modify the weights if this is not the desired behavior.\n",
      "[06/21/2022-18:22:27] [W] [TRT] Weights [name=420 + (Unnamed Layer* 432) [Shuffle]{ForeignNode[830 + (Unnamed Layer* 73) [Shuffle]...Add_512]}]: Converted FP32 positive or negative infinity in weights to corresponding FP16 infinity. Please modify the weights if this is not the desired behavior.\n",
      "[06/21/2022-18:22:27] [W] [TRT] Weights [name=534 + (Unnamed Layer* 592) [Shuffle]{ForeignNode[830 + (Unnamed Layer* 73) [Shuffle]...Add_512]}]: Converted FP32 positive or negative infinity in weights to corresponding FP16 infinity. Please modify the weights if this is not the desired behavior.\n",
      "[06/21/2022-18:22:27] [W] [TRT] Weights [name=648 + (Unnamed Layer* 752) [Shuffle]{ForeignNode[830 + (Unnamed Layer* 73) [Shuffle]...Add_512]}]: Converted FP32 positive or negative infinity in weights to corresponding FP16 infinity. Please modify the weights if this is not the desired behavior.\n",
      "[06/21/2022-18:22:27] [W] [TRT] Weights [name=762 + (Unnamed Layer* 912) [Shuffle]{ForeignNode[830 + (Unnamed Layer* 73) [Shuffle]...Add_512]}]: Converted FP32 positive or negative infinity in weights to corresponding FP16 infinity. Please modify the weights if this is not the desired behavior.\n",
      "[06/21/2022-18:22:27] [06/21/2022-18:22:36] [V] [TRT] Gemm_515 + Relu_516 Set Tactic Name: sm70_xmma_fprop_conv1x1_f16f16_f16_f16_nchw_vect_c_2kcrs_vect_c_2_nchw_simt_small_batch_bias_relu Tactic: -7852373803729529742\n",
      "[06/21/2022-18:22:36] [V] [TRT] Gemm_517 Set Tactic Name: sm70_xmma_fprop_conv1x1_f16f16_f16_f16_nchw_vect_c_2kcrs_vect_c_2_nchw_simt_small_batch_bias_relu Tactic: -7852373803729529742\n",
      "[06/21/2022-18:22:36] [V] [TRT] Layer: distilbert.embeddings.position_embeddings.weight HostPersistent: 0 DevicePersistent: 0\n",
      "[06/21/2022-18:22:36] [V] [TRT] Layer: 109 HostPersistent: 0 DevicePersistent: 0\n",
      "[06/21/2022-18:22:36] [V] [TRT] Layer: Slice_6 HostPersistent: 0 DevicePersistent: 0\n",
      "[06/21/2022-18:22:36] [V] [TRT] Layer: distilbert.embeddings.word_embeddings.weight HostPersistent: 0 DevicePersistent: 0\n",
      "[06/21/2022-18:22:36] [V] [TRT] Layer: Gather_7 HostPersistent: 0 DevicePersistent: 0\n",
      "[06/21/2022-18:22:36] [V] [TRT] Layer: Gather_8 HostPersistent: 0 DevicePersistent: 0\n",
      "[06/21/2022-18:22:36] [V] [TRT] Layer: {ForeignNode[830 + (Unnamed Layer* 73) [Shuffle]...Add_512]} HostPersistent: 32 DevicePersistent: 0\n",
      "[06/21/2022-18:22:36] [V] [TRT] Layer: 815 HostPersistent: 0 DevicePersistent: 0\n",
      "[06/21/2022-18:22:36] [V] [TRT] Layer: Gather_514 HostPersistent: 0 DevicePersistent: 0\n",
      "[06/21/2022-18:22:36] [V] [TRT] Layer: Gemm_515 + Relu_516 HostPersistent: 1120 DevicePersistent: 1184256\n",
      "[06/21/2022-18:22:36] [V] [TRT] Layer: Gemm_517 HostPersistent: 1120 DevicePersistent: 3584\n",
      "[06/21/2022-18:22:36] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 1025) [Shuffle] HostPersistent: 0 DevicePersistent: 0\n",
      "[06/21/2022-18:22:36] [I] [TRT] Total Host Persistent Memory: 2272\n",
      "[06/21/2022-18:22:36] [I] [TRT] Total Device Persistent Memory: 1187840\n",
      "[06/21/2022-18:22:36] [I] [TRT] Total Scratch Memory: 4522272\n",
      "[06/21/2022-18:22:36] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 83 MiB, GPU 4 MiB\n",
      "[06/21/2022-18:22:36] [V] [TRT] Using cublasLt a tactic source\n",
      "[06/21/2022-18:22:36] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 1476, GPU 3950 (MiB)\n",
      "[06/21/2022-18:22:36] [V] [TRT] Using cuDNN as a tactic source\n",
      "[06/21/2022-18:22:36] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 1476, GPU 3958 (MiB)\n",
      "[06/21/2022-18:22:36] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 1476, GPU 3942 (MiB)\n",
      "[06/21/2022-18:22:36] [V] [TRT] Engine generation completed in 33.3518 seconds.\n",
      "[06/21/2022-18:22:36] [V] [TRT] Deleting timing cache: 48 entries, 24 hits\n",
      "[06/21/2022-18:22:36] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 1476, GPU 3924 (MiB)\n",
      "[06/21/2022-18:22:36] [V] [TRT] Engine Layer Information:\n",
      "Layer(Constant): distilbert.embeddings.position_embeddings.weight, Tactic: 0,  -> (Unnamed Layer* 21) [Constant]_output[Half(512,768)]\n",
      "Layer(Constant): 109, Tactic: 0,  -> (Unnamed Layer* 4) [Constant]_output[Int32(1,512)]\n",
      "Layer(Reformat): Slice_6, Tactic: 0, (Unnamed Layer* 4) [Constant]_output[Int32(1,128)] -> 116[Int32(1,128)]\n",
      "Layer(Constant): distilbert.embeddings.word_embeddings.weight, Tactic: 0,  -> (Unnamed Layer* 19) [Constant]_output[Half(30522,768)]\n",
      "Layer(Gather): Gather_7, Tactic: 9, (Unnamed Layer* 19) [Constant]_output[Half(30522,768)], input_ids[Int32(1,128)] -> 117[Half(1,128,768)]\n",
      "Layer(Gather): Gather_8, Tactic: 9, (Unnamed Layer* 21) [Constant]_output[Half(512,768)], 116[Int32(1,128)] -> 118[Half(1,128,768)]\n",
      "Layer(Myelin): {ForeignNode[830 + (Unnamed Layer* 73) [Shuffle]...Add_512]}, Tactic: 0, 117[Half(1,128,768)], 118[Half(1,128,768)], attention_mask[Int32(1,128)] -> 814[Half(1,128,768)]\n",
      "Layer(Constant): 815, Tactic: 0,  -> (Unnamed Layer* 1001) [Constant]_output[Int32()]\n",
      "Layer(Gather): Gather_514, Tactic: 8, 814[Half(1,128,768)], (Unnamed Layer* 1001) [Constant]_output[Int32()] -> 816[Half(1,768)]\n",
      "Layer(CaskConvolution): Gemm_515 + Relu_516, Tactic: -7852373803729529742, Reformatted Input Tensor 0 to Gemm_515 + Relu_516[Half(1,768,1,1)] -> Relu_516_out_tensor[Half(1,768,1,1)]\n",
      "Layer(CaskConvolution): Gemm_517, Tactic: -7852373803729529742, Reformatted Input Tensor 0 to Gemm_517[Half(1,768,1,1)] -> (Unnamed Layer* 1021) [Fully Connected]_output[Half(1,2,1,1)]\n",
      "Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 1025) [Shuffle], Tactic: 0, (Unnamed Layer* 1021) [Fully Connected]_output[Half(1,2,1,1)] -> Reformatted Input Tensor 0 to (Unnamed Layer* 1025) [Shuffle][Float(1,2,1,1)]\n",
      "[06/21/2022-18:22:36] [I] [TRT] [MemUsageSnapshot] Builder end: CPU 1475 MiB, GPU 3924 MiB\n",
      "[06/21/2022-18:22:36] [I] [TRT] Loaded engine size: 129 MB\n",
      "[06/21/2022-18:22:36] [I] [TRT] [MemUsageSnapshot] deserializeCudaEngine begin: CPU 1603 MiB, GPU 3796 MiB\n",
      "[06/21/2022-18:22:37] [V] [TRT] Using cublasLt a tactic source\n",
      "[06/21/2022-18:22:37] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 1604, GPU 3934 (MiB)\n",
      "[06/21/2022-18:22:37] [V] [TRT] Using cuDNN as a tactic source\n",
      "[06/21/2022-18:22:37] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 1604, GPU 3942 (MiB)\n",
      "[06/21/2022-18:22:37] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 1604, GPU 3924 (MiB)\n",
      "[06/21/2022-18:22:37] [V] [TRT] Deserialization required 443424 microseconds.\n",
      "[06/21/2022-18:22:37] [I] [TRT] [MemUsageSnapshot] deserializeCudaEngine end: CPU 1604 MiB, GPU 3924 MiB\n",
      "[06/21/2022-18:22:37] [I] Engine built in 37.2163 sec.\n",
      "[06/21/2022-18:22:37] [I] [TRT] [MemUsageSnapshot] ExecutionContext creation begin: CPU 1216 MiB, GPU 3924 MiB\n",
      "[06/21/2022-18:22:37] [V] [TRT] Using cublasLt a tactic source\n",
      "[06/21/2022-18:22:37] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 1216, GPU 3934 (MiB)\n",
      "[06/21/2022-18:22:37] [V] [TRT] Using cuDNN as a tactic source\n",
      "[06/21/2022-18:22:37] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 1216, GPU 3942 (MiB)\n",
      "[06/21/2022-18:22:37] [V] [TRT] Total per-runner device memory is 1187840\n",
      "[06/21/2022-18:22:37] [V] [TRT] Total per-runner host memory is 2272\n",
      "[06/21/2022-18:22:37] [V] [TRT] Allocated activation device memory of size 5112320\n",
      "[06/21/2022-18:22:38] [V] [TRT] myelinAllocCb allocated GPU (data-constants) 8 bytes at 0x304e98500.\n",
      "[06/21/2022-18:22:38] [I] [TRT] [MemUsageSnapshot] ExecutionContext creation end: CPU 1219 MiB, GPU 3948 MiB\n",
      "[06/21/2022-18:22:38] [I] Created input binding for input_ids with dimensions 1x128\n",
      "[06/21/2022-18:22:38] [I] Created input binding for attention_mask with dimensions 1x128\n",
      "[06/21/2022-18:22:38] [I] Created output binding for logits with dimensions 1x2\n",
      "[06/21/2022-18:22:38] [I] Starting inference\n",
      "[06/21/2022-18:22:38] [V] [TRT] myelinAllocCb allocated GPU 4521984 bytes at 0x30b400000.\n",
      "[06/21/2022-18:22:41] [I] Warmup completed 218 queries over 200 ms\n",
      "[06/21/2022-18:22:41] [I] Timing trace has 3567 queries over 3.00147 s\n",
      "[06/21/2022-18:22:41] [I] \n",
      "[06/21/2022-18:22:41] [I] === Trace details ===\n",
      "[06/21/2022-18:22:41] [I] Trace averages of 10 runs:\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.837094 ms - Host latency: 0.852377 ms (end to end 0.86543 ms, enqueue 0.838387 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.836299 ms - Host latency: 0.851588 ms (end to end 0.864452 ms, enqueue 0.837575 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.822328 ms - Host latency: 0.838582 ms (end to end 0.85152 ms, enqueue 0.820172 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806033 ms - Host latency: 0.821571 ms (end to end 0.833282 ms, enqueue 0.806914 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.812396 ms - Host latency: 0.827924 ms (end to end 0.839911 ms, enqueue 0.813167 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.8032 ms - Host latency: 0.82054 ms (end to end 0.832666 ms, enqueue 0.803065 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807426 ms - Host latency: 0.823614 ms (end to end 0.834364 ms, enqueue 0.807047 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.828415 ms - Host latency: 0.84491 ms (end to end 0.856879 ms, enqueue 0.827399 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.792676 ms - Host latency: 0.808441 ms (end to end 0.819824 ms, enqueue 0.792026 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.777524 ms - Host latency: 0.792691 ms (end to end 0.803732 ms, enqueue 0.777905 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.777863 ms - Host latency: 0.793283 ms (end to end 0.804636 ms, enqueue 0.779169 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773837 ms - Host latency: 0.78902 ms (end to end 0.800827 ms, enqueue 0.77504 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.774045 ms - Host latency: 0.789227 ms (end to end 0.801569 ms, enqueue 0.77514 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772711 ms - Host latency: 0.788339 ms (end to end 0.799182 ms, enqueue 0.773196 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.777911 ms - Host latency: 0.793225 ms (end to end 0.804758 ms, enqueue 0.778659 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773837 ms - Host latency: 0.788974 ms (end to end 0.800961 ms, enqueue 0.774789 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.777628 ms - Host latency: 0.793304 ms (end to end 0.804895 ms, enqueue 0.778485 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773526 ms - Host latency: 0.788959 ms (end to end 0.800351 ms, enqueue 0.773834 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.776062 ms - Host latency: 0.791049 ms (end to end 0.802567 ms, enqueue 0.776343 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773837 ms - Host latency: 0.78895 ms (end to end 0.800366 ms, enqueue 0.774265 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.777802 ms - Host latency: 0.79288 ms (end to end 0.805008 ms, enqueue 0.779199 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773407 ms - Host latency: 0.788922 ms (end to end 0.800659 ms, enqueue 0.774017 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.77374 ms - Host latency: 0.788928 ms (end to end 0.800955 ms, enqueue 0.774509 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773318 ms - Host latency: 0.78837 ms (end to end 0.799826 ms, enqueue 0.774509 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772708 ms - Host latency: 0.788074 ms (end to end 0.799341 ms, enqueue 0.773413 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.774249 ms - Host latency: 0.789709 ms (end to end 0.801138 ms, enqueue 0.774011 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772501 ms - Host latency: 0.788412 ms (end to end 0.799829 ms, enqueue 0.77283 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771683 ms - Host latency: 0.787164 ms (end to end 0.798581 ms, enqueue 0.772568 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.77496 ms - Host latency: 0.79039 ms (end to end 0.801227 ms, enqueue 0.775885 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.777582 ms - Host latency: 0.793533 ms (end to end 0.805045 ms, enqueue 0.777502 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773633 ms - Host latency: 0.789236 ms (end to end 0.799939 ms, enqueue 0.773395 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773218 ms - Host latency: 0.788965 ms (end to end 0.799945 ms, enqueue 0.773593 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.777835 ms - Host latency: 0.793753 ms (end to end 0.806177 ms, enqueue 0.779099 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.778033 ms - Host latency: 0.792841 ms (end to end 0.805096 ms, enqueue 0.780014 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773422 ms - Host latency: 0.788895 ms (end to end 0.799915 ms, enqueue 0.773791 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772507 ms - Host latency: 0.787634 ms (end to end 0.799234 ms, enqueue 0.773196 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772815 ms - Host latency: 0.788272 ms (end to end 0.799283 ms, enqueue 0.773227 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.776462 ms - Host latency: 0.792102 ms (end to end 0.803372 ms, enqueue 0.777289 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.77077 ms - Host latency: 0.786218 ms (end to end 0.797607 ms, enqueue 0.771429 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772089 ms - Host latency: 0.787433 ms (end to end 0.799109 ms, enqueue 0.772266 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.770978 ms - Host latency: 0.78634 ms (end to end 0.797754 ms, enqueue 0.771197 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.782159 ms - Host latency: 0.797418 ms (end to end 0.809668 ms, enqueue 0.783936 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.77312 ms - Host latency: 0.788605 ms (end to end 0.800275 ms, enqueue 0.774274 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772595 ms - Host latency: 0.787714 ms (end to end 0.799451 ms, enqueue 0.773328 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772211 ms - Host latency: 0.787433 ms (end to end 0.798895 ms, enqueue 0.772565 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.777106 ms - Host latency: 0.792474 ms (end to end 0.803766 ms, enqueue 0.777136 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.7724 ms - Host latency: 0.788544 ms (end to end 0.799432 ms, enqueue 0.773084 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771478 ms - Host latency: 0.786896 ms (end to end 0.797778 ms, enqueue 0.771484 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.770966 ms - Host latency: 0.78642 ms (end to end 0.797614 ms, enqueue 0.771472 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771881 ms - Host latency: 0.787189 ms (end to end 0.798346 ms, enqueue 0.771527 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.774854 ms - Host latency: 0.790137 ms (end to end 0.801257 ms, enqueue 0.775757 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773126 ms - Host latency: 0.788251 ms (end to end 0.799542 ms, enqueue 0.77334 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772296 ms - Host latency: 0.78761 ms (end to end 0.798853 ms, enqueue 0.772552 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772498 ms - Host latency: 0.787708 ms (end to end 0.799402 ms, enqueue 0.773706 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.775226 ms - Host latency: 0.791028 ms (end to end 0.802808 ms, enqueue 0.775391 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772614 ms - Host latency: 0.788318 ms (end to end 0.798633 ms, enqueue 0.772723 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771857 ms - Host latency: 0.787042 ms (end to end 0.798584 ms, enqueue 0.772412 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.769946 ms - Host latency: 0.785663 ms (end to end 0.79635 ms, enqueue 0.770172 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.776917 ms - Host latency: 0.792047 ms (end to end 0.803711 ms, enqueue 0.777222 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773212 ms - Host latency: 0.788544 ms (end to end 0.800183 ms, enqueue 0.77403 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.786017 ms - Host latency: 0.801257 ms (end to end 0.813098 ms, enqueue 0.78783 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.808612 ms - Host latency: 0.823535 ms (end to end 0.837054 ms, enqueue 0.808014 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.809326 ms - Host latency: 0.824615 ms (end to end 0.837689 ms, enqueue 0.810992 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.803882 ms - Host latency: 0.81875 ms (end to end 0.831635 ms, enqueue 0.806158 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.810394 ms - Host latency: 0.824969 ms (end to end 0.837762 ms, enqueue 0.812775 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806409 ms - Host latency: 0.821246 ms (end to end 0.834094 ms, enqueue 0.808514 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.805939 ms - Host latency: 0.820966 ms (end to end 0.834051 ms, enqueue 0.809094 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.805664 ms - Host latency: 0.820605 ms (end to end 0.833875 ms, enqueue 0.808221 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.808356 ms - Host latency: 0.822986 ms (end to end 0.836487 ms, enqueue 0.810822 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.808154 ms - Host latency: 0.824298 ms (end to end 0.837238 ms, enqueue 0.811176 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807825 ms - Host latency: 0.822491 ms (end to end 0.835339 ms, enqueue 0.810529 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.803595 ms - Host latency: 0.81825 ms (end to end 0.831061 ms, enqueue 0.805908 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.805078 ms - Host latency: 0.819727 ms (end to end 0.83277 ms, enqueue 0.808197 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806897 ms - Host latency: 0.821533 ms (end to end 0.834479 ms, enqueue 0.809521 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.801959 ms - Host latency: 0.816687 ms (end to end 0.829413 ms, enqueue 0.804297 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.80628 ms - Host latency: 0.821185 ms (end to end 0.834393 ms, enqueue 0.808746 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807916 ms - Host latency: 0.82262 ms (end to end 0.835077 ms, enqueue 0.810669 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.803937 ms - Host latency: 0.818738 ms (end to end 0.831421 ms, enqueue 0.805933 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807306 ms - Host latency: 0.822272 ms (end to end 0.834381 ms, enqueue 0.808698 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.808624 ms - Host latency: 0.824091 ms (end to end 0.836829 ms, enqueue 0.80705 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806128 ms - Host latency: 0.822174 ms (end to end 0.834802 ms, enqueue 0.807855 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.805548 ms - Host latency: 0.820312 ms (end to end 0.833197 ms, enqueue 0.807629 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806177 ms - Host latency: 0.821283 ms (end to end 0.834119 ms, enqueue 0.809045 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.805145 ms - Host latency: 0.820038 ms (end to end 0.833124 ms, enqueue 0.807642 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.803912 ms - Host latency: 0.818866 ms (end to end 0.831757 ms, enqueue 0.805975 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.805743 ms - Host latency: 0.82088 ms (end to end 0.833527 ms, enqueue 0.807892 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.803613 ms - Host latency: 0.819049 ms (end to end 0.834552 ms, enqueue 0.804663 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.804846 ms - Host latency: 0.821381 ms (end to end 0.835132 ms, enqueue 0.80614 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.80766 ms - Host latency: 0.823041 ms (end to end 0.836377 ms, enqueue 0.810205 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.808301 ms - Host latency: 0.82323 ms (end to end 0.836249 ms, enqueue 0.810638 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807117 ms - Host latency: 0.822015 ms (end to end 0.834924 ms, enqueue 0.809698 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.80238 ms - Host latency: 0.817419 ms (end to end 0.830194 ms, enqueue 0.80462 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.810223 ms - Host latency: 0.825287 ms (end to end 0.838373 ms, enqueue 0.813043 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.808734 ms - Host latency: 0.823798 ms (end to end 0.837103 ms, enqueue 0.811914 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806915 ms - Host latency: 0.821936 ms (end to end 0.835455 ms, enqueue 0.809259 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807471 ms - Host latency: 0.822864 ms (end to end 0.83595 ms, enqueue 0.809808 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807025 ms - Host latency: 0.822192 ms (end to end 0.835394 ms, enqueue 0.809485 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.805524 ms - Host latency: 0.820251 ms (end to end 0.833679 ms, enqueue 0.807794 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.799042 ms - Host latency: 0.814154 ms (end to end 0.827557 ms, enqueue 0.801666 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.805762 ms - Host latency: 0.820776 ms (end to end 0.834094 ms, enqueue 0.808594 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.808435 ms - Host latency: 0.823218 ms (end to end 0.836768 ms, enqueue 0.811377 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.808398 ms - Host latency: 0.823242 ms (end to end 0.836157 ms, enqueue 0.811304 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807837 ms - Host latency: 0.822668 ms (end to end 0.835645 ms, enqueue 0.810999 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.810828 ms - Host latency: 0.825732 ms (end to end 0.838647 ms, enqueue 0.813684 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807031 ms - Host latency: 0.821912 ms (end to end 0.834863 ms, enqueue 0.809961 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807092 ms - Host latency: 0.822656 ms (end to end 0.835156 ms, enqueue 0.809021 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806531 ms - Host latency: 0.821411 ms (end to end 0.833667 ms, enqueue 0.809448 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.809436 ms - Host latency: 0.824268 ms (end to end 0.837305 ms, enqueue 0.812842 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806702 ms - Host latency: 0.821594 ms (end to end 0.834814 ms, enqueue 0.809778 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.80188 ms - Host latency: 0.816602 ms (end to end 0.829773 ms, enqueue 0.803967 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.801599 ms - Host latency: 0.816431 ms (end to end 0.829236 ms, enqueue 0.803906 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.814954 ms - Host latency: 0.829651 ms (end to end 0.842712 ms, enqueue 0.817419 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.816577 ms - Host latency: 0.831567 ms (end to end 0.844458 ms, enqueue 0.819458 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.809302 ms - Host latency: 0.823962 ms (end to end 0.837305 ms, enqueue 0.811963 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.812695 ms - Host latency: 0.828735 ms (end to end 0.842346 ms, enqueue 0.815417 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.805481 ms - Host latency: 0.821045 ms (end to end 0.834912 ms, enqueue 0.808105 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.80498 ms - Host latency: 0.81969 ms (end to end 0.833081 ms, enqueue 0.807678 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.804236 ms - Host latency: 0.819189 ms (end to end 0.832178 ms, enqueue 0.806921 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.8104 ms - Host latency: 0.825183 ms (end to end 0.838879 ms, enqueue 0.813794 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806384 ms - Host latency: 0.821118 ms (end to end 0.834631 ms, enqueue 0.809326 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.803003 ms - Host latency: 0.818237 ms (end to end 0.831763 ms, enqueue 0.805615 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.804639 ms - Host latency: 0.819446 ms (end to end 0.832861 ms, enqueue 0.807556 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.81311 ms - Host latency: 0.827869 ms (end to end 0.841357 ms, enqueue 0.816199 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.804736 ms - Host latency: 0.819568 ms (end to end 0.832874 ms, enqueue 0.807397 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.810999 ms - Host latency: 0.82561 ms (end to end 0.839063 ms, enqueue 0.813953 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.810608 ms - Host latency: 0.825378 ms (end to end 0.839197 ms, enqueue 0.813989 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.815625 ms - Host latency: 0.830469 ms (end to end 0.843506 ms, enqueue 0.819299 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.814893 ms - Host latency: 0.829797 ms (end to end 0.843079 ms, enqueue 0.818311 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.812183 ms - Host latency: 0.827209 ms (end to end 0.840808 ms, enqueue 0.815234 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.804724 ms - Host latency: 0.819714 ms (end to end 0.833008 ms, enqueue 0.807678 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.803162 ms - Host latency: 0.817908 ms (end to end 0.830798 ms, enqueue 0.805273 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.803711 ms - Host latency: 0.819043 ms (end to end 0.832422 ms, enqueue 0.806372 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.800342 ms - Host latency: 0.815247 ms (end to end 0.82832 ms, enqueue 0.80332 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.80199 ms - Host latency: 0.819739 ms (end to end 0.833618 ms, enqueue 0.803503 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.811182 ms - Host latency: 0.826208 ms (end to end 0.839233 ms, enqueue 0.810669 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.808545 ms - Host latency: 0.823535 ms (end to end 0.836926 ms, enqueue 0.812244 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806885 ms - Host latency: 0.821777 ms (end to end 0.83501 ms, enqueue 0.809802 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.804224 ms - Host latency: 0.819226 ms (end to end 0.832654 ms, enqueue 0.807288 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.804736 ms - Host latency: 0.819495 ms (end to end 0.832043 ms, enqueue 0.807349 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.801782 ms - Host latency: 0.816638 ms (end to end 0.829932 ms, enqueue 0.804187 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.817493 ms - Host latency: 0.833752 ms (end to end 0.848071 ms, enqueue 0.818591 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.784521 ms - Host latency: 0.799719 ms (end to end 0.813428 ms, enqueue 0.786975 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.819226 ms - Host latency: 0.834497 ms (end to end 0.847388 ms, enqueue 0.820776 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.802271 ms - Host latency: 0.817041 ms (end to end 0.829736 ms, enqueue 0.804834 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.80741 ms - Host latency: 0.822949 ms (end to end 0.836328 ms, enqueue 0.810657 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806445 ms - Host latency: 0.821338 ms (end to end 0.83457 ms, enqueue 0.809497 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.809033 ms - Host latency: 0.823938 ms (end to end 0.837244 ms, enqueue 0.812219 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806897 ms - Host latency: 0.822217 ms (end to end 0.835205 ms, enqueue 0.810034 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.810974 ms - Host latency: 0.826489 ms (end to end 0.839929 ms, enqueue 0.814331 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.814209 ms - Host latency: 0.828943 ms (end to end 0.842505 ms, enqueue 0.817468 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.813306 ms - Host latency: 0.831335 ms (end to end 0.844275 ms, enqueue 0.814563 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.813318 ms - Host latency: 0.82804 ms (end to end 0.840906 ms, enqueue 0.815527 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807605 ms - Host latency: 0.822327 ms (end to end 0.8354 ms, enqueue 0.810254 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806873 ms - Host latency: 0.821802 ms (end to end 0.834705 ms, enqueue 0.810217 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.804016 ms - Host latency: 0.818958 ms (end to end 0.832458 ms, enqueue 0.806238 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.805359 ms - Host latency: 0.820471 ms (end to end 0.832996 ms, enqueue 0.807751 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.80929 ms - Host latency: 0.824084 ms (end to end 0.837024 ms, enqueue 0.811487 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806506 ms - Host latency: 0.821314 ms (end to end 0.834631 ms, enqueue 0.809656 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.804968 ms - Host latency: 0.819678 ms (end to end 0.832434 ms, enqueue 0.807532 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.808752 ms - Host latency: 0.823669 ms (end to end 0.836548 ms, enqueue 0.811877 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807251 ms - Host latency: 0.822339 ms (end to end 0.835474 ms, enqueue 0.809973 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807373 ms - Host latency: 0.822449 ms (end to end 0.835095 ms, enqueue 0.81012 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.808374 ms - Host latency: 0.823669 ms (end to end 0.836072 ms, enqueue 0.811523 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.809851 ms - Host latency: 0.82489 ms (end to end 0.837805 ms, enqueue 0.812781 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806494 ms - Host latency: 0.821545 ms (end to end 0.834143 ms, enqueue 0.808948 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.804639 ms - Host latency: 0.819373 ms (end to end 0.832593 ms, enqueue 0.806287 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.809961 ms - Host latency: 0.825049 ms (end to end 0.838 ms, enqueue 0.81261 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.803296 ms - Host latency: 0.818115 ms (end to end 0.831079 ms, enqueue 0.805847 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.803686 ms - Host latency: 0.818713 ms (end to end 0.831262 ms, enqueue 0.805908 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.8078 ms - Host latency: 0.822888 ms (end to end 0.835864 ms, enqueue 0.810913 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807568 ms - Host latency: 0.822766 ms (end to end 0.835669 ms, enqueue 0.810669 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.810522 ms - Host latency: 0.825598 ms (end to end 0.838306 ms, enqueue 0.813391 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.80907 ms - Host latency: 0.823767 ms (end to end 0.836548 ms, enqueue 0.811316 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.809277 ms - Host latency: 0.824048 ms (end to end 0.837219 ms, enqueue 0.812256 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.811353 ms - Host latency: 0.826428 ms (end to end 0.839417 ms, enqueue 0.813684 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.810071 ms - Host latency: 0.825244 ms (end to end 0.837732 ms, enqueue 0.812659 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806165 ms - Host latency: 0.82135 ms (end to end 0.834363 ms, enqueue 0.808887 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.805774 ms - Host latency: 0.821082 ms (end to end 0.833252 ms, enqueue 0.807349 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807104 ms - Host latency: 0.825415 ms (end to end 0.837463 ms, enqueue 0.808606 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.805334 ms - Host latency: 0.82052 ms (end to end 0.833862 ms, enqueue 0.808289 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.802991 ms - Host latency: 0.817908 ms (end to end 0.830762 ms, enqueue 0.805774 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.810657 ms - Host latency: 0.82533 ms (end to end 0.838379 ms, enqueue 0.813098 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.808325 ms - Host latency: 0.824109 ms (end to end 0.840015 ms, enqueue 0.809143 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806604 ms - Host latency: 0.821411 ms (end to end 0.834131 ms, enqueue 0.808594 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.801746 ms - Host latency: 0.816394 ms (end to end 0.828931 ms, enqueue 0.805164 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.802979 ms - Host latency: 0.818225 ms (end to end 0.831677 ms, enqueue 0.806177 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.811743 ms - Host latency: 0.826685 ms (end to end 0.838977 ms, enqueue 0.81449 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807129 ms - Host latency: 0.822009 ms (end to end 0.835242 ms, enqueue 0.809741 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.8078 ms - Host latency: 0.822864 ms (end to end 0.83584 ms, enqueue 0.810657 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.808606 ms - Host latency: 0.823364 ms (end to end 0.836218 ms, enqueue 0.810754 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807788 ms - Host latency: 0.822583 ms (end to end 0.835889 ms, enqueue 0.809851 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.804712 ms - Host latency: 0.819482 ms (end to end 0.832544 ms, enqueue 0.807837 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.802966 ms - Host latency: 0.817566 ms (end to end 0.830542 ms, enqueue 0.805334 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.809155 ms - Host latency: 0.824011 ms (end to end 0.837512 ms, enqueue 0.812048 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.809229 ms - Host latency: 0.824072 ms (end to end 0.837732 ms, enqueue 0.812647 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.811426 ms - Host latency: 0.827515 ms (end to end 0.839905 ms, enqueue 0.814014 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807898 ms - Host latency: 0.822729 ms (end to end 0.835193 ms, enqueue 0.811353 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.812219 ms - Host latency: 0.827295 ms (end to end 0.840137 ms, enqueue 0.815063 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.814246 ms - Host latency: 0.828894 ms (end to end 0.842004 ms, enqueue 0.817017 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806384 ms - Host latency: 0.821314 ms (end to end 0.834607 ms, enqueue 0.809045 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807068 ms - Host latency: 0.822034 ms (end to end 0.835571 ms, enqueue 0.810022 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.80813 ms - Host latency: 0.823645 ms (end to end 0.836316 ms, enqueue 0.810803 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.802344 ms - Host latency: 0.817224 ms (end to end 0.830029 ms, enqueue 0.804968 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806018 ms - Host latency: 0.82102 ms (end to end 0.83374 ms, enqueue 0.808704 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.811646 ms - Host latency: 0.826575 ms (end to end 0.839758 ms, enqueue 0.814734 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.804736 ms - Host latency: 0.820593 ms (end to end 0.832776 ms, enqueue 0.806958 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.801794 ms - Host latency: 0.816809 ms (end to end 0.829358 ms, enqueue 0.804309 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.80686 ms - Host latency: 0.822754 ms (end to end 0.836218 ms, enqueue 0.809839 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.808838 ms - Host latency: 0.823926 ms (end to end 0.837329 ms, enqueue 0.811182 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806311 ms - Host latency: 0.821497 ms (end to end 0.83418 ms, enqueue 0.809021 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.809558 ms - Host latency: 0.824927 ms (end to end 0.838086 ms, enqueue 0.811963 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807813 ms - Host latency: 0.822815 ms (end to end 0.835791 ms, enqueue 0.810449 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806799 ms - Host latency: 0.822009 ms (end to end 0.835498 ms, enqueue 0.809802 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.805347 ms - Host latency: 0.820459 ms (end to end 0.834033 ms, enqueue 0.808228 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.805786 ms - Host latency: 0.820752 ms (end to end 0.83335 ms, enqueue 0.808765 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.804541 ms - Host latency: 0.820215 ms (end to end 0.832556 ms, enqueue 0.807324 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.804614 ms - Host latency: 0.820801 ms (end to end 0.834534 ms, enqueue 0.807739 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807654 ms - Host latency: 0.823547 ms (end to end 0.836829 ms, enqueue 0.810828 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807202 ms - Host latency: 0.822412 ms (end to end 0.835547 ms, enqueue 0.809717 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807544 ms - Host latency: 0.822314 ms (end to end 0.835498 ms, enqueue 0.810596 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.80542 ms - Host latency: 0.820142 ms (end to end 0.833276 ms, enqueue 0.807861 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.808057 ms - Host latency: 0.822925 ms (end to end 0.836108 ms, enqueue 0.810889 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.805981 ms - Host latency: 0.820654 ms (end to end 0.834058 ms, enqueue 0.808032 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.804907 ms - Host latency: 0.8198 ms (end to end 0.832715 ms, enqueue 0.807373 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.805786 ms - Host latency: 0.821289 ms (end to end 0.834863 ms, enqueue 0.808325 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807544 ms - Host latency: 0.822632 ms (end to end 0.835522 ms, enqueue 0.809668 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.804712 ms - Host latency: 0.819653 ms (end to end 0.832373 ms, enqueue 0.807397 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.802197 ms - Host latency: 0.817773 ms (end to end 0.830225 ms, enqueue 0.804907 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.808716 ms - Host latency: 0.823438 ms (end to end 0.836401 ms, enqueue 0.810718 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.809424 ms - Host latency: 0.824341 ms (end to end 0.837402 ms, enqueue 0.812012 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.804297 ms - Host latency: 0.819482 ms (end to end 0.832471 ms, enqueue 0.806787 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.810181 ms - Host latency: 0.825513 ms (end to end 0.838452 ms, enqueue 0.811963 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.803735 ms - Host latency: 0.818921 ms (end to end 0.831836 ms, enqueue 0.806006 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.80835 ms - Host latency: 0.82395 ms (end to end 0.837085 ms, enqueue 0.810645 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.804053 ms - Host latency: 0.819189 ms (end to end 0.832373 ms, enqueue 0.805762 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.807446 ms - Host latency: 0.822534 ms (end to end 0.835376 ms, enqueue 0.809692 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.808154 ms - Host latency: 0.822852 ms (end to end 0.836011 ms, enqueue 0.810522 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.803125 ms - Host latency: 0.817896 ms (end to end 0.830566 ms, enqueue 0.805029 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.806274 ms - Host latency: 0.821069 ms (end to end 0.834375 ms, enqueue 0.808545 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.809131 ms - Host latency: 0.823828 ms (end to end 0.837427 ms, enqueue 0.812036 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.808594 ms - Host latency: 0.823657 ms (end to end 0.836865 ms, enqueue 0.811743 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.803662 ms - Host latency: 0.818579 ms (end to end 0.831592 ms, enqueue 0.806201 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.805103 ms - Host latency: 0.82019 ms (end to end 0.833496 ms, enqueue 0.807593 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771216 ms - Host latency: 0.78689 ms (end to end 0.798096 ms, enqueue 0.772021 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.774023 ms - Host latency: 0.789136 ms (end to end 0.800977 ms, enqueue 0.775269 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.774609 ms - Host latency: 0.789624 ms (end to end 0.801099 ms, enqueue 0.775366 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.774121 ms - Host latency: 0.789404 ms (end to end 0.801343 ms, enqueue 0.775513 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772705 ms - Host latency: 0.787964 ms (end to end 0.799585 ms, enqueue 0.773779 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.783521 ms - Host latency: 0.79895 ms (end to end 0.812402 ms, enqueue 0.785889 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.770825 ms - Host latency: 0.786401 ms (end to end 0.797339 ms, enqueue 0.771313 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.77373 ms - Host latency: 0.788647 ms (end to end 0.801099 ms, enqueue 0.774561 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.770264 ms - Host latency: 0.785645 ms (end to end 0.796802 ms, enqueue 0.770728 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773926 ms - Host latency: 0.789111 ms (end to end 0.800757 ms, enqueue 0.774414 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.776099 ms - Host latency: 0.79126 ms (end to end 0.802515 ms, enqueue 0.776392 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.780762 ms - Host latency: 0.796484 ms (end to end 0.809131 ms, enqueue 0.782202 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.776733 ms - Host latency: 0.792285 ms (end to end 0.803882 ms, enqueue 0.77749 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773047 ms - Host latency: 0.788232 ms (end to end 0.799829 ms, enqueue 0.773853 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771777 ms - Host latency: 0.787354 ms (end to end 0.798804 ms, enqueue 0.772217 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771289 ms - Host latency: 0.787305 ms (end to end 0.799316 ms, enqueue 0.771851 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.774439 ms - Host latency: 0.78977 ms (end to end 0.80166 ms, enqueue 0.775293 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.787085 ms - Host latency: 0.803101 ms (end to end 0.815723 ms, enqueue 0.788379 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771484 ms - Host latency: 0.78667 ms (end to end 0.798755 ms, enqueue 0.772485 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.774365 ms - Host latency: 0.789502 ms (end to end 0.801074 ms, enqueue 0.775684 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.775146 ms - Host latency: 0.79021 ms (end to end 0.802856 ms, enqueue 0.776294 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772119 ms - Host latency: 0.787622 ms (end to end 0.799194 ms, enqueue 0.773291 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771875 ms - Host latency: 0.787207 ms (end to end 0.79895 ms, enqueue 0.772461 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.787549 ms - Host latency: 0.803589 ms (end to end 0.816284 ms, enqueue 0.788623 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773657 ms - Host latency: 0.788916 ms (end to end 0.801172 ms, enqueue 0.77478 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772266 ms - Host latency: 0.7875 ms (end to end 0.799243 ms, enqueue 0.773096 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.770361 ms - Host latency: 0.785815 ms (end to end 0.797314 ms, enqueue 0.771631 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.777759 ms - Host latency: 0.792871 ms (end to end 0.804932 ms, enqueue 0.778882 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.774072 ms - Host latency: 0.788965 ms (end to end 0.800659 ms, enqueue 0.77395 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.790088 ms - Host latency: 0.805884 ms (end to end 0.818823 ms, enqueue 0.791455 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.7729 ms - Host latency: 0.788159 ms (end to end 0.800024 ms, enqueue 0.774683 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771997 ms - Host latency: 0.787524 ms (end to end 0.798706 ms, enqueue 0.772632 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.77207 ms - Host latency: 0.787402 ms (end to end 0.798633 ms, enqueue 0.772803 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773657 ms - Host latency: 0.78894 ms (end to end 0.800586 ms, enqueue 0.774097 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.770752 ms - Host latency: 0.786084 ms (end to end 0.797583 ms, enqueue 0.771265 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773169 ms - Host latency: 0.788745 ms (end to end 0.800391 ms, enqueue 0.774048 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.785303 ms - Host latency: 0.801343 ms (end to end 0.813501 ms, enqueue 0.78562 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.778198 ms - Host latency: 0.793188 ms (end to end 0.805371 ms, enqueue 0.779175 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.774145 ms - Host latency: 0.789404 ms (end to end 0.801099 ms, enqueue 0.774731 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772461 ms - Host latency: 0.787671 ms (end to end 0.799756 ms, enqueue 0.772876 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.77273 ms - Host latency: 0.788184 ms (end to end 0.79939 ms, enqueue 0.773682 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.781494 ms - Host latency: 0.797192 ms (end to end 0.810278 ms, enqueue 0.783105 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.787012 ms - Host latency: 0.80293 ms (end to end 0.815454 ms, enqueue 0.787939 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.774243 ms - Host latency: 0.789282 ms (end to end 0.800635 ms, enqueue 0.774243 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.778589 ms - Host latency: 0.793896 ms (end to end 0.804907 ms, enqueue 0.77854 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.775659 ms - Host latency: 0.790674 ms (end to end 0.802026 ms, enqueue 0.776318 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.774072 ms - Host latency: 0.789331 ms (end to end 0.800244 ms, enqueue 0.774194 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.776099 ms - Host latency: 0.791406 ms (end to end 0.80293 ms, enqueue 0.777002 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.783594 ms - Host latency: 0.799634 ms (end to end 0.812622 ms, enqueue 0.785059 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.774634 ms - Host latency: 0.789697 ms (end to end 0.801733 ms, enqueue 0.775659 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.777808 ms - Host latency: 0.793018 ms (end to end 0.804785 ms, enqueue 0.778906 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.775293 ms - Host latency: 0.790601 ms (end to end 0.801978 ms, enqueue 0.775806 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772681 ms - Host latency: 0.788061 ms (end to end 0.799219 ms, enqueue 0.772925 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.775098 ms - Host latency: 0.790601 ms (end to end 0.802368 ms, enqueue 0.776196 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.791284 ms - Host latency: 0.8073 ms (end to end 0.819849 ms, enqueue 0.792261 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.775342 ms - Host latency: 0.790527 ms (end to end 0.802881 ms, enqueue 0.776807 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.774121 ms - Host latency: 0.789258 ms (end to end 0.801147 ms, enqueue 0.775098 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.77478 ms - Host latency: 0.790356 ms (end to end 0.801318 ms, enqueue 0.774805 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773022 ms - Host latency: 0.78855 ms (end to end 0.800464 ms, enqueue 0.773755 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772241 ms - Host latency: 0.787598 ms (end to end 0.798828 ms, enqueue 0.773218 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.7896 ms - Host latency: 0.805469 ms (end to end 0.817725 ms, enqueue 0.790283 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.774316 ms - Host latency: 0.789844 ms (end to end 0.801636 ms, enqueue 0.775757 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.77229 ms - Host latency: 0.787622 ms (end to end 0.799219 ms, enqueue 0.773267 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773193 ms - Host latency: 0.788916 ms (end to end 0.800366 ms, enqueue 0.773804 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.776318 ms - Host latency: 0.791504 ms (end to end 0.802832 ms, enqueue 0.777075 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773975 ms - Host latency: 0.789355 ms (end to end 0.800562 ms, enqueue 0.774878 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.774634 ms - Host latency: 0.790674 ms (end to end 0.802271 ms, enqueue 0.775342 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.789893 ms - Host latency: 0.805884 ms (end to end 0.818726 ms, enqueue 0.790674 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771631 ms - Host latency: 0.787427 ms (end to end 0.798706 ms, enqueue 0.77273 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772021 ms - Host latency: 0.787378 ms (end to end 0.798315 ms, enqueue 0.772021 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771582 ms - Host latency: 0.787183 ms (end to end 0.798486 ms, enqueue 0.771533 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773193 ms - Host latency: 0.788599 ms (end to end 0.800098 ms, enqueue 0.773657 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.777832 ms - Host latency: 0.792944 ms (end to end 0.804834 ms, enqueue 0.778833 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.7875 ms - Host latency: 0.803247 ms (end to end 0.815674 ms, enqueue 0.788281 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772607 ms - Host latency: 0.787695 ms (end to end 0.799585 ms, enqueue 0.77373 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.774463 ms - Host latency: 0.789819 ms (end to end 0.80144 ms, enqueue 0.775366 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772803 ms - Host latency: 0.78833 ms (end to end 0.799487 ms, enqueue 0.77312 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772144 ms - Host latency: 0.787476 ms (end to end 0.79895 ms, enqueue 0.772656 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772461 ms - Host latency: 0.788037 ms (end to end 0.79895 ms, enqueue 0.772583 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.789746 ms - Host latency: 0.805689 ms (end to end 0.818237 ms, enqueue 0.79082 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.77251 ms - Host latency: 0.78772 ms (end to end 0.79939 ms, enqueue 0.773047 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773706 ms - Host latency: 0.78877 ms (end to end 0.800049 ms, enqueue 0.773926 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772046 ms - Host latency: 0.79021 ms (end to end 0.80188 ms, enqueue 0.772461 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772827 ms - Host latency: 0.787915 ms (end to end 0.799316 ms, enqueue 0.772876 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.77207 ms - Host latency: 0.78728 ms (end to end 0.799097 ms, enqueue 0.772632 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.792432 ms - Host latency: 0.808276 ms (end to end 0.820825 ms, enqueue 0.793384 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771973 ms - Host latency: 0.78728 ms (end to end 0.799365 ms, enqueue 0.77334 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771802 ms - Host latency: 0.78728 ms (end to end 0.799048 ms, enqueue 0.773389 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771729 ms - Host latency: 0.787158 ms (end to end 0.798975 ms, enqueue 0.773096 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772485 ms - Host latency: 0.787646 ms (end to end 0.799512 ms, enqueue 0.773145 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772876 ms - Host latency: 0.788086 ms (end to end 0.800635 ms, enqueue 0.773682 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.78833 ms - Host latency: 0.804761 ms (end to end 0.817407 ms, enqueue 0.78938 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.780396 ms - Host latency: 0.796191 ms (end to end 0.808691 ms, enqueue 0.781934 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771509 ms - Host latency: 0.786841 ms (end to end 0.79895 ms, enqueue 0.773242 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772363 ms - Host latency: 0.787695 ms (end to end 0.799658 ms, enqueue 0.773657 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771362 ms - Host latency: 0.78645 ms (end to end 0.798047 ms, enqueue 0.771997 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.773877 ms - Host latency: 0.789014 ms (end to end 0.803271 ms, enqueue 0.774829 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.77356 ms - Host latency: 0.78855 ms (end to end 0.800391 ms, enqueue 0.775635 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.790283 ms - Host latency: 0.806885 ms (end to end 0.819922 ms, enqueue 0.791382 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.775146 ms - Host latency: 0.790381 ms (end to end 0.802661 ms, enqueue 0.77644 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771582 ms - Host latency: 0.786987 ms (end to end 0.798462 ms, enqueue 0.772534 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771387 ms - Host latency: 0.786475 ms (end to end 0.798584 ms, enqueue 0.772754 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.77146 ms - Host latency: 0.78667 ms (end to end 0.798584 ms, enqueue 0.772363 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.77749 ms - Host latency: 0.792554 ms (end to end 0.804663 ms, enqueue 0.778687 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.78523 ms - Host latency: 0.801196 ms (end to end 0.814087 ms, enqueue 0.785986 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.771582 ms - Host latency: 0.786792 ms (end to end 0.797852 ms, enqueue 0.771899 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.775586 ms - Host latency: 0.791431 ms (end to end 0.803613 ms, enqueue 0.776489 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772046 ms - Host latency: 0.787183 ms (end to end 0.79917 ms, enqueue 0.773364 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.769629 ms - Host latency: 0.784863 ms (end to end 0.796753 ms, enqueue 0.770752 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.77085 ms - Host latency: 0.786035 ms (end to end 0.798315 ms, enqueue 0.771704 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.79502 ms - Host latency: 0.810938 ms (end to end 0.823315 ms, enqueue 0.795459 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772314 ms - Host latency: 0.787354 ms (end to end 0.799243 ms, enqueue 0.773901 ms)\n",
      "[06/21/2022-18:22:41] [I] Average on 10 runs - GPU latency: 0.772388 ms - Host latency: 0.787622 ms (end to end 0.799878 ms, enqueue 0.773169 ms)\n",
      "[06/21/2022-18:22:41] [I] \n",
      "[06/21/2022-18:22:41] [I] === Performance summary ===\n",
      "[06/21/2022-18:22:41] [I] Throughput: 1188.42 qps\n",
      "[06/21/2022-18:22:41] [I] Latency: min = 0.780762 ms, max = 0.910645 ms, mean = 0.807824 ms, median = 0.814209 ms, percentile(99%) = 0.860107 ms\n",
      "[06/21/2022-18:22:41] [I] End-to-End Host Latency: min = 0.791748 ms, max = 0.920898 ms, mean = 0.820259 ms, median = 0.82695 ms, percentile(99%) = 0.873413 ms\n",
      "[06/21/2022-18:22:41] [I] Enqueue Time: min = 0.764465 ms, max = 0.884521 ms, mean = 0.794217 ms, median = 0.801453 ms, percentile(99%) = 0.845566 ms\n",
      "[06/21/2022-18:22:41] [I] H2D Latency: min = 0.00866699 ms, max = 0.0428467 ms, mean = 0.00935153 ms, median = 0.00921631 ms, percentile(99%) = 0.0126953 ms\n",
      "[06/21/2022-18:22:41] [I] GPU Compute Time: min = 0.765869 ms, max = 0.890869 ms, mean = 0.79256 ms, median = 0.7995 ms, percentile(99%) = 0.84375 ms\n",
      "[06/21/2022-18:22:41] [I] D2H Latency: min = 0.00488281 ms, max = 0.0321045 ms, mean = 0.00591544 ms, median = 0.00585938 ms, percentile(99%) = 0.00952148 ms\n",
      "[06/21/2022-18:22:41] [I] Total Host Walltime: 3.00147 s\n",
      "[W] [06/21/2022-18:22:41] [I] Total GPU Compute Time: 2.82706 s\n",
      "[06/21/2022-18:22:41] * Throughput may be bound by Enqueue Time rather than GPU Compute and the GPU may be under-utilized.\n",
      "[W]   If not already in use, --useCudaGraph (utilize CUDA graphs where possible) may increase the throughput.\n",
      "[06/21/2022-18:22:41] [06/21/2022-18:22:41] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[06/21/2022-18:22:41] [V] \n",
      "[06/21/2022-18:22:41] [V] === Explanations of the performance metrics ===\n",
      "[06/21/2022-18:22:41] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.\n",
      "[06/21/2022-18:22:41] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.\n",
      "[06/21/2022-18:22:41] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.\n",
      "[06/21/2022-18:22:41] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.\n",
      "[06/21/2022-18:22:41] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.\n",
      "[06/21/2022-18:22:41] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.\n",
      "[06/21/2022-18:22:41] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.\n",
      "[06/21/2022-18:22:41] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.\n",
      "[06/21/2022-18:22:41] [V] End-to-End Host Latency: the duration from when the H2D of a query is called to when the D2H of the same query is completed, which includes the latency to wait for the completion of the previous query. This is the latency of a query if multiple queries are enqueued consecutively.\n",
      "[06/21/2022-18:22:41] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v8001] # trtexec --onnx=model.onnx --saveEngine=model_bs16.plan --minShapes=input_ids:1x128,attention_mask:1x128 --optShapes=input_ids:1x128,attention_mask:1x128 --maxShapes=input_ids:1x128,attention_mask:1x128 --fp16 --verbose --workspace=14000\n",
      "[06/21/2022-18:22:41] [V] [TRT] myelinFreeCb freeing GPU at 0x30b400000.\n",
      "[06/21/2022-18:22:41] [V] [TRT] myelinFreeCb freeing GPU at 0x304e98500.\n",
      "[06/21/2022-18:22:41] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 1216, GPU 3930 (MiB)\n"
     ]
    }
   ],
   "source": [
    "!docker run --gpus=all --rm -it -v `pwd`/workspace-trt:/workspace nvcr.io/nvidia/pytorch:21.08-py3 /bin/bash generate_models.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e68b14",
   "metadata": {},
   "source": [
    "# Step 4 - Create SageMaker model package and upload it to SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "090451eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p triton-serve-trt/bert/1/ \n",
    "!cp workspace-trt/model_bs16.plan triton-serve-trt/bert/1/model.plan \n",
    "!tar -C triton-serve-trt/ -czf model.tar.gz bert \n",
    "\n",
    "import boto3, json, sagemaker, time\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = boto3.Session()\n",
    "sm = sess.client(\"sagemaker\")\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
    "role = get_execution_role()\n",
    "client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "model_uri = sagemaker_session.upload_data(path=\"model.tar.gz\", key_prefix=\"triton-serve-trt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8916a0",
   "metadata": {},
   "source": [
    "# Step 5 - Create SageMaker Inference endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f9e4be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Arn: arn:aws:sagemaker:us-east-1:806460758762:model/triton-nlp-bert-trt-2022-06-21-18-45-34\n",
      "Endpoint Config Arn: arn:aws:sagemaker:us-east-1:806460758762:endpoint-config/triton-nlp-bert-trt-2022-06-21-18-45-34\n",
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:806460758762:endpoint/triton-nlp-bert-trt-2022-06-21-18-45-34\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-east-1:806460758762:endpoint/triton-nlp-bert-trt-2022-06-21-18-45-34\n",
      "Status: InService\n"
     ]
    }
   ],
   "source": [
    "account_id_map = {\n",
    "    'us-east-1': '785573368785',\n",
    "    'us-east-2': '007439368137',\n",
    "    'us-west-1': '710691900526',\n",
    "    'us-west-2': '301217895009',\n",
    "    'eu-west-1': '802834080501',\n",
    "    'eu-west-2': '205493899709',\n",
    "    'eu-west-3': '254080097072',\n",
    "    'eu-north-1': '601324751636',\n",
    "    'eu-south-1': '966458181534',\n",
    "    'eu-central-1': '746233611703',\n",
    "    'ap-east-1': '110948597952',\n",
    "    'ap-south-1': '763008648453',\n",
    "    'ap-northeast-1': '941853720454',\n",
    "    'ap-northeast-2': '151534178276',\n",
    "    'ap-southeast-1': '324986816169',\n",
    "    'ap-southeast-2': '355873309152',\n",
    "    'cn-northwest-1': '474822919863',\n",
    "    'cn-north-1': '472730292857',\n",
    "    'sa-east-1': '756306329178',\n",
    "    'ca-central-1': '464438896020',\n",
    "    'me-south-1': '836785723513',\n",
    "    'af-south-1': '774647643957'\n",
    "}\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "if region not in account_id_map.keys():\n",
    "    raise(\"UNSUPPORTED REGION\")\n",
    "    \n",
    "base = \"amazonaws.com.cn\" if region.startswith(\"cn-\") else \"amazonaws.com\"\n",
    "triton_image_uri = \"{account_id}.dkr.ecr.{region}.{base}/sagemaker-tritonserver:21.08-py3\".format(\n",
    "    account_id=account_id_map[region], region=region, base=base\n",
    ")\n",
    "\n",
    "sm_model_name = \"triton-nlp-bert-trt-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "container = {\n",
    "    \"Image\": triton_image_uri,\n",
    "    \"ModelDataUrl\": model_uri,\n",
    "    \"Environment\": {\"SAGEMAKER_TRITON_DEFAULT_MODEL_NAME\": \"bert\"},\n",
    "}\n",
    "\n",
    "create_model_response = sm.create_model(\n",
    "    ModelName=sm_model_name, ExecutionRoleArn=role, PrimaryContainer=container\n",
    ")\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])\n",
    "\n",
    "endpoint_config_name = \"triton-nlp-bert-trt-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "create_endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.p3.2xlarge\",\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": sm_model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])\n",
    "\n",
    "endpoint_name = \"triton-nlp-bert-trt-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "create_endpoint_response = sm.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])\n",
    "\n",
    "resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee3a20",
   "metadata": {},
   "source": [
    "# Step 6 - Test Triton SageMaker Inference Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98c82d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com, https://pypi.ngc.nvidia.com\n",
      "Collecting retry\n",
      "  Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
      "Requirement already satisfied: decorator>=3.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from retry) (5.1.0)\n",
      "Requirement already satisfied: py<2.0.0,>=1.4.26 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from retry) (1.11.0)\n",
      "Installing collected packages: retry\n",
      "Successfully installed retry-0.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b0d456c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ./workspace-trt/added_tokens.json. We won't load it.\n",
      "loading file ./workspace-trt/vocab.txt\n",
      "loading file None\n",
      "loading file ./workspace-trt/special_tokens_map.json\n",
      "loading file ./workspace-trt/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-21 18:53:06,799 [WARNING] Connection pool is full, discarding connection: runtime.sagemaker.us-east-1.amazonaws.com. Connection pool size: 10\n",
      "2022-06-21 18:53:11,043 [WARNING] Connection pool is full, discarding connection: runtime.sagemaker.us-east-1.amazonaws.com. Connection pool size: 10\n",
      "num_inferences:  4000[texts], elapsed_time: 11.79[sec], Throughput:  339.35[texts/sec]\n"
     ]
    }
   ],
   "source": [
    "import tritonclient.http as httpclient\n",
    "from transformers import DistilBertTokenizer\n",
    "import torch.nn.functional as F \n",
    "import numpy as np\n",
    "from retry import retry\n",
    "import botocore\n",
    "import concurrent\n",
    "import time\n",
    "\n",
    "\n",
    "enc = DistilBertTokenizer.from_pretrained(\"./workspace-trt/\")\n",
    "    \n",
    "def tokenize_text(text):\n",
    "    encoded_text = enc(clean_text(text), padding=\"max_length\", max_length=128, truncation=True)\n",
    "    return encoded_text[\"input_ids\"], encoded_text[\"attention_mask\"]\n",
    "\n",
    "\n",
    "def get_sample_tokenized_text_binary(text):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    input_names =  [\"input_ids\", \"attention_mask\"]\n",
    "    output_names = [\"logits\"]\n",
    "    \n",
    "    inputs.append(httpclient.InferInput(input_names[0], [1, 128], \"INT32\"))\n",
    "    inputs.append(httpclient.InferInput(input_names[1], [1, 128], \"INT32\"))\n",
    "    indexed_tokens, attention_mask = tokenize_text(text)\n",
    "\n",
    "    indexed_tokens = np.array(indexed_tokens, dtype=np.int32)\n",
    "    indexed_tokens = np.expand_dims(indexed_tokens, axis=0)\n",
    "    inputs[0].set_data_from_numpy(indexed_tokens, binary_data=True)\n",
    "\n",
    "    attention_mask = np.array(attention_mask, dtype=np.int32)\n",
    "    attention_mask = np.expand_dims(attention_mask, axis=0)\n",
    "    inputs[1].set_data_from_numpy(attention_mask, binary_data=True)\n",
    "\n",
    "    outputs.append(httpclient.InferRequestedOutput(output_names[0], binary_data=True))\n",
    "    outputs.append(httpclient.InferRequestedOutput(output_names[1], binary_data=True))\n",
    "    request_body, header_length = httpclient.InferenceServerClient.generate_request_body(inputs, outputs=outputs)\n",
    "    return request_body, header_length\n",
    "\n",
    "\n",
    "@retry(botocore.exceptions.ClientError, tries=5, delay=1)\n",
    "def get_prediction(text):\n",
    "    input_ids, attention_mask = tokenize_text(text)\n",
    "\n",
    "    payload = {\n",
    "        \"inputs\": [\n",
    "            {\"name\": \"input_ids\", \"shape\": [1, 128], \"datatype\": \"INT32\", \"data\": input_ids},\n",
    "            {\"name\": \"attention_mask\", \"shape\": [1, 128], \"datatype\": \"INT32\", \"data\": attention_mask},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = client.invoke_endpoint(EndpointName=endpoint_name, ContentType=\"application/octet-stream\", Body=json.dumps(payload))\n",
    "\n",
    "    result = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
    "    predictions = F.softmax(torch.tensor(result['outputs'][0]['data']),dim=-1)\n",
    "    return torch.argmax(predictions, dim=-1).numpy()\n",
    "    \n",
    "test_texts = [\n",
    "                \"Oh k...i'''m watching here:)\",\n",
    "                \"As a valued customer, I am pleased to advise you that following recent review of your Mob No. you are awarded with a £1500 Bonus Prize, call 09066364589\",\n",
    "                \"I HAVE A DATE ON SUNDAY WITH WILL!!\",\n",
    "                \"England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/ú1.20 POBOXox36504W45WQ 16+\"\n",
    "]\n",
    "\n",
    "\n",
    "num_inferences = 1000\n",
    "start = time.time() \n",
    "with concurrent.futures.ThreadPoolExecutor() as exe: \n",
    "    fut_list = []\n",
    "    for _ in range (num_inferences):\n",
    "        for test_text in test_texts:\n",
    "            fut = exe.submit(get_prediction, test_text)         \n",
    "            fut_list.append(fut)     \n",
    "    for fut in fut_list:         \n",
    "        rslt = fut.result() \n",
    "        \n",
    "elapsed_time = time.time() - start \n",
    "print('num_inferences:{:>6}[texts], elapsed_time:{:6.2f}[sec], Throughput:{:8.2f}[texts/sec]'.format(num_inferences * len(test_texts), elapsed_time, num_inferences * len(test_texts)/ elapsed_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f914789",
   "metadata": {},
   "source": [
    "# Step 7 - Delete the SageMaker Inference Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56a2fdc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'e54e00b3-d5b4-4cd4-ba5f-690c4794e023',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'e54e00b3-d5b4-4cd4-ba5f-690c4794e023',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Tue, 21 Jun 2022 18:56:00 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm.delete_model(ModelName=sm_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb02c606",
   "metadata": {},
   "source": [
    "# Step 8 - Zip model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ed074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ./distilbert_train_intermediate\n",
    "!rm -r ./distilbert_train_intermediate-torchscript\n",
    "!zip -r ./sagemaker.zip ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20fb3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
